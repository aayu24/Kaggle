{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-16T09:44:55.789902Z","iopub.execute_input":"2023-09-16T09:44:55.790187Z","iopub.status.idle":"2023-09-16T09:44:56.205734Z","shell.execute_reply.started":"2023-09-16T09:44:55.790160Z","shell.execute_reply":"2023-09-16T09:44:56.204808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reference Notebooks - \n1. https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-no-autocorrect for the CV strategy\n2. https://www.kaggle.com/code/olegpush/commonlit-tune-hugging-face-model-for-beginners for getting Baseline model ready\n3. https://www.kaggle.com/code/chumajin/pytorch-bert-beginner-s-room for General understanding of Transformer Library output","metadata":{}},{"cell_type":"markdown","source":"#### Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport transformers\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset\nfrom transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import mean_squared_error\nimport torch\nfrom sklearn.model_selection import KFold, GroupKFold","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:44:56.207698Z","iopub.execute_input":"2023-09-16T09:44:56.208405Z","iopub.status.idle":"2023-09-16T09:45:10.399447Z","shell.execute_reply.started":"2023-09-16T09:44:56.208370Z","shell.execute_reply":"2023-09-16T09:45:10.398389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nimport warnings\nimport logging\nimport shutil\nfrom tqdm import tqdm\nfrom datasets import disable_progress_bar\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \ndisable_progress_bar()\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:10.401144Z","iopub.execute_input":"2023-09-16T09:45:10.401553Z","iopub.status.idle":"2023-09-16T09:45:10.408735Z","shell.execute_reply.started":"2023-09-16T09:45:10.401518Z","shell.execute_reply":"2023-09-16T09:45:10.407334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n#     model_name=\"debertav3base\"\n    model_name=\"deberta-v3-large/deberta-v3-large\"\n    learning_rate=1.5e-5\n    weight_decay=0.02\n    hidden_dropout_prob=0.007\n    attention_probs_dropout_prob=0.007\n    num_train_epochs=5\n    n_splits=4\n    batch_size=4 #8\n    random_seed=42\n    save_steps=100 #500\n    max_length=512 #1024\n    n_freeze_layers=6","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:42:54.528692Z","iopub.execute_input":"2023-09-16T10:42:54.528979Z","iopub.status.idle":"2023-09-16T10:42:54.537370Z","shell.execute_reply.started":"2023-09-16T10:42:54.528949Z","shell.execute_reply":"2023-09-16T10:42:54.536188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SEED 42\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything(CFG.random_seed)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:10.425636Z","iopub.execute_input":"2023-09-16T09:45:10.426212Z","iopub.status.idle":"2023-09-16T09:45:10.438754Z","shell.execute_reply.started":"2023-09-16T09:45:10.426102Z","shell.execute_reply":"2023-09-16T09:45:10.437755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n\nprompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\nprompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\nsummaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\nsummaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\nsample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:10.440077Z","iopub.execute_input":"2023-09-16T09:45:10.441333Z","iopub.status.idle":"2023-09-16T09:45:10.573836Z","shell.execute_reply.started":"2023-09-16T09:45:10.441282Z","shell.execute_reply":"2023-09-16T09:45:10.572896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.merge(prompts_train,summaries_train,on='prompt_id')\ntest=pd.merge(prompts_test,summaries_test,on='prompt_id')","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:10.577362Z","iopub.execute_input":"2023-09-16T09:45:10.577598Z","iopub.status.idle":"2023-09-16T09:45:10.608008Z","shell.execute_reply.started":"2023-09-16T09:45:10.577567Z","shell.execute_reply":"2023-09-16T09:45:10.607126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:10.609923Z","iopub.execute_input":"2023-09-16T09:45:10.610122Z","iopub.status.idle":"2023-09-16T09:45:10.633290Z","shell.execute_reply.started":"2023-09-16T09:45:10.610098Z","shell.execute_reply":"2023-09-16T09:45:10.632488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:10.634421Z","iopub.execute_input":"2023-09-16T09:45:10.634657Z","iopub.status.idle":"2023-09-16T09:45:10.646963Z","shell.execute_reply.started":"2023-09-16T09:45:10.634625Z","shell.execute_reply":"2023-09-16T09:45:10.645823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Split train data using GroupKFolds on prompt_id\nSince test dataset will have new prompts, hence task becomes to train model to perform well on new/unseen prompts - https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/425409#2357563","metadata":{}},{"cell_type":"code","source":"gkf = GroupKFold(n_splits=CFG.n_splits) # Since 4 prompts in training set\n\nfor i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n    train.loc[val_index, \"fold\"] = i","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:10.651365Z","iopub.execute_input":"2023-09-16T09:45:10.652162Z","iopub.status.idle":"2023-09-16T09:45:10.669356Z","shell.execute_reply.started":"2023-09-16T09:45:10.652128Z","shell.execute_reply":"2023-09-16T09:45:10.668463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"fold\").count()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:10.670925Z","iopub.execute_input":"2023-09-16T09:45:10.671187Z","iopub.status.idle":"2023-09-16T09:45:10.692704Z","shell.execute_reply.started":"2023-09-16T09:45:10.671154Z","shell.execute_reply":"2023-09-16T09:45:10.691920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Prepare huggingface dataset\nRef - https://huggingface.co/docs/datasets/v2.14.5/en/tabular_load#pandas-dataframes","metadata":{}},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train[['text'] + ['content','wording'] + ['fold']])","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:10.693875Z","iopub.execute_input":"2023-09-16T09:45:10.694194Z","iopub.status.idle":"2023-09-16T09:45:10.723798Z","shell.execute_reply.started":"2023-09-16T09:45:10.694161Z","shell.execute_reply":"2023-09-16T09:45:10.722824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:10.726910Z","iopub.execute_input":"2023-09-16T09:45:10.727142Z","iopub.status.idle":"2023-09-16T09:45:10.735723Z","shell.execute_reply.started":"2023-09-16T09:45:10.727112Z","shell.execute_reply":"2023-09-16T09:45:10.734524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:10.737623Z","iopub.execute_input":"2023-09-16T09:45:10.737986Z","iopub.status.idle":"2023-09-16T09:45:10.985599Z","shell.execute_reply.started":"2023-09-16T09:45:10.737953Z","shell.execute_reply":"2023-09-16T09:45:10.984461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Model and Metrics","metadata":{}},{"cell_type":"markdown","source":"#### Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(f'/kaggle/input/{CFG.model_name}')","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:10.987674Z","iopub.execute_input":"2023-09-16T09:45:10.987928Z","iopub.status.idle":"2023-09-16T09:45:12.189046Z","shell.execute_reply.started":"2023-09-16T09:45:10.987893Z","shell.execute_reply":"2023-09-16T09:45:12.188049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.encode_plus(train_dataset[0]['text'])","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:42.738294Z","iopub.execute_input":"2023-09-16T09:45:42.738649Z","iopub.status.idle":"2023-09-16T09:45:42.753093Z","shell.execute_reply.started":"2023-09-16T09:45:42.738611Z","shell.execute_reply":"2023-09-16T09:45:42.752174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:44.177136Z","iopub.execute_input":"2023-09-16T09:45:44.178151Z","iopub.status.idle":"2023-09-16T09:45:44.185880Z","shell.execute_reply.started":"2023-09-16T09:45:44.178115Z","shell.execute_reply":"2023-09-16T09:45:44.184716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Figure out generating labels columns for batch of thousand\ndef generate_tokens(examples: pd.DataFrame,mode='train',text_col='text'):\n    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,return_tensors='np')\n    if mode == 'test':\n        return encodings\n    labels = np.column_stack((examples['content'],examples['wording']))\n    return {**encodings, \"labels\": labels}\n\n# tokenized_train_dataset = train_dataset.map(generate_tokens,batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:52.999659Z","iopub.execute_input":"2023-09-16T09:45:52.999930Z","iopub.status.idle":"2023-09-16T09:45:53.005759Z","shell.execute_reply.started":"2023-09-16T09:45:52.999902Z","shell.execute_reply":"2023-09-16T09:45:53.004830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenized_train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-15T04:58:48.523181Z","iopub.status.idle":"2023-09-15T04:58:48.523897Z","shell.execute_reply.started":"2023-09-15T04:58:48.523402Z","shell.execute_reply":"2023-09-15T04:58:48.523430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sep = tokenizer.sep_token\ntrain['full_text'] = train['prompt_title'] + sep + train['prompt_question'] + sep + train['text']\ntest['full_text'] = test['prompt_title'] + sep + test['prompt_question'] + sep + test['text']","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:55.894394Z","iopub.execute_input":"2023-09-16T09:45:55.895325Z","iopub.status.idle":"2023-09-16T09:45:55.910373Z","shell.execute_reply.started":"2023-09-16T09:45:55.895282Z","shell.execute_reply":"2023-09-16T09:45:55.909311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer(train.loc[0]['full_text'])","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:57.305961Z","iopub.execute_input":"2023-09-16T09:45:57.306215Z","iopub.status.idle":"2023-09-16T09:45:57.314544Z","shell.execute_reply.started":"2023-09-16T09:45:57.306187Z","shell.execute_reply":"2023-09-16T09:45:57.313444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(tokenizer(train.loc[0]['full_text'])['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:59.492544Z","iopub.execute_input":"2023-09-16T09:45:59.493127Z","iopub.status.idle":"2023-09-16T09:45:59.501391Z","shell.execute_reply.started":"2023-09-16T09:45:59.493090Z","shell.execute_reply":"2023-09-16T09:45:59.500538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[0]['full_text']","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:45:59.752861Z","iopub.execute_input":"2023-09-16T09:45:59.753114Z","iopub.status.idle":"2023-09-16T09:45:59.759196Z","shell.execute_reply.started":"2023-09-16T09:45:59.753089Z","shell.execute_reply":"2023-09-16T09:45:59.758369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Config","metadata":{}},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(f'/kaggle/input/{CFG.model_name}')","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:46:28.166373Z","iopub.execute_input":"2023-09-16T09:46:28.166959Z","iopub.status.idle":"2023-09-16T09:46:28.175695Z","shell.execute_reply.started":"2023-09-16T09:46:28.166924Z","shell.execute_reply":"2023-09-16T09:46:28.174827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# config","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-16T09:46:34.157160Z","iopub.execute_input":"2023-09-16T09:46:34.157426Z","iopub.status.idle":"2023-09-16T09:46:34.162232Z","shell.execute_reply.started":"2023-09-16T09:46:34.157397Z","shell.execute_reply":"2023-09-16T09:46:34.161148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config.update({\n    \"num_labels\": 2,\n    \"problem_type\": 'regression',\n    \"hidden_dropout_prob\": CFG.hidden_dropout_prob,\n    \"attention_probs_dropout_prob\": CFG.attention_probs_dropout_prob\n})","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:46:34.537067Z","iopub.execute_input":"2023-09-16T09:46:34.537418Z","iopub.status.idle":"2023-09-16T09:46:34.544280Z","shell.execute_reply.started":"2023-09-16T09:46:34.537369Z","shell.execute_reply":"2023-09-16T09:46:34.543276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:46:37.123778Z","iopub.execute_input":"2023-09-16T09:46:37.124034Z","iopub.status.idle":"2023-09-16T09:46:37.131159Z","shell.execute_reply.started":"2023-09-16T09:46:37.124006Z","shell.execute_reply":"2023-09-16T09:46:37.130314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model","metadata":{}},{"cell_type":"code","source":"# model = AutoModel.from_pretrained(f'/kaggle/input/{CFG.model_name}',config=config)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:46:41.048408Z","iopub.execute_input":"2023-09-16T09:46:41.048702Z","iopub.status.idle":"2023-09-16T09:46:41.053638Z","shell.execute_reply.started":"2023-09-16T09:46:41.048674Z","shell.execute_reply":"2023-09-16T09:46:41.052660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:46:41.443138Z","iopub.execute_input":"2023-09-16T09:46:41.443748Z","iopub.status.idle":"2023-09-16T09:46:41.447775Z","shell.execute_reply.started":"2023-09-16T09:46:41.443711Z","shell.execute_reply":"2023-09-16T09:46:41.446622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(f'/kaggle/input/{CFG.model_name}',config=config)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:41:55.803204Z","iopub.execute_input":"2023-09-16T10:41:55.803516Z","iopub.status.idle":"2023-09-16T10:42:05.933394Z","shell.execute_reply.started":"2023-09-16T10:41:55.803461Z","shell.execute_reply":"2023-09-16T10:42:05.932519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:46:57.217111Z","iopub.execute_input":"2023-09-16T09:46:57.217444Z","iopub.status.idle":"2023-09-16T09:46:57.229357Z","shell.execute_reply.started":"2023-09-16T09:46:57.217409Z","shell.execute_reply":"2023-09-16T09:46:57.228458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Can see that a pooling layer followed by Linear Layer with 2 outputs was added to base model","metadata":{}},{"cell_type":"code","source":"# freezing embeddings layer\nmodel.base_model.embeddings.requires_grad_(False)\n\n# freezing the initial N layers\nfor k, param in model.base_model.encoder.layer.named_parameters():\n    l = int(k.split(\".\")[0])\n    if l < CFG.n_freeze_layers:\n        param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:43:01.445461Z","iopub.execute_input":"2023-09-16T10:43:01.445756Z","iopub.status.idle":"2023-09-16T10:43:01.455699Z","shell.execute_reply.started":"2023-09-16T10:43:01.445728Z","shell.execute_reply":"2023-09-16T10:43:01.454823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#You can confirm which layers have been frozen and see the whole layer struct of the model\n# for n, p in model.named_parameters():\n#     print(n, p.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:44:27.583919Z","iopub.execute_input":"2023-09-16T10:44:27.584194Z","iopub.status.idle":"2023-09-16T10:44:27.588821Z","shell.execute_reply.started":"2023-09-16T10:44:27.584164Z","shell.execute_reply":"2023-09-16T10:44:27.587672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:47:02.368504Z","iopub.execute_input":"2023-09-16T09:47:02.368791Z","iopub.status.idle":"2023-09-16T09:47:02.627015Z","shell.execute_reply.started":"2023-09-16T09:47:02.368754Z","shell.execute_reply":"2023-09-16T09:47:02.626077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Metrics - MCRMSE","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    rmse = mean_squared_error(labels, predictions, squared=False)\n    return {\"rmse\": rmse}\n\ndef compute_mcrmse(eval_pred):\n    \"\"\"\n    Calculates mean columnwise root mean squared error\n    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n    \"\"\"\n    preds, labels = eval_pred\n\n    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n    mcrmse = np.mean(col_rmse)\n\n    return {\n        \"content_rmse\": col_rmse[0],\n        \"wording_rmse\": col_rmse[1],\n        \"mcrmse\": mcrmse,\n    }\n\ndef compt_score(content_true, content_pred, wording_true, wording_pred):\n    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n    \n    return (content_score + wording_score)/2","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:47:05.677403Z","iopub.execute_input":"2023-09-16T09:47:05.677851Z","iopub.status.idle":"2023-09-16T09:47:05.688673Z","shell.execute_reply.started":"2023-09-16T09:47:05.677812Z","shell.execute_reply":"2023-09-16T09:47:05.687698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train using GroupKFold for CV","metadata":{}},{"cell_type":"code","source":"train_collator = DataCollatorWithPadding(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:47:08.521956Z","iopub.execute_input":"2023-09-16T09:47:08.522221Z","iopub.status.idle":"2023-09-16T09:47:08.527311Z","shell.execute_reply.started":"2023-09-16T09:47:08.522192Z","shell.execute_reply":"2023-09-16T09:47:08.526160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_fold_dir = './'\n# training_args = TrainingArguments(\n#     output_dir = model_fold_dir,\n#     report_to='none',\n#     load_best_model_at_end=True, # select best model\n#     learning_rate=CFG.learning_rate,\n#     per_device_train_batch_size=CFG.batch_size,\n#     per_device_eval_batch_size=CFG.batch_size,\n#     num_train_epochs=CFG.num_train_epochs,\n#     weight_decay=CFG.weight_decay,\n#     greater_is_better=False,\n#     metric_for_best_model=\"mcrmse\",\n#     save_strategy='no', # \"steps\",\n#     evaluation_strategy='no' #\"steps\",\n# )\n## report_to='none' to avoid wandb login - https://discuss.huggingface.co/t/how-to-turn-wandb-off-in-trainer/6237/2\n## both save strategy and eval strategy have to match","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:28:24.163392Z","iopub.execute_input":"2023-09-14T06:28:24.164351Z","iopub.status.idle":"2023-09-14T06:28:24.169606Z","shell.execute_reply.started":"2023-09-14T06:28:24.164297Z","shell.execute_reply":"2023-09-14T06:28:24.168495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### GPU","metadata":{}},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\ncuda.empty_cache()\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:47:11.966341Z","iopub.execute_input":"2023-09-16T09:47:11.966933Z","iopub.status.idle":"2023-09-16T09:47:12.000565Z","shell.execute_reply.started":"2023-09-16T09:47:11.966897Z","shell.execute_reply":"2023-09-16T09:47:11.997628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:45:32.238075Z","iopub.execute_input":"2023-09-16T10:45:32.238681Z","iopub.status.idle":"2023-09-16T10:45:32.547921Z","shell.execute_reply.started":"2023-09-16T10:45:32.238646Z","shell.execute_reply":"2023-09-16T10:45:32.546971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:45:32.554799Z","iopub.execute_input":"2023-09-16T10:45:32.555446Z","iopub.status.idle":"2023-09-16T10:45:32.627314Z","shell.execute_reply.started":"2023-09-16T10:45:32.555403Z","shell.execute_reply":"2023-09-16T10:45:32.626238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training loop","metadata":{}},{"cell_type":"markdown","source":"### Use prompt question + prompt text + text to generate embeddings","metadata":{}},{"cell_type":"code","source":"target_cols = ['content','wording']\ntext_col = 'full_text' #'text'\ntext_cols = [text_col]","metadata":{"execution":{"iopub.status.busy":"2023-09-16T09:47:20.517138Z","iopub.execute_input":"2023-09-16T09:47:20.518194Z","iopub.status.idle":"2023-09-16T09:47:20.523927Z","shell.execute_reply.started":"2023-09-16T09:47:20.518154Z","shell.execute_reply":"2023-09-16T09:47:20.522784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# delete old model files\nif os.path.exists('deberta-v3-large'):\n    shutil.rmtree('deberta-v3-large')\nos.mkdir('deberta-v3-large')\n# if os.path.exists(CFG.model_name):\n#     shutil.rmtree(CFG.model_name)\n# os.mkdir(CFG.model_name)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:45:24.395643Z","iopub.execute_input":"2023-09-16T10:45:24.395917Z","iopub.status.idle":"2023-09-16T10:45:24.717511Z","shell.execute_reply.started":"2023-09-16T10:45:24.395887Z","shell.execute_reply":"2023-09-16T10:45:24.716250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GPU training loop","metadata":{}},{"cell_type":"code","source":"for fold in range(CFG.n_splits):\n    print(f\"Fold: {fold}\")\n    fold_train_data = train[train['fold']!=fold]\n    fold_val_data = train[train['fold']==fold]\n    fold_train_dataset = Dataset.from_pandas(fold_train_data[text_cols + target_cols])\n    fold_val_dataset = Dataset.from_pandas(fold_val_data[text_cols + target_cols])\n    fold_train_tokenized = fold_train_dataset.map(lambda x: generate_tokens(x,text_col=text_col),batched=True)\n    fold_val_tokenized = fold_val_dataset.map(lambda x: generate_tokens(x,text_col=text_col),batched=True)\n    print(f\"Number of training examples: {fold_train_tokenized.num_rows}\")\n    print(f\"Number of validation examples: {fold_val_tokenized.num_rows}\")\n    gc.collect()\n    \n    model = AutoModelForSequenceClassification.from_pretrained(f'/kaggle/input/{CFG.model_name}',config=config)\n    # freezing embeddings layer\n    model.base_model.embeddings.requires_grad_(False)\n\n    # freezing the initial N layers\n    for k, param in model.base_model.encoder.layer.named_parameters():\n        l = int(k.split(\".\")[0])\n        if l < CFG.n_freeze_layers:\n            param.requires_grad = False\n            \n    model_gpu = model.to(device)\n    \n    model_dir = f\"{CFG.model_name}/fold_{fold}\"\n    model_fold_dir = os.path.join(model_dir, str(fold))\n    \n    training_args = TrainingArguments(\n        output_dir = model_fold_dir,\n        report_to='none',\n        load_best_model_at_end=True, # select best model\n        learning_rate=CFG.learning_rate,\n        per_device_train_batch_size=CFG.batch_size,\n        per_device_eval_batch_size=CFG.batch_size,\n        num_train_epochs=CFG.num_train_epochs,\n        weight_decay=CFG.weight_decay,\n        greater_is_better=False,\n        metric_for_best_model=\"mcrmse\",\n        save_strategy='steps',\n        evaluation_strategy='steps',\n        save_total_limit=1,\n        gradient_accumulation_steps=4,\n        gradient_checkpointing=True,\n        optim='adafactor',\n#         fp16=True,\n        save_steps = CFG.save_steps,\n        eval_steps = CFG.save_steps\n    )\n    \n    trainer = Trainer(\n        model = model_gpu,\n        train_dataset = fold_train_tokenized,\n        eval_dataset = fold_val_tokenized,\n        args = training_args,\n        data_collator = train_collator,\n        tokenizer = tokenizer,\n        compute_metrics = compute_mcrmse    \n    )\n    \n    trainer.train()\n    \n    model_gpu.save_pretrained(model_dir)\n    tokenizer.save_pretrained(model_dir)\n    model_gpu.cpu()\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T10:45:41.226669Z","iopub.execute_input":"2023-09-16T10:45:41.227241Z","iopub.status.idle":"2023-09-16T15:29:45.050874Z","shell.execute_reply.started":"2023-09-16T10:45:41.227193Z","shell.execute_reply":"2023-09-16T15:29:45.049811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Combine these outputs with numerical text based feats and feed into LGBM","metadata":{}},{"cell_type":"markdown","source":"#### Add each fold model predictions to training data","metadata":{}},{"cell_type":"code","source":"for fold in range(CFG.n_splits):\n    val_data = train[train['fold']==fold]\n    val_dataset = Dataset.from_pandas(val_data[text_cols+target_cols])\n    tokenized_val_dataset = val_dataset.map(lambda x: generate_tokens(x,text_col=text_col),batched=True)\n    \n    model_dir = f\"{CFG.model_name}/fold_{fold}\"\n    model_fold_dir = os.path.join(model_dir, str(fold))\n\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)    \n    model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n    model_gpu = model.to(device)\n    \n    test_args = TrainingArguments(\n        output_dir=  model_fold_dir,\n        do_train = False,\n        do_predict = True,\n        per_device_eval_batch_size = CFG.batch_size,   \n        dataloader_drop_last = False,\n        fp16=True\n    )\n    \n    infer = Trainer(\n        model = model_gpu,\n        args = test_args,\n        tokenizer = tokenizer,\n        data_collator = train_collator\n    )\n    \n    preds = infer.predict(tokenized_val_dataset)[0]\n    train.loc[val_data.index,\"content_pred\"] = preds[:,0]\n    train.loc[val_data.index,\"wording_pred\"] = preds[:,1]\n    \n    model_gpu.cpu()\n    del model_gpu\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T15:31:38.671783Z","iopub.execute_input":"2023-09-16T15:31:38.672062Z","iopub.status.idle":"2023-09-16T15:36:31.990645Z","shell.execute_reply.started":"2023-09-16T15:31:38.672032Z","shell.execute_reply":"2023-09-16T15:36:31.989656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T15:36:31.992924Z","iopub.execute_input":"2023-09-16T15:36:31.993179Z","iopub.status.idle":"2023-09-16T15:36:32.008003Z","shell.execute_reply.started":"2023-09-16T15:36:31.993147Z","shell.execute_reply":"2023-09-16T15:36:32.007104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(compute_mcrmse((train[['content_pred','wording_pred']].values,train[target_cols].values)))","metadata":{"execution":{"iopub.status.busy":"2023-09-16T15:38:58.646453Z","iopub.execute_input":"2023-09-16T15:38:58.647075Z","iopub.status.idle":"2023-09-16T15:38:58.656597Z","shell.execute_reply.started":"2023-09-16T15:38:58.647040Z","shell.execute_reply":"2023-09-16T15:38:58.655591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CV Score","metadata":{}},{"cell_type":"code","source":"for fold in range(CFG.n_splits):\n    val_data = train\n    val_dataset = Dataset.from_pandas(val_data[text_cols+target_cols])\n    tokenized_val_dataset = val_dataset.map(lambda x: generate_tokens(x,'test',text_col=text_col),batched=True)\n    \n    model_dir = f\"{CFG.model_name}/fold_{fold}\"\n    model_fold_dir = os.path.join(model_dir, str(fold))\n\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)    \n    model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n    model_gpu = model.to(device)\n    \n    test_args = TrainingArguments(\n        output_dir=  model_fold_dir,\n        do_train = False,\n        do_predict = True,\n        per_device_eval_batch_size = CFG.batch_size,   \n        dataloader_drop_last = False,\n        fp16=True\n    )\n    \n    infer = Trainer(\n        model = model_gpu,\n        args = test_args,\n        tokenizer = tokenizer,\n        data_collator = train_collator\n    )\n    \n    preds = infer.predict(tokenized_val_dataset)[0]\n    train.loc[val_data.index,f\"content_pred_{fold}\"] = preds[:,0]\n    train.loc[val_data.index,f\"wording_pred_{fold}\"] = preds[:,1]\n    \n    model_gpu.cpu()\n    del model_gpu\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T15:44:36.204811Z","iopub.execute_input":"2023-09-16T15:44:36.205087Z","iopub.status.idle":"2023-09-16T16:00:42.197900Z","shell.execute_reply.started":"2023-09-16T15:44:36.205057Z","shell.execute_reply":"2023-09-16T16:00:42.196890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T16:01:52.747760Z","iopub.execute_input":"2023-09-16T16:01:52.748022Z","iopub.status.idle":"2023-09-16T16:01:52.776934Z","shell.execute_reply.started":"2023-09-16T16:01:52.747994Z","shell.execute_reply":"2023-09-16T16:01:52.776093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Take mean of predictions across all folds\ntrain[f'{target_cols[0]}_pred_mean'] = train[[f\"{target_cols[0]}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\ntrain[f'{target_cols[1]}_pred_mean'] = train[[f\"{target_cols[1]}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T16:00:42.226358Z","iopub.execute_input":"2023-09-16T16:00:42.226950Z","iopub.status.idle":"2023-09-16T16:00:42.243614Z","shell.execute_reply.started":"2023-09-16T16:00:42.226916Z","shell.execute_reply":"2023-09-16T16:00:42.242797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(compute_mcrmse((train[['content_pred_mean','wording_pred_mean']].values,train[target_cols].values)))","metadata":{"execution":{"iopub.status.busy":"2023-09-16T16:00:42.245882Z","iopub.execute_input":"2023-09-16T16:00:42.246423Z","iopub.status.idle":"2023-09-16T16:00:42.253989Z","shell.execute_reply.started":"2023-09-16T16:00:42.246390Z","shell.execute_reply":"2023-09-16T16:00:42.253034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import re\n# # Text cleaning function\n# def clean_text(text):\n#     text = text.lower()\n#     text = re.sub(r'\\n', ' ', text)\n#     text = re.sub(r'\\W', ' ', text)\n#     text = re.sub(r'\\s+', ' ', text)\n#     return text","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:16:16.698483Z","iopub.execute_input":"2023-09-13T13:16:16.698848Z","iopub.status.idle":"2023-09-13T13:16:16.708438Z","shell.execute_reply.started":"2023-09-13T13:16:16.698813Z","shell.execute_reply":"2023-09-13T13:16:16.707535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Enhanced preprocessing function\n# def preprocess_data(data: pd.DataFrame):\n#     merged_df = data.copy()\n#     text_columns = ['prompt_question', 'prompt_title', 'prompt_text', 'text']\n#     for column in text_columns:\n#         merged_df[column] = merged_df[column].apply(clean_text)\n#     merged_df['prompt_length'] = merged_df['prompt_text'].apply(len)\n#     merged_df['summary_length'] = merged_df['text'].apply(len)\n# #     merged_df['prompt_unique_words_cnt'] = merged_df['prompt_text'].apply(lambda x: len(set(x.split())))\n# #     merged_df['summary_unique_words_cnt'] = merged_df['text'].apply(lambda x: len(set(x.split())))\n# #     merged_df['summary_stopwords_cnt'] = merged_df['text'].apply(lambda x: count_stopwords(x))\n# #     merged_df['num_typos'] = merged_df['text'].apply(lambda x: get_num_typos(x))\n# #     merged_df['length_ratio'] = merged_df['summary_length']/merged_df['prompt_length']\n#     return merged_df","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:16:16.710494Z","iopub.execute_input":"2023-09-13T13:16:16.710980Z","iopub.status.idle":"2023-09-13T13:16:16.723263Z","shell.execute_reply.started":"2023-09-13T13:16:16.710947Z","shell.execute_reply":"2023-09-13T13:16:16.722214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# enh_train = preprocess_data(train)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:16:16.724638Z","iopub.execute_input":"2023-09-13T13:16:16.725108Z","iopub.status.idle":"2023-09-13T13:16:22.086692Z","shell.execute_reply.started":"2023-09-13T13:16:16.725072Z","shell.execute_reply":"2023-09-13T13:16:22.085759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# enh_text_cols = ['prompt_id', 'student_id', 'prompt_question', 'prompt_title', 'prompt_text', 'text']\n# cols_to_drop = enh_text_cols + target_cols + ['fold']","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:20:54.331689Z","iopub.execute_input":"2023-09-13T13:20:54.331970Z","iopub.status.idle":"2023-09-13T13:20:54.337603Z","shell.execute_reply.started":"2023-09-13T13:20:54.331939Z","shell.execute_reply":"2023-09-13T13:20:54.336667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# enh_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:20:54.691849Z","iopub.execute_input":"2023-09-13T13:20:54.692825Z","iopub.status.idle":"2023-09-13T13:20:54.713699Z","shell.execute_reply.started":"2023-09-13T13:20:54.692787Z","shell.execute_reply":"2023-09-13T13:20:54.712774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from xgboost import XGBRegressor\n# import lightgbm as lgb\n# model_dict = {}\n# for target in target_cols:\n#     models = []\n#     for fold in range(CFG.n_splits):\n#         enh_train_data = enh_train[enh_train['fold']!=fold]\n#         enh_val_data = enh_train[enh_train['fold']==fold]\n#         fold_X_train = enh_train_data.drop(columns=cols_to_drop)\n#         fold_y_train = enh_train_data[target]\n#         fold_X_val = enh_val_data.drop(columns=cols_to_drop)\n#         fold_y_val = enh_val_data[target]\n        \n#         dtrain = lgb.Dataset(fold_X_train, label=fold_y_train)\n#         dval = lgb.Dataset(fold_X_val, label=fold_y_val)\n\n#         params = {\n#                   'boosting_type': 'gbdt',\n#                   'random_state': 42,\n#                   'objective': 'regression',\n#                   'metric': 'rmse',\n#                   'learning_rate': 0.05,\n#                   }\n\n#         evaluation_results = {}\n#         model = lgb.train(params,\n#                           num_boost_round=10000,\n#                             #categorical_feature = categorical_features,\n#                           valid_names=['train', 'valid'],\n#                           train_set=dtrain,\n#                           valid_sets=dval,\n#                           callbacks=[\n#                               lgb.early_stopping(stopping_rounds=30, verbose=True),\n#                                lgb.log_evaluation(100),\n#                               lgb.callback.record_evaluation(evaluation_results)\n#                             ],\n#                           )\n#         models.append(model)\n#     model_dict[target] = models","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:22:10.373893Z","iopub.execute_input":"2023-09-13T13:22:10.374167Z","iopub.status.idle":"2023-09-13T13:22:11.324243Z","shell.execute_reply.started":"2023-09-13T13:22:10.374136Z","shell.execute_reply":"2023-09-13T13:22:11.323218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # cv\n# rmses = []\n\n# for target in target_cols:\n#     models = model_dict[target]\n\n#     preds = []\n#     trues = []\n    \n#     for fold, model in enumerate(models):\n#         X_eval_cv = enh_train[enh_train[\"fold\"] == fold].drop(columns=cols_to_drop)\n#         y_eval_cv = enh_train[enh_train[\"fold\"] == fold][target]\n\n#         pred = model.predict(X_eval_cv)\n\n#         trues.extend(y_eval_cv)\n#         preds.extend(pred)\n    \n#     rmse = np.sqrt(mean_squared_error(trues, preds))\n#     print(f\"{target}_rmse : {rmse}\")\n#     rmses = rmses + [rmse]\n\n# print(f\"mcrmse : {sum(rmses) / len(rmses)}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:24:10.304917Z","iopub.execute_input":"2023-09-13T13:24:10.305199Z","iopub.status.idle":"2023-09-13T13:24:10.406449Z","shell.execute_reply.started":"2023-09-13T13:24:10.305169Z","shell.execute_reply":"2023-09-13T13:24:10.404593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"test_dataset = Dataset.from_pandas(test[text_cols])","metadata":{"execution":{"iopub.status.busy":"2023-09-16T15:39:35.253842Z","iopub.execute_input":"2023-09-16T15:39:35.255634Z","iopub.status.idle":"2023-09-16T15:39:35.263402Z","shell.execute_reply.started":"2023-09-16T15:39:35.255591Z","shell.execute_reply":"2023-09-16T15:39:35.262444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_dataset = test_dataset.map(lambda x: generate_tokens(x,'test','full_text'),batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T15:39:35.615506Z","iopub.execute_input":"2023-09-16T15:39:35.615764Z","iopub.status.idle":"2023-09-16T15:39:35.630066Z","shell.execute_reply.started":"2023-09-16T15:39:35.615735Z","shell.execute_reply":"2023-09-16T15:39:35.629026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-16T15:39:35.967638Z","iopub.execute_input":"2023-09-16T15:39:35.967899Z","iopub.status.idle":"2023-09-16T15:39:35.974278Z","shell.execute_reply.started":"2023-09-16T15:39:35.967870Z","shell.execute_reply":"2023-09-16T15:39:35.973381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(CFG.n_splits):\n    model_dir = f\"{CFG.model_name}/fold_{fold}\"\n    model_fold_dir = os.path.join(model_dir, str(fold))\n\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)    \n    model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n    model_gpu = model.to(device)\n    \n    test_args = TrainingArguments(\n        output_dir=  model_fold_dir,\n        do_train = False,\n        do_predict = True,\n        per_device_eval_batch_size = 4,   \n        dataloader_drop_last = False,\n        fp16=True\n    )\n    \n    infer = Trainer(\n        model = model_gpu,\n        args = test_args,\n        tokenizer = tokenizer,\n        data_collator = train_collator\n    )\n    \n    preds = infer.predict(tokenized_test_dataset)[0]\n    test[f\"{target_cols[0]}_{fold}\"] = preds[:,0]\n    test[f\"{target_cols[1]}_{fold}\"] = preds[:,1]\n    \n    model_gpu.cpu()\n    del model_gpu\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T15:39:36.385062Z","iopub.execute_input":"2023-09-16T15:39:36.385610Z","iopub.status.idle":"2023-09-16T15:40:40.146891Z","shell.execute_reply.started":"2023-09-16T15:39:36.385567Z","shell.execute_reply":"2023-09-16T15:40:40.145942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2023-09-16T15:40:40.151040Z","iopub.execute_input":"2023-09-16T15:40:40.152090Z","iopub.status.idle":"2023-09-16T15:40:40.174443Z","shell.execute_reply.started":"2023-09-16T15:40:40.152057Z","shell.execute_reply":"2023-09-16T15:40:40.173426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Take mean of predictions across all folds\ntest[target_cols[0]] = test[[f\"{target_cols[0]}_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\ntest[target_cols[1]] = test[[f\"{target_cols[1]}_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T15:40:40.175757Z","iopub.execute_input":"2023-09-16T15:40:40.176733Z","iopub.status.idle":"2023-09-16T15:40:40.197513Z","shell.execute_reply.started":"2023-09-16T15:40:40.176700Z","shell.execute_reply":"2023-09-16T15:40:40.196696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"df_submission = pd.DataFrame()\ndf_submission['student_id'] = test['student_id']\ndf_submission['content'] = 0\ndf_submission['wording'] = 0\ndf_submission[target_cols[0]] = test[target_cols[0]]\ndf_submission[target_cols[1]] = test[target_cols[1]]\ndf_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T15:40:40.199690Z","iopub.execute_input":"2023-09-16T15:40:40.200267Z","iopub.status.idle":"2023-09-16T15:40:40.216934Z","shell.execute_reply.started":"2023-09-16T15:40:40.200234Z","shell.execute_reply":"2023-09-16T15:40:40.215996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission","metadata":{"execution":{"iopub.status.busy":"2023-09-16T15:40:40.218490Z","iopub.execute_input":"2023-09-16T15:40:40.219204Z","iopub.status.idle":"2023-09-16T15:40:40.229354Z","shell.execute_reply.started":"2023-09-16T15:40:40.219171Z","shell.execute_reply":"2023-09-16T15:40:40.228298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Possible Next Steps for model improvement\n1. Have used base model. From multiple comments, it might be worth considering using v3large model - https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/424330\n2. Add some numerical features, combine with preds by base model and feed into XGB/LGBM for training\n3. Consider not just text, but also other text cols for generating embeddings. (prompt_question + title + text) \n4. Add some more numerical features before using LGBM like semantic similarity - https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/436187\n5. Do some text cleaning before generating embeddings.","metadata":{}},{"cell_type":"markdown","source":"| Approach | CV | LB |\n| -------- | -- | -- |\n| 1. v3large        |    | 0.483 |\n| 2.        |    |     |\n| 3. mult text cols       |    |   |","metadata":{}},{"cell_type":"markdown","source":"### Challenges faced\n1. Faced Cuda out of memory errors many times while training DebertaV3Large - Had to reduce batch size,along with using gradient accumulation, checkpointing etc. Good ref - https://huggingface.co/docs/transformers/v4.18.0/en/performance ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}