{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-13T17:37:46.391162Z","iopub.execute_input":"2023-09-13T17:37:46.391788Z","iopub.status.idle":"2023-09-13T17:37:46.766693Z","shell.execute_reply.started":"2023-09-13T17:37:46.391752Z","shell.execute_reply":"2023-09-13T17:37:46.765709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reference Notebooks - \n1. https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-no-autocorrect for the CV strategy\n2. https://www.kaggle.com/code/olegpush/commonlit-tune-hugging-face-model-for-beginners for getting Baseline model ready\n3. https://www.kaggle.com/code/chumajin/pytorch-bert-beginner-s-room for General understanding of Transformer Library output","metadata":{}},{"cell_type":"markdown","source":"#### Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport transformers\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset\nfrom transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import mean_squared_error\nimport torch\nfrom sklearn.model_selection import KFold, GroupKFold","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:27.504903Z","iopub.execute_input":"2023-09-13T17:38:27.505385Z","iopub.status.idle":"2023-09-13T17:38:41.451402Z","shell.execute_reply.started":"2023-09-13T17:38:27.505346Z","shell.execute_reply":"2023-09-13T17:38:41.450396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nimport warnings\nimport logging\nimport shutil\nfrom tqdm import tqdm\nfrom datasets import disable_progress_bar\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \ndisable_progress_bar()\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:41.453360Z","iopub.execute_input":"2023-09-13T17:38:41.453731Z","iopub.status.idle":"2023-09-13T17:38:41.460780Z","shell.execute_reply.started":"2023-09-13T17:38:41.453698Z","shell.execute_reply":"2023-09-13T17:38:41.459374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n#     model_name=\"debertav3base\"\n    model_name=\"deberta-v3-large/deberta-v3-large\"\n    learning_rate=1.5e-5\n    weight_decay=0.02\n    hidden_dropout_prob=0.007\n    attention_probs_dropout_prob=0.007\n    num_train_epochs=5\n    n_splits=4\n    batch_size=4\n    random_seed=42\n    save_steps=100\n    max_length=512 #1024","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:45:29.218779Z","iopub.execute_input":"2023-09-13T17:45:29.219064Z","iopub.status.idle":"2023-09-13T17:45:29.224620Z","shell.execute_reply.started":"2023-09-13T17:45:29.219034Z","shell.execute_reply":"2023-09-13T17:45:29.223489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SEED 42\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything(CFG.random_seed)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:41.480264Z","iopub.execute_input":"2023-09-13T17:38:41.480534Z","iopub.status.idle":"2023-09-13T17:38:41.493303Z","shell.execute_reply.started":"2023-09-13T17:38:41.480499Z","shell.execute_reply":"2023-09-13T17:38:41.492352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n\nprompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\nprompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\nsummaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\nsummaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\nsample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:41.494523Z","iopub.execute_input":"2023-09-13T17:38:41.495463Z","iopub.status.idle":"2023-09-13T17:38:41.629000Z","shell.execute_reply.started":"2023-09-13T17:38:41.495328Z","shell.execute_reply":"2023-09-13T17:38:41.628062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.merge(prompts_train,summaries_train,on='prompt_id')\ntest=pd.merge(prompts_test,summaries_test,on='prompt_id')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:41.630599Z","iopub.execute_input":"2023-09-13T17:38:41.630831Z","iopub.status.idle":"2023-09-13T17:38:41.661696Z","shell.execute_reply.started":"2023-09-13T17:38:41.630800Z","shell.execute_reply":"2023-09-13T17:38:41.660814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:41.663210Z","iopub.execute_input":"2023-09-13T17:38:41.663479Z","iopub.status.idle":"2023-09-13T17:38:41.684496Z","shell.execute_reply.started":"2023-09-13T17:38:41.663447Z","shell.execute_reply":"2023-09-13T17:38:41.683505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:41.686126Z","iopub.execute_input":"2023-09-13T17:38:41.686651Z","iopub.status.idle":"2023-09-13T17:38:41.700448Z","shell.execute_reply.started":"2023-09-13T17:38:41.686606Z","shell.execute_reply":"2023-09-13T17:38:41.699468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Split train data using GroupKFolds on prompt_id\nSince test dataset will have new prompts, hence task becomes to train model to perform well on new/unseen prompts - https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/425409#2357563","metadata":{}},{"cell_type":"code","source":"gkf = GroupKFold(n_splits=CFG.n_splits) # Since 4 prompts in training set\n\nfor i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n    train.loc[val_index, \"fold\"] = i","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:41.701787Z","iopub.execute_input":"2023-09-13T17:38:41.702293Z","iopub.status.idle":"2023-09-13T17:38:41.721320Z","shell.execute_reply.started":"2023-09-13T17:38:41.702257Z","shell.execute_reply":"2023-09-13T17:38:41.720476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"fold\").count()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:41.813072Z","iopub.execute_input":"2023-09-13T17:38:41.813344Z","iopub.status.idle":"2023-09-13T17:38:41.837037Z","shell.execute_reply.started":"2023-09-13T17:38:41.813313Z","shell.execute_reply":"2023-09-13T17:38:41.836113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Prepare huggingface dataset\nRef - https://huggingface.co/docs/datasets/v2.14.5/en/tabular_load#pandas-dataframes","metadata":{}},{"cell_type":"code","source":"target_cols = ['content','wording']\ntext_cols = ['text']","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:42.918914Z","iopub.execute_input":"2023-09-13T17:38:42.919176Z","iopub.status.idle":"2023-09-13T17:38:42.924132Z","shell.execute_reply.started":"2023-09-13T17:38:42.919145Z","shell.execute_reply":"2023-09-13T17:38:42.923051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train[text_cols + target_cols + ['fold']])\ntest_dataset = Dataset.from_pandas(test[text_cols])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:43.257151Z","iopub.execute_input":"2023-09-13T17:38:43.257439Z","iopub.status.idle":"2023-09-13T17:38:43.292626Z","shell.execute_reply.started":"2023-09-13T17:38:43.257391Z","shell.execute_reply":"2023-09-13T17:38:43.291735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:43.692330Z","iopub.execute_input":"2023-09-13T17:38:43.693277Z","iopub.status.idle":"2023-09-13T17:38:43.699531Z","shell.execute_reply.started":"2023-09-13T17:38:43.693235Z","shell.execute_reply":"2023-09-13T17:38:43.698637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:44.543356Z","iopub.execute_input":"2023-09-13T17:38:44.544174Z","iopub.status.idle":"2023-09-13T17:38:44.808395Z","shell.execute_reply.started":"2023-09-13T17:38:44.544137Z","shell.execute_reply":"2023-09-13T17:38:44.807497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Model and Metrics","metadata":{}},{"cell_type":"markdown","source":"#### Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(f'/kaggle/input/{CFG.model_name}')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:46.297616Z","iopub.execute_input":"2023-09-13T17:38:46.297883Z","iopub.status.idle":"2023-09-13T17:38:47.506961Z","shell.execute_reply.started":"2023-09-13T17:38:46.297854Z","shell.execute_reply":"2023-09-13T17:38:47.505912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.encode_plus(train_dataset[0]['text'])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:47.509120Z","iopub.execute_input":"2023-09-13T17:38:47.509369Z","iopub.status.idle":"2023-09-13T17:38:47.520766Z","shell.execute_reply.started":"2023-09-13T17:38:47.509337Z","shell.execute_reply":"2023-09-13T17:38:47.519782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:47.522719Z","iopub.execute_input":"2023-09-13T17:38:47.522979Z","iopub.status.idle":"2023-09-13T17:38:47.532365Z","shell.execute_reply.started":"2023-09-13T17:38:47.522946Z","shell.execute_reply":"2023-09-13T17:38:47.531394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Figure out generating labels columns for batch of thousand\ndef generate_tokens(examples: pd.DataFrame,mode='train'):\n    encodings = tokenizer(examples['text'],truncation=True,max_length=CFG.max_length,return_tensors='np')\n    if mode == 'test':\n        return encodings\n    labels = np.column_stack((examples['content'],examples['wording']))\n    return {**encodings, \"labels\": labels}\n\n# tokenized_train_dataset = train_dataset.map(generate_tokens,batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:47.536842Z","iopub.execute_input":"2023-09-13T17:38:47.537036Z","iopub.status.idle":"2023-09-13T17:38:47.543253Z","shell.execute_reply.started":"2023-09-13T17:38:47.537013Z","shell.execute_reply":"2023-09-13T17:38:47.542321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenized_train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:47.959910Z","iopub.execute_input":"2023-09-13T17:38:47.961592Z","iopub.status.idle":"2023-09-13T17:38:47.966080Z","shell.execute_reply.started":"2023-09-13T17:38:47.961546Z","shell.execute_reply":"2023-09-13T17:38:47.965108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Config","metadata":{}},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(f'/kaggle/input/{CFG.model_name}')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:49.071090Z","iopub.execute_input":"2023-09-13T17:38:49.071590Z","iopub.status.idle":"2023-09-13T17:38:49.079857Z","shell.execute_reply.started":"2023-09-13T17:38:49.071554Z","shell.execute_reply":"2023-09-13T17:38:49.078914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# config","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-13T17:38:49.542042Z","iopub.execute_input":"2023-09-13T17:38:49.542310Z","iopub.status.idle":"2023-09-13T17:38:49.547011Z","shell.execute_reply.started":"2023-09-13T17:38:49.542281Z","shell.execute_reply":"2023-09-13T17:38:49.546094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config.update({\n    \"num_labels\": 2,\n    \"problem_type\": 'regression',\n    \"hidden_dropout_prob\": CFG.hidden_dropout_prob,\n    \"attention_probs_dropout_prob\": CFG.attention_probs_dropout_prob\n})","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:50.212400Z","iopub.execute_input":"2023-09-13T17:38:50.213396Z","iopub.status.idle":"2023-09-13T17:38:50.219065Z","shell.execute_reply.started":"2023-09-13T17:38:50.213351Z","shell.execute_reply":"2023-09-13T17:38:50.217656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:51.123910Z","iopub.execute_input":"2023-09-13T17:38:51.124172Z","iopub.status.idle":"2023-09-13T17:38:51.132209Z","shell.execute_reply.started":"2023-09-13T17:38:51.124142Z","shell.execute_reply":"2023-09-13T17:38:51.131127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model","metadata":{}},{"cell_type":"code","source":"# model = AutoModel.from_pretrained(f'/kaggle/input/{CFG.model_name}',config=config)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:52.272325Z","iopub.execute_input":"2023-09-13T17:38:52.272926Z","iopub.status.idle":"2023-09-13T17:38:52.277818Z","shell.execute_reply.started":"2023-09-13T17:38:52.272888Z","shell.execute_reply":"2023-09-13T17:38:52.276837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:38:52.609407Z","iopub.execute_input":"2023-09-13T17:38:52.610009Z","iopub.status.idle":"2023-09-13T17:38:52.614951Z","shell.execute_reply.started":"2023-09-13T17:38:52.609974Z","shell.execute_reply":"2023-09-13T17:38:52.614089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(f'/kaggle/input/{CFG.model_name}',config=config)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:40:45.598372Z","iopub.execute_input":"2023-09-13T17:40:45.599367Z","iopub.status.idle":"2023-09-13T17:40:50.252625Z","shell.execute_reply.started":"2023-09-13T17:40:45.599322Z","shell.execute_reply":"2023-09-13T17:40:50.251624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:40:50.254640Z","iopub.execute_input":"2023-09-13T17:40:50.254907Z","iopub.status.idle":"2023-09-13T17:40:50.266464Z","shell.execute_reply.started":"2023-09-13T17:40:50.254872Z","shell.execute_reply":"2023-09-13T17:40:50.265464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Can see that a pooling layer followed by Linear Layer with 2 outputs was added to base model","metadata":{}},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:39:11.701331Z","iopub.execute_input":"2023-09-13T17:39:11.701953Z","iopub.status.idle":"2023-09-13T17:39:11.966375Z","shell.execute_reply.started":"2023-09-13T17:39:11.701916Z","shell.execute_reply":"2023-09-13T17:39:11.965339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Metrics - MCRMSE","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    rmse = mean_squared_error(labels, predictions, squared=False)\n    return {\"rmse\": rmse}\n\ndef compute_mcrmse(eval_pred):\n    \"\"\"\n    Calculates mean columnwise root mean squared error\n    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n    \"\"\"\n    preds, labels = eval_pred\n\n    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n    mcrmse = np.mean(col_rmse)\n\n    return {\n        \"content_rmse\": col_rmse[0],\n        \"wording_rmse\": col_rmse[1],\n        \"mcrmse\": mcrmse,\n    }\n\ndef compt_score(content_true, content_pred, wording_true, wording_pred):\n    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n    \n    return (content_score + wording_score)/2","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:39:13.337741Z","iopub.execute_input":"2023-09-13T17:39:13.338241Z","iopub.status.idle":"2023-09-13T17:39:13.347462Z","shell.execute_reply.started":"2023-09-13T17:39:13.338205Z","shell.execute_reply":"2023-09-13T17:39:13.346469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train using GroupKFold for CV","metadata":{}},{"cell_type":"code","source":"train_collator = DataCollatorWithPadding(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:39:15.104116Z","iopub.execute_input":"2023-09-13T17:39:15.104724Z","iopub.status.idle":"2023-09-13T17:39:15.108920Z","shell.execute_reply.started":"2023-09-13T17:39:15.104685Z","shell.execute_reply":"2023-09-13T17:39:15.107930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_fold_dir = './'\n# training_args = TrainingArguments(\n#     output_dir = model_fold_dir,\n#     report_to='none',\n#     load_best_model_at_end=True, # select best model\n#     learning_rate=CFG.learning_rate,\n#     per_device_train_batch_size=CFG.batch_size,\n#     per_device_eval_batch_size=CFG.batch_size,\n#     num_train_epochs=CFG.num_train_epochs,\n#     weight_decay=CFG.weight_decay,\n#     greater_is_better=False,\n#     metric_for_best_model=\"mcrmse\",\n#     save_strategy='no', # \"steps\",\n#     evaluation_strategy='no' #\"steps\",\n# )\n## report_to='none' to avoid wandb login - https://discuss.huggingface.co/t/how-to-turn-wandb-off-in-trainer/6237/2\n## both save strategy and eval strategy have to match","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:39:17.762922Z","iopub.execute_input":"2023-09-13T17:39:17.763548Z","iopub.status.idle":"2023-09-13T17:39:17.768163Z","shell.execute_reply.started":"2023-09-13T17:39:17.763511Z","shell.execute_reply":"2023-09-13T17:39:17.767276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### GPU","metadata":{}},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\ncuda.empty_cache()\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:39:18.371995Z","iopub.execute_input":"2023-09-13T17:39:18.372774Z","iopub.status.idle":"2023-09-13T17:39:18.404654Z","shell.execute_reply.started":"2023-09-13T17:39:18.372722Z","shell.execute_reply":"2023-09-13T17:39:18.403671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_gpu = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:39:19.918388Z","iopub.execute_input":"2023-09-13T17:39:19.918975Z","iopub.status.idle":"2023-09-13T17:39:19.923398Z","shell.execute_reply.started":"2023-09-13T17:39:19.918941Z","shell.execute_reply":"2023-09-13T17:39:19.922292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_gpu","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:39:20.179782Z","iopub.execute_input":"2023-09-13T17:39:20.180057Z","iopub.status.idle":"2023-09-13T17:39:20.184297Z","shell.execute_reply.started":"2023-09-13T17:39:20.180027Z","shell.execute_reply":"2023-09-13T17:39:20.183271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainer = Trainer(\n#     model = model_gpu,\n#     train_dataset = tokenized_train_dataset,\n#     args = training_args,\n#     data_collator = train_collator,\n#     tokenizer = tokenizer,\n#     compute_metrics = compute_mcrmse    \n# )","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:39:20.456267Z","iopub.execute_input":"2023-09-13T17:39:20.456857Z","iopub.status.idle":"2023-09-13T17:39:20.461440Z","shell.execute_reply.started":"2023-09-13T17:39:20.456821Z","shell.execute_reply":"2023-09-13T17:39:20.460587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:45:41.491945Z","iopub.execute_input":"2023-09-13T17:45:41.492216Z","iopub.status.idle":"2023-09-13T17:45:41.808935Z","shell.execute_reply.started":"2023-09-13T17:45:41.492187Z","shell.execute_reply":"2023-09-13T17:45:41.808024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:45:43.657930Z","iopub.execute_input":"2023-09-13T17:45:43.658929Z","iopub.status.idle":"2023-09-13T17:45:43.725144Z","shell.execute_reply.started":"2023-09-13T17:45:43.658883Z","shell.execute_reply":"2023-09-13T17:45:43.724210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training loop","metadata":{}},{"cell_type":"code","source":"# delete old model files\nif os.path.exists('deberta-v3-large'):\n    shutil.rmtree('deberta-v3-large')\nos.mkdir('deberta-v3-large')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:45:48.016985Z","iopub.execute_input":"2023-09-13T17:45:48.017266Z","iopub.status.idle":"2023-09-13T17:45:48.023339Z","shell.execute_reply.started":"2023-09-13T17:45:48.017238Z","shell.execute_reply":"2023-09-13T17:45:48.022238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(CFG.n_splits):\n    print(f\"Fold: {fold}\")\n    fold_train_data = train[train['fold']!=fold]\n    fold_val_data = train[train['fold']==fold]\n    fold_train_dataset = Dataset.from_pandas(fold_train_data[text_cols + target_cols])\n    fold_val_dataset = Dataset.from_pandas(fold_val_data[text_cols + target_cols])\n    fold_train_tokenized = fold_train_dataset.map(generate_tokens,batched=True)\n    fold_val_tokenized = fold_val_dataset.map(generate_tokens,batched=True)\n    print(f\"Number of training examples: {fold_train_tokenized.num_rows}\")\n    print(f\"Number of validation examples: {fold_val_tokenized.num_rows}\")\n    gc.collect()\n    \n    model = AutoModelForSequenceClassification.from_pretrained(f'/kaggle/input/{CFG.model_name}',config=config)\n    model_gpu = model.to(device)\n    \n    model_dir = f\"{CFG.model_name}/fold_{fold}\"\n    model_fold_dir = os.path.join(model_dir, str(fold))\n    \n    training_args = TrainingArguments(\n        output_dir = model_fold_dir,\n        report_to='none',\n        load_best_model_at_end=True, # select best model\n        learning_rate=CFG.learning_rate,\n        per_device_train_batch_size=CFG.batch_size,\n        per_device_eval_batch_size=CFG.batch_size,\n        num_train_epochs=CFG.num_train_epochs,\n        weight_decay=CFG.weight_decay,\n        greater_is_better=False,\n        metric_for_best_model=\"mcrmse\",\n        save_strategy='steps',\n        evaluation_strategy='steps',\n        save_total_limit=1,\n        gradient_accumulation_steps=4,\n        gradient_checkpointing=True,\n        optim='adafactor',\n#         fp16=True,\n        save_steps = CFG.save_steps,\n        eval_steps = CFG.save_steps\n    )\n    \n    trainer = Trainer(\n        model = model_gpu,\n        train_dataset = fold_train_tokenized,\n        eval_dataset = fold_val_tokenized,\n        args = training_args,\n        data_collator = train_collator,\n        tokenizer = tokenizer,\n        compute_metrics = compute_mcrmse    \n    )\n    \n    trainer.train()\n    \n    model_gpu.save_pretrained(model_dir)\n    tokenizer.save_pretrained(model_dir)\n    model_gpu.cpu()\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T17:46:17.707193Z","iopub.execute_input":"2023-09-13T17:46:17.707494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Combine these outputs with numerical text based feats and feed into LGBM","metadata":{}},{"cell_type":"markdown","source":"#### Add each fold model predictions to training data","metadata":{}},{"cell_type":"code","source":"# for fold in range(CFG.n_splits):\n#     val_data = train[train['fold']==fold]\n#     val_dataset = Dataset.from_pandas(val_data[text_cols+target_cols])\n#     tokenized_val_dataset = val_dataset.map(generate_tokens,batched=True)\n    \n#     model_dir = f\"{CFG.model_name}/fold_{fold}\"\n#     model_fold_dir = os.path.join(model_dir, str(fold))\n\n#     model = AutoModelForSequenceClassification.from_pretrained(model_dir)    \n#     model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n#     model_gpu = model.to(device)\n    \n#     test_args = TrainingArguments(\n#         output_dir=  model_fold_dir,\n#         do_train = False,\n#         do_predict = True,\n#         per_device_eval_batch_size = CFG.batch_size,   \n#         dataloader_drop_last = False,\n#         fp16=True\n#     )\n    \n#     infer = Trainer(\n#         model = model_gpu,\n#         args = test_args,\n#         tokenizer = tokenizer,\n#         data_collator = train_collator\n#     )\n    \n#     preds = infer.predict(tokenized_val_dataset)[0]\n#     train.loc[val_data.index,\"content_pred\"] = preds[:,0]\n#     train.loc[val_data.index,\"wording_pred\"] = preds[:,1]\n    \n#     model_gpu.cpu()\n#     del model_gpu\n#     gc.collect()\n#     torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:14:36.709191Z","iopub.execute_input":"2023-09-13T13:14:36.710085Z","iopub.status.idle":"2023-09-13T13:16:16.675649Z","shell.execute_reply.started":"2023-09-13T13:14:36.710048Z","shell.execute_reply":"2023-09-13T13:16:16.674667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:16:16.678283Z","iopub.execute_input":"2023-09-13T13:16:16.678564Z","iopub.status.idle":"2023-09-13T13:16:16.696825Z","shell.execute_reply.started":"2023-09-13T13:16:16.678526Z","shell.execute_reply":"2023-09-13T13:16:16.695722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import re\n# # Text cleaning function\n# def clean_text(text):\n#     text = text.lower()\n#     text = re.sub(r'\\n', ' ', text)\n#     text = re.sub(r'\\W', ' ', text)\n#     text = re.sub(r'\\s+', ' ', text)\n#     return text","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:16:16.698483Z","iopub.execute_input":"2023-09-13T13:16:16.698848Z","iopub.status.idle":"2023-09-13T13:16:16.708438Z","shell.execute_reply.started":"2023-09-13T13:16:16.698813Z","shell.execute_reply":"2023-09-13T13:16:16.707535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Enhanced preprocessing function\n# def preprocess_data(data: pd.DataFrame):\n#     merged_df = data.copy()\n#     text_columns = ['prompt_question', 'prompt_title', 'prompt_text', 'text']\n#     for column in text_columns:\n#         merged_df[column] = merged_df[column].apply(clean_text)\n#     merged_df['prompt_length'] = merged_df['prompt_text'].apply(len)\n#     merged_df['summary_length'] = merged_df['text'].apply(len)\n# #     merged_df['prompt_unique_words_cnt'] = merged_df['prompt_text'].apply(lambda x: len(set(x.split())))\n# #     merged_df['summary_unique_words_cnt'] = merged_df['text'].apply(lambda x: len(set(x.split())))\n# #     merged_df['summary_stopwords_cnt'] = merged_df['text'].apply(lambda x: count_stopwords(x))\n# #     merged_df['num_typos'] = merged_df['text'].apply(lambda x: get_num_typos(x))\n# #     merged_df['length_ratio'] = merged_df['summary_length']/merged_df['prompt_length']\n#     return merged_df","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:16:16.710494Z","iopub.execute_input":"2023-09-13T13:16:16.710980Z","iopub.status.idle":"2023-09-13T13:16:16.723263Z","shell.execute_reply.started":"2023-09-13T13:16:16.710947Z","shell.execute_reply":"2023-09-13T13:16:16.722214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# enh_train = preprocess_data(train)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:16:16.724638Z","iopub.execute_input":"2023-09-13T13:16:16.725108Z","iopub.status.idle":"2023-09-13T13:16:22.086692Z","shell.execute_reply.started":"2023-09-13T13:16:16.725072Z","shell.execute_reply":"2023-09-13T13:16:22.085759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# enh_text_cols = ['prompt_id', 'student_id', 'prompt_question', 'prompt_title', 'prompt_text', 'text']\n# cols_to_drop = enh_text_cols + target_cols + ['fold']","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:20:54.331689Z","iopub.execute_input":"2023-09-13T13:20:54.331970Z","iopub.status.idle":"2023-09-13T13:20:54.337603Z","shell.execute_reply.started":"2023-09-13T13:20:54.331939Z","shell.execute_reply":"2023-09-13T13:20:54.336667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# enh_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:20:54.691849Z","iopub.execute_input":"2023-09-13T13:20:54.692825Z","iopub.status.idle":"2023-09-13T13:20:54.713699Z","shell.execute_reply.started":"2023-09-13T13:20:54.692787Z","shell.execute_reply":"2023-09-13T13:20:54.712774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from xgboost import XGBRegressor\n# import lightgbm as lgb\n# model_dict = {}\n# for target in target_cols:\n#     models = []\n#     for fold in range(CFG.n_splits):\n#         enh_train_data = enh_train[enh_train['fold']!=fold]\n#         enh_val_data = enh_train[enh_train['fold']==fold]\n#         fold_X_train = enh_train_data.drop(columns=cols_to_drop)\n#         fold_y_train = enh_train_data[target]\n#         fold_X_val = enh_val_data.drop(columns=cols_to_drop)\n#         fold_y_val = enh_val_data[target]\n        \n#         dtrain = lgb.Dataset(fold_X_train, label=fold_y_train)\n#         dval = lgb.Dataset(fold_X_val, label=fold_y_val)\n\n#         params = {\n#                   'boosting_type': 'gbdt',\n#                   'random_state': 42,\n#                   'objective': 'regression',\n#                   'metric': 'rmse',\n#                   'learning_rate': 0.05,\n#                   }\n\n#         evaluation_results = {}\n#         model = lgb.train(params,\n#                           num_boost_round=10000,\n#                             #categorical_feature = categorical_features,\n#                           valid_names=['train', 'valid'],\n#                           train_set=dtrain,\n#                           valid_sets=dval,\n#                           callbacks=[\n#                               lgb.early_stopping(stopping_rounds=30, verbose=True),\n#                                lgb.log_evaluation(100),\n#                               lgb.callback.record_evaluation(evaluation_results)\n#                             ],\n#                           )\n#         models.append(model)\n#     model_dict[target] = models","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:22:10.373893Z","iopub.execute_input":"2023-09-13T13:22:10.374167Z","iopub.status.idle":"2023-09-13T13:22:11.324243Z","shell.execute_reply.started":"2023-09-13T13:22:10.374136Z","shell.execute_reply":"2023-09-13T13:22:11.323218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # cv\n# rmses = []\n\n# for target in target_cols:\n#     models = model_dict[target]\n\n#     preds = []\n#     trues = []\n    \n#     for fold, model in enumerate(models):\n#         X_eval_cv = enh_train[enh_train[\"fold\"] == fold].drop(columns=cols_to_drop)\n#         y_eval_cv = enh_train[enh_train[\"fold\"] == fold][target]\n\n#         pred = model.predict(X_eval_cv)\n\n#         trues.extend(y_eval_cv)\n#         preds.extend(pred)\n    \n#     rmse = np.sqrt(mean_squared_error(trues, preds))\n#     print(f\"{target}_rmse : {rmse}\")\n#     rmses = rmses + [rmse]\n\n# print(f\"mcrmse : {sum(rmses) / len(rmses)}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:24:10.304917Z","iopub.execute_input":"2023-09-13T13:24:10.305199Z","iopub.status.idle":"2023-09-13T13:24:10.406449Z","shell.execute_reply.started":"2023-09-13T13:24:10.305169Z","shell.execute_reply":"2023-09-13T13:24:10.404593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"# preds = trainer.predict(tokenized_test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_args = TrainingArguments(\n#             output_dir=  model_fold_dir,\n#             do_train = False,\n#             do_predict = True,\n#             per_device_eval_batch_size = 4,   \n#             dataloader_drop_last = False\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# infer = Trainer(\n#     model = model_gpu,\n#     args = test_args,\n#     tokenizer = tokenizer,\n#     data_collator = train_collator\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds2 = infer.predict(tokenized_test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds2[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_dataset = test_dataset.map(lambda x: generate_tokens(x,'test'),batched=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(CFG.n_splits):\n    model_dir = f\"{CFG.model_name}/fold_{fold}\"\n    model_fold_dir = os.path.join(model_dir, str(fold))\n\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)    \n    model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n    model_gpu = model.to(device)\n    \n    test_args = TrainingArguments(\n        output_dir=  model_fold_dir,\n        do_train = False,\n        do_predict = True,\n        per_device_eval_batch_size = 4,   \n        dataloader_drop_last = False,\n        fp16=True\n    )\n    \n    infer = Trainer(\n        model = model_gpu,\n        args = test_args,\n        tokenizer = tokenizer,\n        data_collator = train_collator\n    )\n    \n    preds = infer.predict(tokenized_test_dataset)[0]\n    test[f\"{target_cols[0]}_{fold}\"] = preds[:,0]\n    test[f\"{target_cols[1]}_{fold}\"] = preds[:,1]\n    \n    model_gpu.cpu()\n    del model_gpu\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Take mean of predictions across all folds\ntest[target_cols[0]] = test[[f\"{target_cols[0]}_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\ntest[target_cols[1]] = test[[f\"{target_cols[1]}_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"df_submission = pd.DataFrame()\ndf_submission['student_id'] = test['student_id']\ndf_submission['content'] = 0\ndf_submission['wording'] = 0\ndf_submission[target_cols[0]] = test[target_cols[0]]\ndf_submission[target_cols[1]] = test[target_cols[1]]\ndf_submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Possible Next Steps for model improvement\n1. Have used base model. From multiple comments, it might be worth considering using v3large model - https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/424330\n2. Do some text cleaning before generating embeddings. \n3. Consider not just text, but also other text cols for generating embeddings. \n4. Add some more numerical features before using LGBM like semantic similarity - https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/436187","metadata":{}}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}