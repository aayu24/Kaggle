{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-13T05:50:54.838629Z","iopub.execute_input":"2023-09-13T05:50:54.839575Z","iopub.status.idle":"2023-09-13T05:50:55.196486Z","shell.execute_reply.started":"2023-09-13T05:50:54.839540Z","shell.execute_reply":"2023-09-13T05:50:55.194532Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/debertav3base/rust_model.ot\n/kaggle/input/debertav3base/spm.model\n/kaggle/input/debertav3base/config.json\n/kaggle/input/debertav3base/tf_model.h5\n/kaggle/input/debertav3base/tokenizer_config.json\n/kaggle/input/debertav3base/pytorch_model.bin\n/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv\n/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\n/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\n/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\n/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport transformers\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset\nfrom transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import mean_squared_error\nimport torch\nfrom sklearn.model_selection import KFold, GroupKFold","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:56:23.892143Z","iopub.execute_input":"2023-09-13T05:56:23.892851Z","iopub.status.idle":"2023-09-13T05:56:36.285752Z","shell.execute_reply.started":"2023-09-13T05:56:23.892820Z","shell.execute_reply":"2023-09-13T05:56:36.284667Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport os\nimport warnings\nimport logging\nimport shutil\nfrom tqdm import tqdm\nfrom datasets import disable_progress_bar\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \ndisable_progress_bar()\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:56:36.287605Z","iopub.execute_input":"2023-09-13T05:56:36.288018Z","iopub.status.idle":"2023-09-13T05:56:36.573826Z","shell.execute_reply.started":"2023-09-13T05:56:36.287976Z","shell.execute_reply":"2023-09-13T05:56:36.572770Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    model_name=\"debertav3base\"\n    learning_rate=1.5e-5\n    weight_decay=0.02\n    hidden_dropout_prob=0.007\n    attention_probs_dropout_prob=0.007\n    num_train_epochs=5\n    n_splits=4\n    batch_size=8\n    random_seed=42\n    save_steps=500\n    max_length=512","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:56:36.575336Z","iopub.execute_input":"2023-09-13T05:56:36.575994Z","iopub.status.idle":"2023-09-13T05:56:36.586511Z","shell.execute_reply.started":"2023-09-13T05:56:36.575961Z","shell.execute_reply":"2023-09-13T05:56:36.585661Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# SEED 42\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything(CFG.random_seed)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:56:36.588540Z","iopub.execute_input":"2023-09-13T05:56:36.588737Z","iopub.status.idle":"2023-09-13T05:56:36.602473Z","shell.execute_reply.started":"2023-09-13T05:56:36.588715Z","shell.execute_reply":"2023-09-13T05:56:36.601599Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n\nprompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\nprompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\nsummaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\nsummaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\nsample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:56:36.606008Z","iopub.execute_input":"2023-09-13T05:56:36.606208Z","iopub.status.idle":"2023-09-13T05:56:36.726474Z","shell.execute_reply.started":"2023-09-13T05:56:36.606185Z","shell.execute_reply":"2023-09-13T05:56:36.725563Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train = pd.merge(prompts_train,summaries_train,on='prompt_id')\ntest=pd.merge(prompts_test,summaries_test,on='prompt_id')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:56:36.727774Z","iopub.execute_input":"2023-09-13T05:56:36.728032Z","iopub.status.idle":"2023-09-13T05:56:36.758521Z","shell.execute_reply.started":"2023-09-13T05:56:36.727991Z","shell.execute_reply":"2023-09-13T05:56:36.757443Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:56:36.761977Z","iopub.execute_input":"2023-09-13T05:56:36.762187Z","iopub.status.idle":"2023-09-13T05:56:36.781309Z","shell.execute_reply.started":"2023-09-13T05:56:36.762162Z","shell.execute_reply":"2023-09-13T05:56:36.780303Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"  prompt_id                                    prompt_question prompt_title  \\\n0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n\n                                         prompt_text    student_id  \\\n0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n\n                                                text   content   wording  \n0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>00791789cc1f</td>\n      <td>1 element of an ideal tragedy is that it shoul...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>0086ef22de8f</td>\n      <td>The three elements of an ideal tragedy are:  H...</td>\n      <td>-0.970237</td>\n      <td>-0.417058</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:56:38.229453Z","iopub.execute_input":"2023-09-13T05:56:38.229722Z","iopub.status.idle":"2023-09-13T05:56:38.242851Z","shell.execute_reply.started":"2023-09-13T05:56:38.229688Z","shell.execute_reply":"2023-09-13T05:56:38.241718Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"  prompt_id prompt_question     prompt_title       prompt_text    student_id  \\\n0    abc123    Summarize...  Example Title 1  Heading\\nText...  000000ffffff   \n1    abc123    Summarize...  Example Title 1  Heading\\nText...  222222cccccc   \n\n             text  \n0  Example text 1  \n1  Example text 3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>000000ffffff</td>\n      <td>Example text 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>222222cccccc</td>\n      <td>Example text 3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Split train data using GroupKFolds on prompt_id\nSince test dataset will have new prompts, hence task becomes to train model to perform well on new/unseen prompts - https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/425409#2357563","metadata":{}},{"cell_type":"code","source":"gkf = GroupKFold(n_splits=CFG.n_splits) # Since 4 prompts in training set\n\nfor i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n    train.loc[val_index, \"fold\"] = i","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:57:32.383437Z","iopub.execute_input":"2023-09-13T05:57:32.383709Z","iopub.status.idle":"2023-09-13T05:57:32.401404Z","shell.execute_reply.started":"2023-09-13T05:57:32.383682Z","shell.execute_reply":"2023-09-13T05:57:32.400520Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"fold\").count()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:00:35.813902Z","iopub.execute_input":"2023-09-13T06:00:35.814181Z","iopub.status.idle":"2023-09-13T06:00:35.836260Z","shell.execute_reply.started":"2023-09-13T06:00:35.814150Z","shell.execute_reply":"2023-09-13T06:00:35.835297Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"      prompt_id  prompt_question  prompt_title  prompt_text  student_id  text  \\\nfold                                                                            \n0.0        2057             2057          2057         2057        2057  2057   \n1.0        2009             2009          2009         2009        2009  2009   \n2.0        1996             1996          1996         1996        1996  1996   \n3.0        1103             1103          1103         1103        1103  1103   \n\n      content  wording  \nfold                    \n0.0      2057     2057  \n1.0      2009     2009  \n2.0      1996     1996  \n3.0      1103     1103  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n    <tr>\n      <th>fold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.0</th>\n      <td>2057</td>\n      <td>2057</td>\n      <td>2057</td>\n      <td>2057</td>\n      <td>2057</td>\n      <td>2057</td>\n      <td>2057</td>\n      <td>2057</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>2009</td>\n      <td>2009</td>\n      <td>2009</td>\n      <td>2009</td>\n      <td>2009</td>\n      <td>2009</td>\n      <td>2009</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>1996</td>\n      <td>1996</td>\n      <td>1996</td>\n      <td>1996</td>\n      <td>1996</td>\n      <td>1996</td>\n      <td>1996</td>\n      <td>1996</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>1103</td>\n      <td>1103</td>\n      <td>1103</td>\n      <td>1103</td>\n      <td>1103</td>\n      <td>1103</td>\n      <td>1103</td>\n      <td>1103</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Prepare huggingface dataset\nRef - https://huggingface.co/docs/datasets/v2.14.5/en/tabular_load#pandas-dataframes","metadata":{}},{"cell_type":"code","source":"target_cols = ['content','wording']\ntext_cols = ['text']","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:00:48.947148Z","iopub.execute_input":"2023-09-13T06:00:48.947477Z","iopub.status.idle":"2023-09-13T06:00:48.952894Z","shell.execute_reply.started":"2023-09-13T06:00:48.947447Z","shell.execute_reply":"2023-09-13T06:00:48.951642Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train[text_cols + target_cols + ['fold']])\ntest_dataset = Dataset.from_pandas(test[text_cols])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:17:01.518086Z","iopub.execute_input":"2023-09-13T06:17:01.518386Z","iopub.status.idle":"2023-09-13T06:17:01.541194Z","shell.execute_reply.started":"2023-09-13T06:17:01.518356Z","shell.execute_reply":"2023-09-13T06:17:01.540121Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"train_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:17:02.710024Z","iopub.execute_input":"2023-09-13T06:17:02.710301Z","iopub.status.idle":"2023-09-13T06:17:02.717013Z","shell.execute_reply.started":"2023-09-13T06:17:02.710272Z","shell.execute_reply":"2023-09-13T06:17:02.716174Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['text', 'content', 'wording', 'fold'],\n     num_rows: 7165\n }),\n Dataset({\n     features: ['text'],\n     num_rows: 4\n }))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Define Model and Metrics","metadata":{}},{"cell_type":"markdown","source":"#### Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(f'/kaggle/input/{CFG.model_name}')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:01:07.074153Z","iopub.execute_input":"2023-09-13T06:01:07.074743Z","iopub.status.idle":"2023-09-13T06:01:08.283144Z","shell.execute_reply.started":"2023-09-13T06:01:07.074710Z","shell.execute_reply":"2023-09-13T06:01:08.282139Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"tokenizer.encode_plus(train_dataset[0]['text'])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:01:08.285150Z","iopub.execute_input":"2023-09-13T06:01:08.285423Z","iopub.status.idle":"2023-09-13T06:01:08.297729Z","shell.execute_reply.started":"2023-09-13T06:01:08.285390Z","shell.execute_reply":"2023-09-13T06:01:08.296878Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [1, 376, 3036, 265, 299, 1949, 8948, 269, 272, 278, 403, 282, 6128, 277, 266, 1739, 741, 260, 1811, 3036, 265, 299, 1949, 8948, 269, 272, 278, 403, 364, 286, 311, 872, 889, 260, 279, 437, 3036, 265, 299, 1949, 8948, 269, 272, 278, 403, 286, 266, 1664, 3676, 4278, 263, 299, 3680, 21419, 270, 462, 397, 263, 966, 260, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:17:08.403339Z","iopub.execute_input":"2023-09-13T06:17:08.403602Z","iopub.status.idle":"2023-09-13T06:17:08.410696Z","shell.execute_reply.started":"2023-09-13T06:17:08.403573Z","shell.execute_reply":"2023-09-13T06:17:08.409687Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"{'text': '1 element of an ideal tragedy is that it should be arranged on a complex plan.  Another element of an ideal tragedy is that it should only have one main issue. The last element of an ideal tragedy is that it should have a double thread plot and an opposite catastrophe for both good and bad.',\n 'content': -0.210613934166593,\n 'wording': -0.471414826967448,\n 'fold': 0.0}"},"metadata":{}}]},{"cell_type":"code","source":"## Figure out generating labels columns for batch of thousand\ndef generate_tokens(examples: pd.DataFrame,mode='train'):\n    encodings = tokenizer(examples['text'],truncation=True,max_length=CFG.max_length,return_tensors='np')\n    if mode == 'test':\n        return encodings\n    labels = np.column_stack((examples['content'],examples['wording']))\n    return {**encodings, \"labels\": labels, \"fold\": examples['fold']}\n\ntokenized_train_dataset = train_dataset.map(generate_tokens,batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:17:11.648413Z","iopub.execute_input":"2023-09-13T06:17:11.648681Z","iopub.status.idle":"2023-09-13T06:17:14.709171Z","shell.execute_reply.started":"2023-09-13T06:17:11.648653Z","shell.execute_reply":"2023-09-13T06:17:14.708275Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"tokenized_train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:17:17.301249Z","iopub.execute_input":"2023-09-13T06:17:17.301595Z","iopub.status.idle":"2023-09-13T06:17:17.309710Z","shell.execute_reply.started":"2023-09-13T06:17:17.301551Z","shell.execute_reply":"2023-09-13T06:17:17.308352Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'content', 'wording', 'fold', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n    num_rows: 7165\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_test_dataset = test_dataset.map(lambda x: generate_tokens(x,'test'),batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:17:28.952126Z","iopub.execute_input":"2023-09-13T06:17:28.952971Z","iopub.status.idle":"2023-09-13T06:17:28.966477Z","shell.execute_reply.started":"2023-09-13T06:17:28.952920Z","shell.execute_reply":"2023-09-13T06:17:28.965484Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"tokenized_test_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:17:30.102109Z","iopub.execute_input":"2023-09-13T06:17:30.102709Z","iopub.status.idle":"2023-09-13T06:17:30.108515Z","shell.execute_reply.started":"2023-09-13T06:17:30.102674Z","shell.execute_reply":"2023-09-13T06:17:30.107638Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 4\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Config","metadata":{}},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(f'/kaggle/input/{CFG.model_name}')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:02:11.859143Z","iopub.execute_input":"2023-09-13T06:02:11.859806Z","iopub.status.idle":"2023-09-13T06:02:11.868438Z","shell.execute_reply.started":"2023-09-13T06:02:11.859770Z","shell.execute_reply":"2023-09-13T06:02:11.867549Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-13T06:02:12.158396Z","iopub.execute_input":"2023-09-13T06:02:12.158974Z","iopub.status.idle":"2023-09-13T06:02:12.166583Z","shell.execute_reply.started":"2023-09-13T06:02:12.158926Z","shell.execute_reply":"2023-09-13T06:02:12.165652Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"DebertaV2Config {\n  \"_name_or_path\": \"/kaggle/input/debertav3base\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"transformers_version\": \"4.33.0\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}"},"metadata":{}}]},{"cell_type":"code","source":"config.update({\n    \"num_labels\": 2,\n    \"problem_type\": 'regression',\n    \"hidden_dropout_prob\": CFG.hidden_dropout_prob,\n    \"attention_probs_dropout_prob\": CFG.attention_probs_dropout_prob\n})","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:03:15.333053Z","iopub.execute_input":"2023-09-13T06:03:15.333334Z","iopub.status.idle":"2023-09-13T06:03:15.338620Z","shell.execute_reply.started":"2023-09-13T06:03:15.333304Z","shell.execute_reply":"2023-09-13T06:03:15.337488Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:03:15.867059Z","iopub.execute_input":"2023-09-13T06:03:15.867657Z","iopub.status.idle":"2023-09-13T06:03:15.875279Z","shell.execute_reply.started":"2023-09-13T06:03:15.867621Z","shell.execute_reply":"2023-09-13T06:03:15.874273Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"DebertaV2Config {\n  \"_name_or_path\": \"/kaggle/input/debertav3base\",\n  \"attention_probs_dropout_prob\": 0.007,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.007,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"problem_type\": \"regression\",\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"transformers_version\": \"4.33.0\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Model","metadata":{}},{"cell_type":"code","source":"# model = AutoModel.from_pretrained(f'/kaggle/input/{CFG.model_name}',config=config)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:03:56.090151Z","iopub.execute_input":"2023-09-13T06:03:56.090748Z","iopub.status.idle":"2023-09-13T06:03:56.095021Z","shell.execute_reply.started":"2023-09-13T06:03:56.090714Z","shell.execute_reply":"2023-09-13T06:03:56.094036Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# model","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:03:56.327707Z","iopub.execute_input":"2023-09-13T06:03:56.328283Z","iopub.status.idle":"2023-09-13T06:03:56.332600Z","shell.execute_reply.started":"2023-09-13T06:03:56.328240Z","shell.execute_reply":"2023-09-13T06:03:56.331735Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(f'/kaggle/input/{CFG.model_name}',config=config)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:04:13.312929Z","iopub.execute_input":"2023-09-13T06:04:13.313184Z","iopub.status.idle":"2023-09-13T06:04:15.306206Z","shell.execute_reply.started":"2023-09-13T06:04:13.313155Z","shell.execute_reply":"2023-09-13T06:04:15.305279Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:04:15.308717Z","iopub.execute_input":"2023-09-13T06:04:15.309044Z","iopub.status.idle":"2023-09-13T06:04:15.320199Z","shell.execute_reply.started":"2023-09-13T06:04:15.309012Z","shell.execute_reply":"2023-09-13T06:04:15.319205Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"DebertaV2ForSequenceClassification(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): StableDropout()\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): StableDropout()\n  )\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): StableDropout()\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"> Can see that a pooling layer followed by Linear Layer with 2 outputs was added to base model","metadata":{}},{"cell_type":"markdown","source":"#### Metrics - MCRMSE","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    rmse = mean_squared_error(labels, predictions, squared=False)\n    return {\"rmse\": rmse}\n\ndef compute_mcrmse(eval_pred):\n    \"\"\"\n    Calculates mean columnwise root mean squared error\n    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n    \"\"\"\n    preds, labels = eval_pred\n\n    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n    mcrmse = np.mean(col_rmse)\n\n    return {\n        \"content_rmse\": col_rmse[0],\n        \"wording_rmse\": col_rmse[1],\n        \"mcrmse\": mcrmse,\n    }\n\ndef compt_score(content_true, content_pred, wording_true, wording_pred):\n    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n    \n    return (content_score + wording_score)/2","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:04:24.101387Z","iopub.execute_input":"2023-09-13T06:04:24.101693Z","iopub.status.idle":"2023-09-13T06:04:24.115852Z","shell.execute_reply.started":"2023-09-13T06:04:24.101661Z","shell.execute_reply":"2023-09-13T06:04:24.114936Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"## Train using GroupKFold for CV","metadata":{}},{"cell_type":"markdown","source":"<!-- ### Build Trainer -->","metadata":{}},{"cell_type":"code","source":"train_collator = DataCollatorWithPadding(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:04:30.994089Z","iopub.execute_input":"2023-09-13T06:04:30.994680Z","iopub.status.idle":"2023-09-13T06:04:30.998801Z","shell.execute_reply.started":"2023-09-13T06:04:30.994644Z","shell.execute_reply":"2023-09-13T06:04:30.997894Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# model_fold_dir = './'\n# training_args = TrainingArguments(\n#     output_dir = model_fold_dir,\n#     report_to='none',\n#     load_best_model_at_end=True, # select best model\n#     learning_rate=CFG.learning_rate,\n#     per_device_train_batch_size=CFG.batch_size,\n#     per_device_eval_batch_size=CFG.batch_size,\n#     num_train_epochs=CFG.num_train_epochs,\n#     weight_decay=CFG.weight_decay,\n#     greater_is_better=False,\n#     metric_for_best_model=\"mcrmse\",\n#     save_strategy='no', # \"steps\",\n#     evaluation_strategy='no' #\"steps\",\n# )\n## report_to='none' to avoid wandb login - https://discuss.huggingface.co/t/how-to-turn-wandb-off-in-trainer/6237/2\n## both save strategy and eval strategy have to match","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:11:49.638289Z","iopub.execute_input":"2023-09-13T06:11:49.638557Z","iopub.status.idle":"2023-09-13T06:11:49.645146Z","shell.execute_reply.started":"2023-09-13T06:11:49.638527Z","shell.execute_reply":"2023-09-13T06:11:49.644302Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"#### GPU","metadata":{}},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\ncuda.empty_cache()\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:04:41.299431Z","iopub.execute_input":"2023-09-13T06:04:41.299698Z","iopub.status.idle":"2023-09-13T06:04:41.305381Z","shell.execute_reply.started":"2023-09-13T06:04:41.299670Z","shell.execute_reply":"2023-09-13T06:04:41.304465Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# model_gpu = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:04:43.502498Z","iopub.execute_input":"2023-09-13T06:04:43.503333Z","iopub.status.idle":"2023-09-13T06:04:48.604637Z","shell.execute_reply.started":"2023-09-13T06:04:43.503295Z","shell.execute_reply":"2023-09-13T06:04:48.603537Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# model_gpu","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:04:48.606939Z","iopub.execute_input":"2023-09-13T06:04:48.607244Z","iopub.status.idle":"2023-09-13T06:04:48.618759Z","shell.execute_reply.started":"2023-09-13T06:04:48.607196Z","shell.execute_reply":"2023-09-13T06:04:48.617276Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"DebertaV2ForSequenceClassification(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): StableDropout()\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): StableDropout()\n  )\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): StableDropout()\n)"},"metadata":{}}]},{"cell_type":"code","source":"# trainer = Trainer(\n#     model = model_gpu,\n#     train_dataset = tokenized_train_dataset,\n#     args = training_args,\n#     data_collator = train_collator,\n#     tokenizer = tokenizer,\n#     compute_metrics = compute_mcrmse    \n# )","metadata":{"execution":{"iopub.status.busy":"2023-09-13T06:13:07.628442Z","iopub.execute_input":"2023-09-13T06:13:07.628709Z","iopub.status.idle":"2023-09-13T06:13:07.641720Z","shell.execute_reply.started":"2023-09-13T06:13:07.628682Z","shell.execute_reply":"2023-09-13T06:13:07.640785Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"#### Training loop","metadata":{}},{"cell_type":"code","source":"# delete old model files\nif os.path.exists(CFG.model_name):\n    shutil.rmtree(CFG.model_name)\nos.mkdir(CFG.model_name)\n\nfor fold in range(CFG.n_splits):\n    print(f\"Fold: {fold}\")\n    fold_train_data = train[train['fold']!=fold]\n    fold_val_data = train[train['fold']==fold]\n    fold_train_dataset = Dataset.from_pandas(fold_train_data[text_cols + target_cols])\n    fold_val_dataset = Dataset.from_pandas(fold_val_data[text_cols + target_cols])\n    fold_train_tokenized = fold_train_dataset.map(generate_tokens,batched=True)\n    fold_val_tokenized = fold_val_dataset.map(generate_tokens,batched=True)\n    print(f\"Number of training examples: {fold_train_tokenized.num_rows}\")\n    print(f\"Number of validation examples: {fold_val_tokenized.num_rows}\")\n    \n    model = AutoModelForSequenceClassification.from_pretrained(f'/kaggle/input/{CFG.model_name}',config=config)\n    model_gpu = model.to(device)\n    \n    model_dir = f\"{CFG.model_name}/fold_{fold}\"\n    model_fold_dir = os.path.join(model_dir, str(fold))\n    \n    training_args = TrainingArguments(\n        output_dir = model_fold_dir,\n        report_to='none',\n        load_best_model_at_end=True, # select best model\n        learning_rate=CFG.learning_rate,\n        per_device_train_batch_size=CFG.batch_size,\n        per_device_eval_batch_size=CFG.batch_size,\n        num_train_epochs=CFG.num_train_epochs,\n        weight_decay=CFG.weight_decay,\n        greater_is_better=False,\n        metric_for_best_model=\"mcrmse\",\n        save_strategy='steps',\n        evaluation_strategy='steps',\n        save_total_limit=1,\n        fp16=True,\n        save_steps = CFG.save_steps,\n        eval_steps = CFG.eval_steps\n    )\n    \n    trainer = Trainer(\n        model = model_gpu,\n        train_dataset = fold_train_tokenized,\n        eval_dataset = fold_val_tokenized,\n        args = training_args,\n        data_collator = train_collator,\n        tokenizer = tokenizer,\n        compute_metrics = compute_mcrmse    \n    )\n    \n    model_gpu.save_pretrained(model_dir)\n    tokenizer.save_pretrained(model_dir)\n    model_gpu.cpu()\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"# preds = trainer.predict(tokenized_test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T19:55:45.366290Z","iopub.execute_input":"2023-09-12T19:55:45.366579Z","iopub.status.idle":"2023-09-12T19:55:45.407269Z","shell.execute_reply.started":"2023-09-12T19:55:45.366547Z","shell.execute_reply":"2023-09-12T19:55:45.406341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds","metadata":{"execution":{"iopub.status.busy":"2023-09-12T20:01:44.983025Z","iopub.execute_input":"2023-09-12T20:01:44.983285Z","iopub.status.idle":"2023-09-12T20:01:44.992114Z","shell.execute_reply.started":"2023-09-12T20:01:44.983256Z","shell.execute_reply":"2023-09-12T20:01:44.991158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_args = TrainingArguments(\n            output_dir=  model_fold_dir,\n            do_train = False,\n            do_predict = True,\n            per_device_eval_batch_size = 4,   \n            dataloader_drop_last = False\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T19:57:53.720692Z","iopub.execute_input":"2023-09-12T19:57:53.720964Z","iopub.status.idle":"2023-09-12T19:57:53.728924Z","shell.execute_reply.started":"2023-09-12T19:57:53.720935Z","shell.execute_reply":"2023-09-12T19:57:53.727841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"infer = Trainer(\n    model = model_gpu,\n    args = test_args,\n    tokenizer = tokenizer,\n    data_collator = train_collator\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T20:00:48.286329Z","iopub.execute_input":"2023-09-12T20:00:48.287205Z","iopub.status.idle":"2023-09-12T20:00:48.300539Z","shell.execute_reply.started":"2023-09-12T20:00:48.287168Z","shell.execute_reply":"2023-09-12T20:00:48.299517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds2 = infer.predict(tokenized_test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T20:01:12.716223Z","iopub.execute_input":"2023-09-12T20:01:12.716500Z","iopub.status.idle":"2023-09-12T20:01:12.759664Z","shell.execute_reply.started":"2023-09-12T20:01:12.716468Z","shell.execute_reply":"2023-09-12T20:01:12.758781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds2[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-12T20:01:29.217303Z","iopub.execute_input":"2023-09-12T20:01:29.218147Z","iopub.status.idle":"2023-09-12T20:01:29.225098Z","shell.execute_reply.started":"2023-09-12T20:01:29.218112Z","shell.execute_reply":"2023-09-12T20:01:29.224035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(CFG.n_splits):\n    model_dir = f\"{CFG.model_name}/fold_{fold}\"\n    model_fold_dir = os.path.join(model_dir, str(fold))\n\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)    \n    model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n    model_gpu = model.to(device)\n    \n    test_args = TrainingArguments(\n        output_dir=  model_fold_dir,\n        do_train = False,\n        do_predict = True,\n        per_device_eval_batch_size = 4,   \n        dataloader_drop_last = False,\n        fp16=True\n    )\n    \n    infer = Trainer(\n        model = model_gpu,\n        args = test_args,\n        tokenizer = tokenizer,\n        data_collator = train_collator\n    )\n    \n    preds = infer.predict(tokenized_test_dataset)[0]\n    test[f\"{target_cols[0]}_{fold}\"] = preds[:,0]\n    test[f\"{target_cols[1]}_{fold}\"] = preds[:,1]\n    \n    model_gpu.cpu()\n    del model_gpu\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Take mean of predictions across all folds\ntest[target_cols[0]] = test[test[f\"{target_cols[0]}_{fold}\"] for fold in range(CFG.num_splits)].mean(axis=1)\ntest[target_cols[1]] = test[test[f\"{target_cols[1]}_{fold}\"] for fold in range(CFG.num_splits)].mean(axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"df_submission = pd.DataFrame()\ndf_submission['student_id'] = test['student_id']\ndf_submission['content'] = 0\ndf_submission['wording'] = 0\ndf_submission[target_cols[0]] = test[target_cols[0]]\ndf_submission[target_cols[1]] = test[target_cols[1]]\ndf_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T20:03:57.987125Z","iopub.execute_input":"2023-09-12T20:03:57.987383Z","iopub.status.idle":"2023-09-12T20:03:57.999369Z","shell.execute_reply.started":"2023-09-12T20:03:57.987354Z","shell.execute_reply":"2023-09-12T20:03:57.998497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission","metadata":{"execution":{"iopub.status.busy":"2023-09-12T20:04:04.228544Z","iopub.execute_input":"2023-09-12T20:04:04.228813Z","iopub.status.idle":"2023-09-12T20:04:04.241073Z","shell.execute_reply.started":"2023-09-12T20:04:04.228786Z","shell.execute_reply":"2023-09-12T20:04:04.240007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}