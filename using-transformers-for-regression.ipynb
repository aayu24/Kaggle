{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-13T11:07:17.800621Z","iopub.execute_input":"2023-09-13T11:07:17.800994Z","iopub.status.idle":"2023-09-13T11:07:18.168822Z","shell.execute_reply.started":"2023-09-13T11:07:17.800960Z","shell.execute_reply":"2023-09-13T11:07:18.167152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport transformers\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset\nfrom transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import mean_squared_error\nimport torch\nfrom sklearn.model_selection import KFold, GroupKFold","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:18.498481Z","iopub.execute_input":"2023-09-13T11:07:18.499578Z","iopub.status.idle":"2023-09-13T11:07:29.662706Z","shell.execute_reply.started":"2023-09-13T11:07:18.499540Z","shell.execute_reply":"2023-09-13T11:07:29.661733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nimport warnings\nimport logging\nimport shutil\nfrom tqdm import tqdm\nfrom datasets import disable_progress_bar\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \ndisable_progress_bar()\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.664796Z","iopub.execute_input":"2023-09-13T11:07:29.665144Z","iopub.status.idle":"2023-09-13T11:07:29.674539Z","shell.execute_reply.started":"2023-09-13T11:07:29.665111Z","shell.execute_reply":"2023-09-13T11:07:29.673040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    model_name=\"debertav3base\"\n    learning_rate=1.5e-5\n    weight_decay=0.02\n    hidden_dropout_prob=0.007\n    attention_probs_dropout_prob=0.007\n    num_train_epochs=5\n    n_splits=4\n    batch_size=8\n    random_seed=42\n    save_steps=500\n    max_length=512","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.676158Z","iopub.execute_input":"2023-09-13T11:07:29.676586Z","iopub.status.idle":"2023-09-13T11:07:29.686119Z","shell.execute_reply.started":"2023-09-13T11:07:29.676551Z","shell.execute_reply":"2023-09-13T11:07:29.685265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SEED 42\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything(CFG.random_seed)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.690294Z","iopub.execute_input":"2023-09-13T11:07:29.690531Z","iopub.status.idle":"2023-09-13T11:07:29.701126Z","shell.execute_reply.started":"2023-09-13T11:07:29.690507Z","shell.execute_reply":"2023-09-13T11:07:29.700155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n\nprompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\nprompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\nsummaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\nsummaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\nsample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.703930Z","iopub.execute_input":"2023-09-13T11:07:29.704130Z","iopub.status.idle":"2023-09-13T11:07:29.831538Z","shell.execute_reply.started":"2023-09-13T11:07:29.704098Z","shell.execute_reply":"2023-09-13T11:07:29.830616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.merge(prompts_train,summaries_train,on='prompt_id')\ntest=pd.merge(prompts_test,summaries_test,on='prompt_id')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.833121Z","iopub.execute_input":"2023-09-13T11:07:29.833364Z","iopub.status.idle":"2023-09-13T11:07:29.848497Z","shell.execute_reply.started":"2023-09-13T11:07:29.833334Z","shell.execute_reply":"2023-09-13T11:07:29.847433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.850305Z","iopub.execute_input":"2023-09-13T11:07:29.850635Z","iopub.status.idle":"2023-09-13T11:07:29.870116Z","shell.execute_reply.started":"2023-09-13T11:07:29.850603Z","shell.execute_reply":"2023-09-13T11:07:29.869242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.871364Z","iopub.execute_input":"2023-09-13T11:07:29.871790Z","iopub.status.idle":"2023-09-13T11:07:29.882820Z","shell.execute_reply.started":"2023-09-13T11:07:29.871754Z","shell.execute_reply":"2023-09-13T11:07:29.881800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Split train data using GroupKFolds on prompt_id\nSince test dataset will have new prompts, hence task becomes to train model to perform well on new/unseen prompts - https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/discussion/425409#2357563","metadata":{}},{"cell_type":"code","source":"gkf = GroupKFold(n_splits=CFG.n_splits) # Since 4 prompts in training set\n\nfor i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n    train.loc[val_index, \"fold\"] = i","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.884526Z","iopub.execute_input":"2023-09-13T11:07:29.884784Z","iopub.status.idle":"2023-09-13T11:07:29.904076Z","shell.execute_reply.started":"2023-09-13T11:07:29.884750Z","shell.execute_reply":"2023-09-13T11:07:29.903262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"fold\").count()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.907788Z","iopub.execute_input":"2023-09-13T11:07:29.907995Z","iopub.status.idle":"2023-09-13T11:07:29.927198Z","shell.execute_reply.started":"2023-09-13T11:07:29.907962Z","shell.execute_reply":"2023-09-13T11:07:29.926244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Prepare huggingface dataset\nRef - https://huggingface.co/docs/datasets/v2.14.5/en/tabular_load#pandas-dataframes","metadata":{}},{"cell_type":"code","source":"target_cols = ['content','wording']\ntext_cols = ['text']","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.928808Z","iopub.execute_input":"2023-09-13T11:07:29.929066Z","iopub.status.idle":"2023-09-13T11:07:29.934367Z","shell.execute_reply.started":"2023-09-13T11:07:29.929032Z","shell.execute_reply":"2023-09-13T11:07:29.933413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train[text_cols + target_cols + ['fold']])\ntest_dataset = Dataset.from_pandas(test[text_cols])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.935643Z","iopub.execute_input":"2023-09-13T11:07:29.936505Z","iopub.status.idle":"2023-09-13T11:07:29.964357Z","shell.execute_reply.started":"2023-09-13T11:07:29.936472Z","shell.execute_reply":"2023-09-13T11:07:29.963520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.965597Z","iopub.execute_input":"2023-09-13T11:07:29.965821Z","iopub.status.idle":"2023-09-13T11:07:29.974671Z","shell.execute_reply.started":"2023-09-13T11:07:29.965792Z","shell.execute_reply":"2023-09-13T11:07:29.973672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Model and Metrics","metadata":{}},{"cell_type":"markdown","source":"#### Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(f'/kaggle/input/{CFG.model_name}')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:29.976450Z","iopub.execute_input":"2023-09-13T11:07:29.976685Z","iopub.status.idle":"2023-09-13T11:07:31.108638Z","shell.execute_reply.started":"2023-09-13T11:07:29.976655Z","shell.execute_reply":"2023-09-13T11:07:31.107583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.encode_plus(train_dataset[0]['text'])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:31.109881Z","iopub.execute_input":"2023-09-13T11:07:31.111053Z","iopub.status.idle":"2023-09-13T11:07:31.121118Z","shell.execute_reply.started":"2023-09-13T11:07:31.111015Z","shell.execute_reply":"2023-09-13T11:07:31.120201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:31.122452Z","iopub.execute_input":"2023-09-13T11:07:31.122765Z","iopub.status.idle":"2023-09-13T11:07:31.130001Z","shell.execute_reply.started":"2023-09-13T11:07:31.122730Z","shell.execute_reply":"2023-09-13T11:07:31.129083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Figure out generating labels columns for batch of thousand\ndef generate_tokens(examples: pd.DataFrame,mode='train'):\n    encodings = tokenizer(examples['text'],truncation=True,max_length=CFG.max_length,return_tensors='np')\n    if mode == 'test':\n        return encodings\n    labels = np.column_stack((examples['content'],examples['wording']))\n    return {**encodings, \"labels\": labels}\n\ntokenized_train_dataset = train_dataset.map(generate_tokens,batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:31.131477Z","iopub.execute_input":"2023-09-13T11:07:31.132393Z","iopub.status.idle":"2023-09-13T11:07:33.549825Z","shell.execute_reply.started":"2023-09-13T11:07:31.132357Z","shell.execute_reply":"2023-09-13T11:07:33.548896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:33.553385Z","iopub.execute_input":"2023-09-13T11:07:33.553674Z","iopub.status.idle":"2023-09-13T11:07:33.560177Z","shell.execute_reply.started":"2023-09-13T11:07:33.553638Z","shell.execute_reply":"2023-09-13T11:07:33.559153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_dataset = test_dataset.map(lambda x: generate_tokens(x,'test'),batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:33.561838Z","iopub.execute_input":"2023-09-13T11:07:33.562246Z","iopub.status.idle":"2023-09-13T11:07:33.577449Z","shell.execute_reply.started":"2023-09-13T11:07:33.562197Z","shell.execute_reply":"2023-09-13T11:07:33.576497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:33.579134Z","iopub.execute_input":"2023-09-13T11:07:33.579397Z","iopub.status.idle":"2023-09-13T11:07:33.586682Z","shell.execute_reply.started":"2023-09-13T11:07:33.579365Z","shell.execute_reply":"2023-09-13T11:07:33.585669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Config","metadata":{}},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(f'/kaggle/input/{CFG.model_name}')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:33.587978Z","iopub.execute_input":"2023-09-13T11:07:33.588355Z","iopub.status.idle":"2023-09-13T11:07:33.598209Z","shell.execute_reply.started":"2023-09-13T11:07:33.588322Z","shell.execute_reply":"2023-09-13T11:07:33.597280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-13T11:07:33.795165Z","iopub.execute_input":"2023-09-13T11:07:33.795437Z","iopub.status.idle":"2023-09-13T11:07:33.802570Z","shell.execute_reply.started":"2023-09-13T11:07:33.795409Z","shell.execute_reply":"2023-09-13T11:07:33.801627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config.update({\n    \"num_labels\": 2,\n    \"problem_type\": 'regression',\n    \"hidden_dropout_prob\": CFG.hidden_dropout_prob,\n    \"attention_probs_dropout_prob\": CFG.attention_probs_dropout_prob\n})","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:34.454063Z","iopub.execute_input":"2023-09-13T11:07:34.455403Z","iopub.status.idle":"2023-09-13T11:07:34.460857Z","shell.execute_reply.started":"2023-09-13T11:07:34.455357Z","shell.execute_reply":"2023-09-13T11:07:34.459946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:35.026160Z","iopub.execute_input":"2023-09-13T11:07:35.027128Z","iopub.status.idle":"2023-09-13T11:07:35.035977Z","shell.execute_reply.started":"2023-09-13T11:07:35.027091Z","shell.execute_reply":"2023-09-13T11:07:35.034818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model","metadata":{}},{"cell_type":"code","source":"# model = AutoModel.from_pretrained(f'/kaggle/input/{CFG.model_name}',config=config)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:36.171996Z","iopub.execute_input":"2023-09-13T11:07:36.172620Z","iopub.status.idle":"2023-09-13T11:07:36.177175Z","shell.execute_reply.started":"2023-09-13T11:07:36.172581Z","shell.execute_reply":"2023-09-13T11:07:36.176277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:36.557946Z","iopub.execute_input":"2023-09-13T11:07:36.558553Z","iopub.status.idle":"2023-09-13T11:07:36.563150Z","shell.execute_reply.started":"2023-09-13T11:07:36.558510Z","shell.execute_reply":"2023-09-13T11:07:36.562271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(f'/kaggle/input/{CFG.model_name}',config=config)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:36.927568Z","iopub.execute_input":"2023-09-13T11:07:36.927817Z","iopub.status.idle":"2023-09-13T11:07:41.812986Z","shell.execute_reply.started":"2023-09-13T11:07:36.927788Z","shell.execute_reply":"2023-09-13T11:07:41.812087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:41.815432Z","iopub.execute_input":"2023-09-13T11:07:41.815696Z","iopub.status.idle":"2023-09-13T11:07:41.824139Z","shell.execute_reply.started":"2023-09-13T11:07:41.815662Z","shell.execute_reply":"2023-09-13T11:07:41.823280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Can see that a pooling layer followed by Linear Layer with 2 outputs was added to base model","metadata":{}},{"cell_type":"markdown","source":"#### Metrics - MCRMSE","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    rmse = mean_squared_error(labels, predictions, squared=False)\n    return {\"rmse\": rmse}\n\ndef compute_mcrmse(eval_pred):\n    \"\"\"\n    Calculates mean columnwise root mean squared error\n    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n    \"\"\"\n    preds, labels = eval_pred\n\n    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n    mcrmse = np.mean(col_rmse)\n\n    return {\n        \"content_rmse\": col_rmse[0],\n        \"wording_rmse\": col_rmse[1],\n        \"mcrmse\": mcrmse,\n    }\n\ndef compt_score(content_true, content_pred, wording_true, wording_pred):\n    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n    \n    return (content_score + wording_score)/2","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:41.825441Z","iopub.execute_input":"2023-09-13T11:07:41.826127Z","iopub.status.idle":"2023-09-13T11:07:41.835887Z","shell.execute_reply.started":"2023-09-13T11:07:41.826094Z","shell.execute_reply":"2023-09-13T11:07:41.834821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train using GroupKFold for CV","metadata":{}},{"cell_type":"markdown","source":"<!-- ### Build Trainer -->","metadata":{}},{"cell_type":"code","source":"train_collator = DataCollatorWithPadding(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:41.838364Z","iopub.execute_input":"2023-09-13T11:07:41.838616Z","iopub.status.idle":"2023-09-13T11:07:41.848105Z","shell.execute_reply.started":"2023-09-13T11:07:41.838586Z","shell.execute_reply":"2023-09-13T11:07:41.847273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_fold_dir = './'\n# training_args = TrainingArguments(\n#     output_dir = model_fold_dir,\n#     report_to='none',\n#     load_best_model_at_end=True, # select best model\n#     learning_rate=CFG.learning_rate,\n#     per_device_train_batch_size=CFG.batch_size,\n#     per_device_eval_batch_size=CFG.batch_size,\n#     num_train_epochs=CFG.num_train_epochs,\n#     weight_decay=CFG.weight_decay,\n#     greater_is_better=False,\n#     metric_for_best_model=\"mcrmse\",\n#     save_strategy='no', # \"steps\",\n#     evaluation_strategy='no' #\"steps\",\n# )\n## report_to='none' to avoid wandb login - https://discuss.huggingface.co/t/how-to-turn-wandb-off-in-trainer/6237/2\n## both save strategy and eval strategy have to match","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:41.849359Z","iopub.execute_input":"2023-09-13T11:07:41.849836Z","iopub.status.idle":"2023-09-13T11:07:41.859813Z","shell.execute_reply.started":"2023-09-13T11:07:41.849804Z","shell.execute_reply":"2023-09-13T11:07:41.858921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### GPU","metadata":{}},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\ncuda.empty_cache()\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:42.638626Z","iopub.execute_input":"2023-09-13T11:07:42.638916Z","iopub.status.idle":"2023-09-13T11:07:42.673609Z","shell.execute_reply.started":"2023-09-13T11:07:42.638881Z","shell.execute_reply":"2023-09-13T11:07:42.672695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_gpu = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:43.246778Z","iopub.execute_input":"2023-09-13T11:07:43.247628Z","iopub.status.idle":"2023-09-13T11:07:43.252416Z","shell.execute_reply.started":"2023-09-13T11:07:43.247580Z","shell.execute_reply":"2023-09-13T11:07:43.251422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_gpu","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:43.983433Z","iopub.execute_input":"2023-09-13T11:07:43.984376Z","iopub.status.idle":"2023-09-13T11:07:43.989500Z","shell.execute_reply.started":"2023-09-13T11:07:43.984324Z","shell.execute_reply":"2023-09-13T11:07:43.988489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainer = Trainer(\n#     model = model_gpu,\n#     train_dataset = tokenized_train_dataset,\n#     args = training_args,\n#     data_collator = train_collator,\n#     tokenizer = tokenizer,\n#     compute_metrics = compute_mcrmse    \n# )","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:07:44.694848Z","iopub.execute_input":"2023-09-13T11:07:44.695597Z","iopub.status.idle":"2023-09-13T11:07:44.700894Z","shell.execute_reply.started":"2023-09-13T11:07:44.695544Z","shell.execute_reply":"2023-09-13T11:07:44.699687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:08:10.273639Z","iopub.execute_input":"2023-09-13T11:08:10.273911Z","iopub.status.idle":"2023-09-13T11:08:10.564119Z","shell.execute_reply.started":"2023-09-13T11:08:10.273880Z","shell.execute_reply":"2023-09-13T11:08:10.563243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training loop","metadata":{}},{"cell_type":"code","source":"# delete old model files\nif os.path.exists(CFG.model_name):\n    shutil.rmtree(CFG.model_name)\nos.mkdir(CFG.model_name)\n\nfor fold in range(CFG.n_splits):\n    print(f\"Fold: {fold}\")\n    fold_train_data = train[train['fold']!=fold]\n    fold_val_data = train[train['fold']==fold]\n    fold_train_dataset = Dataset.from_pandas(fold_train_data[text_cols + target_cols])\n    fold_val_dataset = Dataset.from_pandas(fold_val_data[text_cols + target_cols])\n    fold_train_tokenized = fold_train_dataset.map(generate_tokens,batched=True)\n    fold_val_tokenized = fold_val_dataset.map(generate_tokens,batched=True)\n    print(f\"Number of training examples: {fold_train_tokenized.num_rows}\")\n    print(f\"Number of validation examples: {fold_val_tokenized.num_rows}\")\n    \n    model = AutoModelForSequenceClassification.from_pretrained(f'/kaggle/input/{CFG.model_name}',config=config)\n    model_gpu = model.to(device)\n    \n    model_dir = f\"{CFG.model_name}/fold_{fold}\"\n    model_fold_dir = os.path.join(model_dir, str(fold))\n    \n    training_args = TrainingArguments(\n        output_dir = model_fold_dir,\n        report_to='none',\n        load_best_model_at_end=True, # select best model\n        learning_rate=CFG.learning_rate,\n        per_device_train_batch_size=CFG.batch_size,\n        per_device_eval_batch_size=CFG.batch_size,\n        num_train_epochs=CFG.num_train_epochs,\n        weight_decay=CFG.weight_decay,\n        greater_is_better=False,\n        metric_for_best_model=\"mcrmse\",\n        save_strategy='steps',\n        evaluation_strategy='steps',\n        save_total_limit=1,\n        fp16=True,\n        save_steps = CFG.save_steps,\n        eval_steps = CFG.save_steps\n    )\n    \n    trainer = Trainer(\n        model = model_gpu,\n        train_dataset = fold_train_tokenized,\n        eval_dataset = fold_val_tokenized,\n        args = training_args,\n        data_collator = train_collator,\n        tokenizer = tokenizer,\n        compute_metrics = compute_mcrmse    \n    )\n    \n    trainer.train()\n    \n    model_gpu.save_pretrained(model_dir)\n    tokenizer.save_pretrained(model_dir)\n    model_gpu.cpu()\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:09:16.946099Z","iopub.execute_input":"2023-09-13T11:09:16.946740Z","iopub.status.idle":"2023-09-13T11:09:43.468623Z","shell.execute_reply.started":"2023-09-13T11:09:16.946703Z","shell.execute_reply":"2023-09-13T11:09:43.467257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"# preds = trainer.predict(tokenized_test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_args = TrainingArguments(\n#             output_dir=  model_fold_dir,\n#             do_train = False,\n#             do_predict = True,\n#             per_device_eval_batch_size = 4,   \n#             dataloader_drop_last = False\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# infer = Trainer(\n#     model = model_gpu,\n#     args = test_args,\n#     tokenizer = tokenizer,\n#     data_collator = train_collator\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds2 = infer.predict(tokenized_test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds2[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(CFG.n_splits):\n    model_dir = f\"{CFG.model_name}/fold_{fold}\"\n    model_fold_dir = os.path.join(model_dir, str(fold))\n\n    model = AutoModelForSequenceClassification.from_pretrained(model_dir)    \n    model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n    model_gpu = model.to(device)\n    \n    test_args = TrainingArguments(\n        output_dir=  model_fold_dir,\n        do_train = False,\n        do_predict = True,\n        per_device_eval_batch_size = 4,   \n        dataloader_drop_last = False,\n        fp16=True\n    )\n    \n    infer = Trainer(\n        model = model_gpu,\n        args = test_args,\n        tokenizer = tokenizer,\n        data_collator = train_collator\n    )\n    \n    preds = infer.predict(tokenized_test_dataset)[0]\n    test[f\"{target_cols[0]}_{fold}\"] = preds[:,0]\n    test[f\"{target_cols[1]}_{fold}\"] = preds[:,1]\n    \n    model_gpu.cpu()\n    del model_gpu\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Take mean of predictions across all folds\ntest[target_cols[0]] = test[[f\"{target_cols[0]}_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\ntest[target_cols[1]] = test[[f\"{target_cols[1]}_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"df_submission = pd.DataFrame()\ndf_submission['student_id'] = test['student_id']\ndf_submission['content'] = 0\ndf_submission['wording'] = 0\ndf_submission[target_cols[0]] = test[target_cols[0]]\ndf_submission[target_cols[1]] = test[target_cols[1]]\ndf_submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}