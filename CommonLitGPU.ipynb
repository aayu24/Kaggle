{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNduYAfXQnovDu8rhHlpK1u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayu24/Kaggle/blob/master/CommonLitGPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# assert os.environ['COLAB_TPU_ADDR']"
      ],
      "metadata": {
        "id": "6EYVtODH-QDM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "dPw3xeu4De-3",
        "outputId": "d9668070-08a8-47cf-90c0-e377d9578882"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-acd13812-1854-4acc-90e6-ceb5f44ebbdf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-acd13812-1854-4acc-90e6-ceb5f44ebbdf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"aayushpatni\",\"key\":\"ed56c47117dd39939581753865d001bc\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()         # expire any previous token(s) and upload recreated token"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# !kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO61PF4EDlzk",
        "outputId": "a774e59c-a8b7-407d-cb8b-d07224dd3d56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/root/.kaggle': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c commonlit-evaluate-student-summaries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bi3gZvQD9f3",
        "outputId": "69ca8f12-de1f-411e-b70f-79253cd99b1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading commonlit-evaluate-student-summaries.zip to /content\n",
            "\r  0% 0.00/1.05M [00:00<?, ?B/s]\n",
            "\r100% 1.05M/1.05M [00:00<00:00, 166MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jonathanchan/deberta-v3-large"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKJKEx3kEMEn",
        "outputId": "56ac0abb-5e63-4061-8b45-133bb1c8ca95"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading deberta-v3-large.zip to /content\n",
            "100% 768M/770M [00:08<00:00, 94.1MB/s]\n",
            "100% 770M/770M [00:08<00:00, 94.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d debarshichanda/debertav3base"
      ],
      "metadata": {
        "id": "i7N7DDMyETdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d aayushpatni/debertav3large-weights-for-commonlit"
      ],
      "metadata": {
        "id": "F4yzHR5gEZMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir debertav3base"
      ],
      "metadata": {
        "id": "AP_vEU70llAT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir commonlit-evaluate-student-summaries"
      ],
      "metadata": {
        "id": "VDTKxOs1mAR3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset"
      ],
      "metadata": {
        "id": "XWsL7JfdmUKv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv *.zip dataset/"
      ],
      "metadata": {
        "id": "l47mL9QCmRZD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset/commonlit-evaluate-student-summaries.zip -d commonlit-evaluate-student-summaries/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tTNXi4nml1m",
        "outputId": "1c978faf-8b7e-4c47-df00-5093eb0fa717"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset/commonlit-evaluate-student-summaries.zip\n",
            "  inflating: commonlit-evaluate-student-summaries/prompts_test.csv  \n",
            "  inflating: commonlit-evaluate-student-summaries/prompts_train.csv  \n",
            "  inflating: commonlit-evaluate-student-summaries/sample_submission.csv  \n",
            "  inflating: commonlit-evaluate-student-summaries/summaries_test.csv  \n",
            "  inflating: commonlit-evaluate-student-summaries/summaries_train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset/debertav3base.zip -d debertav3base/"
      ],
      "metadata": {
        "id": "Vj3KCzVJm8ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p deberta-v3-large-raw"
      ],
      "metadata": {
        "id": "_vdATeFIltV-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset/deberta-v3-large.zip -d deberta-v3-large-raw/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AW2cc_8FiB3",
        "outputId": "6eda240d-074c-4b66-a0b1-632e33d0f95b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset/deberta-v3-large.zip\n",
            "  inflating: deberta-v3-large-raw/deberta-v3-large/README.md  \n",
            "  inflating: deberta-v3-large-raw/deberta-v3-large/config.json  \n",
            "  inflating: deberta-v3-large-raw/deberta-v3-large/pytorch_model.bin  \n",
            "  inflating: deberta-v3-large-raw/deberta-v3-large/spm.model  \n",
            "  inflating: deberta-v3-large-raw/deberta-v3-large/tokenizer_config.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset/debertav3large-weights-for-commonlit.zip"
      ],
      "metadata": {
        "id": "CERpQwProM13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/deberta-v3-large /content/debertav3base.zip /content/weights /content/v3_small_individual_targets /content/deberta-v3-large-freeze-6/"
      ],
      "metadata": {
        "id": "6XnCbwsxIdd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf dataset"
      ],
      "metadata": {
        "id": "bAHtZa4fGNXn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets sentencepiece"
      ],
      "metadata": {
        "id": "O7Zkhft7E921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5cbf1f4-1cf0-4bb8-a670-16d9f0788ad2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, xxhash, dill, multiprocess, huggingface-hub, transformers, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 huggingface-hub-0.17.2 multiprocess-0.70.15 safetensors-0.3.3 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.33.2 xxhash-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV-KeLbNI2rT",
        "outputId": "85a392bf-e9de-4049-bba3-11c69fdf6e98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "Pzfn3QSl2DT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import Dataset\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "import gc"
      ],
      "metadata": {
        "id": "WTcyI4tPEdtv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import warnings\n",
        "import logging\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "from datasets import disable_progress_bar\n",
        "warnings.simplefilter(\"ignore\")\n",
        "logging.disable(logging.ERROR)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "disable_progress_bar()\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "mtTY-CBJE8Sf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content\""
      ],
      "metadata": {
        "id": "1IWvFSmnG7hH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_MULTI = {\n",
        "    \"debertav3base1\" : f\"{BASE_DIR}/weights/weights/debertav3base\",\n",
        "    \"debertav3large1\" : f\"{BASE_DIR}/deberta-v3-large/deberta-v3-large/deberta-v3-large\",\n",
        "    \"debertav3large2\" : f\"{BASE_DIR}/deberta-v3-large-freeze-6/deberta-v3-large-freeze-6\"\n",
        "}"
      ],
      "metadata": {
        "id": "5Opf_3NQFExb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_models = [\"debertav3base1\",\"debertav3large1\",\"debertav3large2\"]"
      ],
      "metadata": {
        "id": "n46oKMSkFH9K"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    # model_name=\"debertav3base\"\n",
        "    model_name=\"deberta-v3-large-raw/deberta-v3-large\"\n",
        "    learning_rate=1.5e-5 #1e-5\n",
        "    weight_decay=0.02\n",
        "    hidden_dropout_prob=0.007 #0.0\n",
        "    attention_probs_dropout_prob=0.007 #0.0\n",
        "    num_train_epochs=5\n",
        "    n_splits=4\n",
        "    batch_size=4 #1,4,8\n",
        "    random_seed=42 #42,102\n",
        "    save_steps=100 #500\n",
        "    max_length=512 #1024\n",
        "    n_freeze_layers=6 #6,10,12"
      ],
      "metadata": {
        "id": "v215Kr_AFIjZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SEED 42\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "seed_everything(CFG.random_seed)"
      ],
      "metadata": {
        "id": "irb1_QWBFLm4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = f\"{BASE_DIR}/commonlit-evaluate-student-summaries/\"\n",
        "\n",
        "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
        "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
        "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
      ],
      "metadata": {
        "id": "1L0lw5e9FNkU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.merge(prompts_train,summaries_train,on='prompt_id')"
      ],
      "metadata": {
        "id": "0vEUlsmOGF-_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gkf = GroupKFold(n_splits=CFG.n_splits) # Since 4 prompts in training set\n",
        "\n",
        "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
        "    train.loc[val_index, \"fold\"] = i"
      ],
      "metadata": {
        "id": "udm6XYNVGbzF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.groupby(\"fold\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OsdbweqWGd_A",
        "outputId": "323ef24e-1f87-4605-be4c-733e0b6056c2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      prompt_id  prompt_question  prompt_title  prompt_text  student_id  text  \\\n",
              "fold                                                                            \n",
              "0.0        2057             2057          2057         2057        2057  2057   \n",
              "1.0        2009             2009          2009         2009        2009  2009   \n",
              "2.0        1996             1996          1996         1996        1996  1996   \n",
              "3.0        1103             1103          1103         1103        1103  1103   \n",
              "\n",
              "      content  wording  \n",
              "fold                    \n",
              "0.0      2057     2057  \n",
              "1.0      2009     2009  \n",
              "2.0      1996     1996  \n",
              "3.0      1103     1103  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ce57ffb-8221-477a-a992-d9f42e6a154e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>student_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fold</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ce57ffb-8221-477a-a992-d9f42e6a154e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ce57ffb-8221-477a-a992-d9f42e6a154e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ce57ffb-8221-477a-a992-d9f42e6a154e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b35d1a1e-acd8-49d3-91d8-09671732c740\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b35d1a1e-acd8-49d3-91d8-09671732c740')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b35d1a1e-acd8-49d3-91d8-09671732c740 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline components"
      ],
      "metadata": {
        "id": "_WeyZCKvQLwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(f'{BASE_DIR}/{CFG.model_name}')"
      ],
      "metadata": {
        "id": "98-qQOxyGgUL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Note that above tokenizer contains padding because for TPUs we want to have all the examples of same size, otherwise the tensors would have to be continouosly loaded again after each batch."
      ],
      "metadata": {
        "id": "xyyHUCIzp5cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_collator = DataCollatorWithPadding(tokenizer)"
      ],
      "metadata": {
        "id": "czLB_iMzQKds"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(f'{BASE_DIR}/{CFG.model_name}')\n",
        "config.update({\n",
        "    \"num_labels\": 1, #2\n",
        "    \"problem_type\": 'regression',\n",
        "    \"hidden_dropout_prob\": CFG.hidden_dropout_prob,\n",
        "    \"attention_probs_dropout_prob\": CFG.attention_probs_dropout_prob\n",
        "})"
      ],
      "metadata": {
        "id": "_lgPO55CjU-T"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "id": "Yo_hdtfHkh2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ac4f11-042c-47f7-b52b-06646ccb26fb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DebertaV2Config {\n",
              "  \"_name_or_path\": \"/content/deberta-v3-large-raw/deberta-v3-large\",\n",
              "  \"attention_probs_dropout_prob\": 0.007,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.007,\n",
              "  \"hidden_size\": 1024,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"LABEL_0\"\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 4096,\n",
              "  \"label2id\": {\n",
              "    \"LABEL_0\": 0\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-07,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"max_relative_positions\": -1,\n",
              "  \"model_type\": \"deberta-v2\",\n",
              "  \"norm_rel_ebd\": \"layer_norm\",\n",
              "  \"num_attention_heads\": 16,\n",
              "  \"num_hidden_layers\": 24,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pooler_dropout\": 0,\n",
              "  \"pooler_hidden_act\": \"gelu\",\n",
              "  \"pooler_hidden_size\": 1024,\n",
              "  \"pos_att_type\": [\n",
              "    \"p2c\",\n",
              "    \"c2p\"\n",
              "  ],\n",
              "  \"position_biased_input\": false,\n",
              "  \"position_buckets\": 256,\n",
              "  \"problem_type\": \"regression\",\n",
              "  \"relative_attention\": true,\n",
              "  \"share_att_key\": true,\n",
              "  \"transformers_version\": \"4.33.2\",\n",
              "  \"type_vocab_size\": 0,\n",
              "  \"vocab_size\": 128100\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Util functions"
      ],
      "metadata": {
        "id": "ukAlGxaPQWQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Figure out generating labels columns for batch of thousand\n",
        "def generate_tokens(examples: pd.DataFrame,mode='train',text_col='text'):\n",
        "    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,return_tensors='np')\n",
        "    if mode == 'test':\n",
        "        return encodings\n",
        "    labels = np.column_stack((examples['content'],examples['wording']))\n",
        "    return {**encodings, \"labels\": labels}"
      ],
      "metadata": {
        "id": "3Nv3VsZTQZE4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tokens_for_single_target(examples: pd.DataFrame,target: str,mode='train',text_col='text'):\n",
        "    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,return_tensors='np')\n",
        "    if mode == 'test':\n",
        "        return encodings\n",
        "    labels = examples[target]\n",
        "    return {**encodings, \"labels\": labels}"
      ],
      "metadata": {
        "id": "A0Kp0rVXQY60"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Util functions - TPU"
      ],
      "metadata": {
        "id": "EHus_brouV7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Figure out generating labels columns for batch of thousand\n",
        "def generate_tokens(examples: pd.DataFrame,mode='train',text_col='text'):\n",
        "    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,padding='max_length',return_tensors='pt')\n",
        "    if mode == 'test':\n",
        "        return encodings\n",
        "    labels = np.column_stack((examples['content'],examples['wording']))\n",
        "    return {**encodings, \"labels\": labels}"
      ],
      "metadata": {
        "id": "SI_O4R8MuZVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tokens_for_single_target(examples: pd.DataFrame,target: str,mode='train',text_col='text'):\n",
        "    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,padding='max_length',return_tensors='pt')\n",
        "    if mode == 'test':\n",
        "        return encodings\n",
        "    labels = examples[target]\n",
        "    return {**encodings, \"labels\": labels}"
      ],
      "metadata": {
        "id": "aVznyXM7ubMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing text cols"
      ],
      "metadata": {
        "id": "Ad__5dq6Qe6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sep = tokenizer.sep_token\n",
        "train['full_text'] = train['prompt_title'] + sep + train['prompt_question'] + sep + train['text']"
      ],
      "metadata": {
        "id": "H-YjXkSeQjCv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = ['content','wording']\n",
        "text_col = 'full_text' #'text'\n",
        "text_cols = [text_col]"
      ],
      "metadata": {
        "id": "ZjR2CF-cQi8l"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "e4VksKpFP7ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
        "    return {\"rmse\": rmse}\n",
        "\n",
        "def compute_mcrmse(eval_pred):\n",
        "    \"\"\"\n",
        "    Calculates mean columnwise root mean squared error\n",
        "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
        "    \"\"\"\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
        "    mcrmse = np.mean(col_rmse)\n",
        "\n",
        "    return {\n",
        "        \"content_rmse\": col_rmse[0],\n",
        "        \"wording_rmse\": col_rmse[1],\n",
        "        \"mcrmse\": mcrmse,\n",
        "    }\n",
        "\n",
        "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
        "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
        "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
        "\n",
        "    return (content_score + wording_score)/2"
      ],
      "metadata": {
        "id": "6S8_4NcqP0_V"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "nTtav4OAQAPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if os.path.exists(CFG.model_name):\n",
        "#     shutil.rmtree(CFG.model_name)\n",
        "# os.mkdir(CFG.model_name)"
      ],
      "metadata": {
        "id": "l-A3Igv5QtLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the different target models\n",
        "# for target in target_cols:\n",
        "#     if os.path.exists(target):\n",
        "#         shutil.rmtree(target)\n",
        "#     os.mkdir(target)"
      ],
      "metadata": {
        "id": "RXfmNrIsQuaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU setup"
      ],
      "metadata": {
        "id": "C90HQOomSRcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "cuda.empty_cache()\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UFLK3kwSQZT",
        "outputId": "3e3dd424-2310-4817-a325-87c03e7b5450"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "_0Nu1Y3mSIQr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for multi_model in multi_models:\n",
        "    print(f'Model: {multi_model}')\n",
        "    oof_preds = pd.DataFrame()\n",
        "    for fold in range(CFG.n_splits):\n",
        "        val_data = train[train['fold']==fold]\n",
        "        val_dataset = Dataset.from_pandas(val_data[text_cols+target_cols])\n",
        "        tokenized_val_dataset = val_dataset.map(lambda x: generate_tokens(x,text_col=text_col),batched=True)\n",
        "\n",
        "        pretrained_model_dir = f\"{CONFIG_MULTI[multi_model]}/fold_{fold}\"\n",
        "        model_dir = f\"{multi_model}/fold_{fold}\"\n",
        "        model_fold_dir = os.path.join(model_dir, str(fold))\n",
        "\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_dir)\n",
        "        model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n",
        "        model_gpu = model.to(device)\n",
        "\n",
        "        test_args = TrainingArguments(\n",
        "            output_dir=  model_fold_dir,\n",
        "            do_train = False,\n",
        "            do_predict = True,\n",
        "            per_device_eval_batch_size = CFG.batch_size,\n",
        "            dataloader_drop_last = False,\n",
        "            fp16=True\n",
        "        )\n",
        "\n",
        "        infer = Trainer(\n",
        "            model = model_gpu,\n",
        "            args = test_args,\n",
        "            tokenizer = tokenizer,\n",
        "            data_collator = train_collator\n",
        "        )\n",
        "\n",
        "        preds = infer.predict(tokenized_val_dataset)[0]\n",
        "        train.loc[val_data.index,f\"{multi_model}_content_pred\"] = preds[:,0]\n",
        "        train.loc[val_data.index,f\"{multi_model}_wording_pred\"] = preds[:,1]\n",
        "\n",
        "        model_gpu.cpu()\n",
        "        del model_gpu\n",
        "        del model\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"Saving {multi_model} oof preds in csv file.\")\n",
        "    for target in target_cols:\n",
        "        oof_preds[target] = train[f\"{multi_model}_{target}_pred\"]\n",
        "    oof_preds['student_id'] = train['student_id']\n",
        "    oof_preds.to_csv(f\"{multi_model}_oof_preds.csv\",index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "-pSrD25vQHPg",
        "outputId": "b801562e-6906-45da-8f0d-22f9c2ce5682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: debertav3base1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving debertav3base1 oof preds in csv file.\n",
            "Model: debertav3large1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving debertav3large1 oof preds in csv file.\n",
            "Model: debertav3large2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving debertav3large2 oof preds in csv file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_IND = {\n",
        "    \"debertav3base_ind_content\" : f\"{BASE_DIR}/v3_small_individual_targets/v3_small_individual_targets/content/debertav3base\",\n",
        "    \"debertav3base_ind_wording\" : f\"{BASE_DIR}/v3_small_individual_targets/v3_small_individual_targets/wording/debertav3base\",\n",
        "    \"debertav3large_6_ind_content\" : f\"{BASE_DIR}/content/deberta-v3-large-raw/deberta-v3-large\",\n",
        "    \"debertav3large_6_ind_wording\" : f\"{BASE_DIR}/wording/deberta-v3-large-raw/deberta-v3-large\"\n",
        "}"
      ],
      "metadata": {
        "id": "AiF3xTzoSMea"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_models = [\"debertav3base_ind\"]"
      ],
      "metadata": {
        "id": "3s2KQa9fNYNb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ind_model in ind_models:\n",
        "    print(f'Model: {ind_model}')\n",
        "    oof_preds=pd.DataFrame()\n",
        "    for target in target_cols:\n",
        "      for fold in range(CFG.n_splits):\n",
        "        val_data = train[train['fold']==fold]\n",
        "        val_dataset = Dataset.from_pandas(val_data[text_cols+target_cols])\n",
        "        tokenized_val_dataset = val_dataset.map(lambda x: generate_tokens_for_single_target(x,target,text_col=text_col),batched=True)\n",
        "        pretrained_model_dir = f\"{CONFIG_IND[f'{ind_model}_{target}']}/fold_{fold}\"\n",
        "        model_dir =  f\"{target}/{ind_model}/fold_{fold}\"\n",
        "        model_fold_dir = os.path.join(model_dir, str(fold))\n",
        "\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_dir)\n",
        "        model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n",
        "        model_gpu = model.to(device)\n",
        "\n",
        "        test_args = TrainingArguments(\n",
        "            output_dir=  model_fold_dir,\n",
        "            do_train = False,\n",
        "            do_predict = True,\n",
        "            per_device_eval_batch_size = CFG.batch_size,\n",
        "            dataloader_drop_last = False,\n",
        "            fp16=True\n",
        "        )\n",
        "\n",
        "        infer = Trainer(\n",
        "            model = model_gpu,\n",
        "            args = test_args,\n",
        "            tokenizer = tokenizer,\n",
        "            data_collator = train_collator\n",
        "        )\n",
        "\n",
        "        preds = infer.predict(tokenized_val_dataset)[0]\n",
        "        train.loc[val_data.index,f\"{ind_model}_{target}_pred\"] = preds\n",
        "\n",
        "        model_gpu.cpu()\n",
        "        del model_gpu\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "      oof_preds[target] = train[f\"{ind_model}_{target}_pred\"]\n",
        "    print(f\"Saving {ind_model} oof preds in csv file.\")\n",
        "    oof_preds['student_id'] = train['student_id']\n",
        "    oof_preds.to_csv(f\"{ind_model}_oof_preds.csv\",index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rhydpIroNaQP",
        "outputId": "7dd1881f-34a9-4a1f-e915-164e16e96271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: debertav3base_ind\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving debertav3base_ind oof preds in csv file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir commonlit-oof-preds"
      ],
      "metadata": {
        "id": "T6KsVUOuNuaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp *.csv commonlit-oof-preds/"
      ],
      "metadata": {
        "id": "o8uAnDhDQ0rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets init -p commonlit-oof-preds/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6cuyAplQ6O1",
        "outputId": "ec0e0c12-c410-49fc-b0fc-40a854a468e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data package template written to: commonlit-oof-preds/dataset-metadata.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets create -p commonlit-oof-preds/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJsf6A3kQ97x",
        "outputId": "54f768d7-d403-455a-a232-882ad4f9618c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting upload for file debertav3base1_oof_preds.csv\n",
            "100% 154k/154k [00:02<00:00, 63.7kB/s]\n",
            "Upload successful: debertav3base1_oof_preds.csv (154KB)\n",
            "Starting upload for file debertav3large1_oof_preds.csv\n",
            "100% 158k/158k [00:02<00:00, 59.8kB/s]\n",
            "Upload successful: debertav3large1_oof_preds.csv (158KB)\n",
            "Starting upload for file debertav3base_ind_oof_preds.csv\n",
            "100% 155k/155k [00:02<00:00, 53.3kB/s]\n",
            "Upload successful: debertav3base_ind_oof_preds.csv (155KB)\n",
            "Starting upload for file debertav3large2_oof_preds.csv\n",
            "100% 154k/154k [00:02<00:00, 69.8kB/s]\n",
            "Upload successful: debertav3large2_oof_preds.csv (154KB)\n",
            "Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/aayushpatni/commonlit-oof-preds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create different ensembles for wording and content"
      ],
      "metadata": {
        "id": "aX9Hbh-HSrd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {}\n",
        "for multi_model in multi_models:\n",
        "  scores[multi_model] = compute_mcrmse((pd.read_csv(f'commonlit-oof-preds/{multi_model}_oof_preds.csv')[target_cols].values,train[target_cols].values))"
      ],
      "metadata": {
        "id": "KM6mnrcHRbjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL5pTE84VQdj",
        "outputId": "6d9b6aad-ffbb-4fae-d47c-ec6a1375769c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'debertav3base1': {'content_rmse': 0.476628584745796,\n",
              "  'wording_rmse': 0.6357522646155996,\n",
              "  'mcrmse': 0.5561904246806978},\n",
              " 'debertav3large1': {'content_rmse': 0.6286460800064813,\n",
              "  'wording_rmse': 0.6878538019328642,\n",
              "  'mcrmse': 0.6582499409696727},\n",
              " 'debertav3large2': {'content_rmse': 0.46874032364212037,\n",
              "  'wording_rmse': 0.6064148516998585,\n",
              "  'mcrmse': 0.5375775876709894}}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ind_model in ind_models:\n",
        "  scores[ind_model] = compute_mcrmse((pd.read_csv(f'commonlit-oof-preds/{ind_model}_oof_preds.csv')[target_cols].values,train[target_cols].values))"
      ],
      "metadata": {
        "id": "mMK_58jFVRzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehplp32QVc7I",
        "outputId": "bf4cff81-ee6b-47f4-93d5-d5e90f32fcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'debertav3base1': {'content_rmse': 0.476628584745796,\n",
              "  'wording_rmse': 0.6357522646155996,\n",
              "  'mcrmse': 0.5561904246806978},\n",
              " 'debertav3large1': {'content_rmse': 0.6286460800064813,\n",
              "  'wording_rmse': 0.6878538019328642,\n",
              "  'mcrmse': 0.6582499409696727},\n",
              " 'debertav3large2': {'content_rmse': 0.46874032364212037,\n",
              "  'wording_rmse': 0.6064148516998585,\n",
              "  'mcrmse': 0.5375775876709894},\n",
              " 'debertav3base_ind': {'content_rmse': 0.5042827060349722,\n",
              "  'wording_rmse': 0.611206661209505,\n",
              "  'mcrmse': 0.5577446836222386}}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hill Climbing"
      ],
      "metadata": {
        "id": "sZ_vkzjjXnr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_content = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1]['content_rmse'])}"
      ],
      "metadata": {
        "id": "9-UJKEDLXrt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH_SyiVjYVAg",
        "outputId": "4ee0c9d9-6f6c-4e4e-fb3b-e9c5cfc636b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'debertav3large2': {'content_rmse': 0.46874032364212037,\n",
              "  'wording_rmse': 0.6064148516998585,\n",
              "  'mcrmse': 0.5375775876709894},\n",
              " 'debertav3base1': {'content_rmse': 0.476628584745796,\n",
              "  'wording_rmse': 0.6357522646155996,\n",
              "  'mcrmse': 0.5561904246806978},\n",
              " 'debertav3base_ind': {'content_rmse': 0.5042827060349722,\n",
              "  'wording_rmse': 0.611206661209505,\n",
              "  'mcrmse': 0.5577446836222386},\n",
              " 'debertav3large1': {'content_rmse': 0.6286460800064813,\n",
              "  'wording_rmse': 0.6878538019328642,\n",
              "  'mcrmse': 0.6582499409696727}}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_wording = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1]['wording_rmse'])}"
      ],
      "metadata": {
        "id": "lRfl0pagZSH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_wording"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YQit5eiZjrP",
        "outputId": "aa7eef88-23ad-405f-8ed2-0f6a0797f019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'debertav3large2': {'content_rmse': 0.46874032364212037,\n",
              "  'wording_rmse': 0.6064148516998585,\n",
              "  'mcrmse': 0.5375775876709894},\n",
              " 'debertav3base_ind': {'content_rmse': 0.5042827060349722,\n",
              "  'wording_rmse': 0.611206661209505,\n",
              "  'mcrmse': 0.5577446836222386},\n",
              " 'debertav3base1': {'content_rmse': 0.476628584745796,\n",
              "  'wording_rmse': 0.6357522646155996,\n",
              "  'mcrmse': 0.5561904246806978},\n",
              " 'debertav3large1': {'content_rmse': 0.6286460800064813,\n",
              "  'wording_rmse': 0.6878538019328642,\n",
              "  'mcrmse': 0.6582499409696727}}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = train['content'].values"
      ],
      "metadata": {
        "id": "uZnkWyXWaMXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof_df_content = pd.DataFrame()\n",
        "\n",
        "for item in scores_content.items():\n",
        "  oof_df_content[item[0]]=pd.read_csv(f'commonlit-oof-preds/{item[0]}_oof_preds.csv')['content'].values"
      ],
      "metadata": {
        "id": "gVMZsU1waTi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof_df_content.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "ibM37cfSa7LT",
        "outputId": "a7f8989d-9581-420b-cf3b-bbc75922ba64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   debertav3large2  debertav3base1  debertav3base_ind  debertav3large1\n",
              "0        -0.375244       -0.193848          -0.087341        -0.611328\n",
              "1        -1.220703       -1.149414          -1.194336        -1.023438"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d209b6aa-626f-46ce-bbeb-e727e8b806e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>debertav3large2</th>\n",
              "      <th>debertav3base1</th>\n",
              "      <th>debertav3base_ind</th>\n",
              "      <th>debertav3large1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.375244</td>\n",
              "      <td>-0.193848</td>\n",
              "      <td>-0.087341</td>\n",
              "      <td>-0.611328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.220703</td>\n",
              "      <td>-1.149414</td>\n",
              "      <td>-1.194336</td>\n",
              "      <td>-1.023438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d209b6aa-626f-46ce-bbeb-e727e8b806e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d209b6aa-626f-46ce-bbeb-e727e8b806e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d209b6aa-626f-46ce-bbeb-e727e8b806e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-091ff51e-bac4-40c7-b937-0ec91ce416e6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-091ff51e-bac4-40c7-b937-0ec91ce416e6')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-091ff51e-bac4-40c7-b937-0ec91ce416e6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise\n",
        "STOP = False\n",
        "current_best_ensemble_content = oof_df_content.iloc[:,0]\n",
        "# current_best_test_preds = test_preds.iloc[:,0]\n",
        "MODELS = oof_df_content.iloc[:,1:]\n",
        "weight_range = np.arange(0.01,0.51,0.01)   # or with negative weights: np.arange(-0.5,0.51,0.01)\n",
        "history = [compute_metrics((current_best_ensemble_content,y))['rmse']]\n",
        "i=0\n",
        "\n",
        "# Hill climbing\n",
        "while not STOP:\n",
        "    i+=1\n",
        "    potential_new_best_cv_score = compute_metrics((current_best_ensemble_content,y))['rmse']\n",
        "    k_best, wgt_best = None, None\n",
        "    for k in MODELS:\n",
        "        for wgt in weight_range:\n",
        "            potential_ensemble = (1-wgt) * current_best_ensemble_content + wgt * MODELS[k]\n",
        "            cv_score = compute_metrics((potential_ensemble,y))['rmse']\n",
        "            if cv_score < potential_new_best_cv_score:\n",
        "                potential_new_best_cv_score = cv_score\n",
        "                k_best, wgt_best = k, wgt\n",
        "\n",
        "    if k_best is not None:\n",
        "        current_best_ensemble_content = (1-wgt_best) * current_best_ensemble_content + wgt_best * MODELS[k_best]\n",
        "        # current_best_test_preds = (1-wgt_best) * current_best_test_preds + wgt_best * test_preds[k_best]\n",
        "        MODELS.drop(k_best, axis=1, inplace=True)\n",
        "        if MODELS.shape[1]==0:\n",
        "            STOP = True\n",
        "        print(f'Iteration: {i}, Model added: {k_best}, Best weight: {wgt_best:.2f}, Best RMSE: {potential_new_best_cv_score:.5f}')\n",
        "        history.append(potential_new_best_cv_score)\n",
        "    else:\n",
        "        STOP = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c8hIe8tVd6e",
        "outputId": "d7a2c522-855e-4a4c-a53e-c3549016efa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1, Model added: debertav3base1, Best weight: 0.40, Best RMSE: 0.46218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_best_ensemble_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwPmcsi8cubn",
        "outputId": "5c8ff4f3-652f-4157-d30b-8aced65a0e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      -0.302686\n",
              "1      -1.192187\n",
              "2      -0.125220\n",
              "3      -0.109253\n",
              "4      -0.703223\n",
              "          ...   \n",
              "7160    1.583984\n",
              "7161   -0.937695\n",
              "7162    0.531543\n",
              "7163   -0.116687\n",
              "7164    0.814160\n",
              "Length: 7165, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oof_df_wording = pd.DataFrame()\n",
        "\n",
        "for item in scores_wording.items():\n",
        "  oof_df_wording[item[0]]=pd.read_csv(f'commonlit-oof-preds/{item[0]}_oof_preds.csv')['wording'].values"
      ],
      "metadata": {
        "id": "3xO8YmJ3cB3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof_df_wording.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "lVaSD-9obXsK",
        "outputId": "6174f73d-5e45-442a-9d93-6a6e0c0af267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   debertav3large2  debertav3base_ind  debertav3base1  debertav3large1\n",
              "0         0.038025           0.128784        0.056030        -0.393066\n",
              "1        -1.045898          -1.162109       -1.103516        -0.826660"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-664e1940-260d-4912-bb9e-5bc7fc59c095\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>debertav3large2</th>\n",
              "      <th>debertav3base_ind</th>\n",
              "      <th>debertav3base1</th>\n",
              "      <th>debertav3large1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.038025</td>\n",
              "      <td>0.128784</td>\n",
              "      <td>0.056030</td>\n",
              "      <td>-0.393066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.045898</td>\n",
              "      <td>-1.162109</td>\n",
              "      <td>-1.103516</td>\n",
              "      <td>-0.826660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-664e1940-260d-4912-bb9e-5bc7fc59c095')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-664e1940-260d-4912-bb9e-5bc7fc59c095 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-664e1940-260d-4912-bb9e-5bc7fc59c095');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-44120676-c429-4c7c-8f1f-0d6ac47b3332\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44120676-c429-4c7c-8f1f-0d6ac47b3332')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-44120676-c429-4c7c-8f1f-0d6ac47b3332 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise\n",
        "STOP = False\n",
        "current_best_ensemble_wording = oof_df_wording.iloc[:,0]\n",
        "# current_best_test_preds = test_preds.iloc[:,0]\n",
        "MODELS = oof_df_wording.iloc[:,1:]\n",
        "weight_range = np.arange(0.01,0.51,0.01)   # or with negative weights: np.arange(-0.5,0.51,0.01)\n",
        "history = [compute_metrics((current_best_ensemble_wording,y))['rmse']]\n",
        "i=0\n",
        "\n",
        "# Hill climbing\n",
        "while not STOP:\n",
        "    i+=1\n",
        "    potential_new_best_cv_score = compute_metrics((current_best_ensemble_wording,y))['rmse']\n",
        "    k_best, wgt_best = None, None\n",
        "    for k in MODELS:\n",
        "        for wgt in weight_range:\n",
        "            potential_ensemble = (1-wgt) * current_best_ensemble_wording + wgt * MODELS[k]\n",
        "            cv_score = compute_metrics((potential_ensemble,y))['rmse']\n",
        "            if cv_score < potential_new_best_cv_score:\n",
        "                potential_new_best_cv_score = cv_score\n",
        "                k_best, wgt_best = k, wgt\n",
        "\n",
        "    if k_best is not None:\n",
        "        current_best_ensemble_wording = (1-wgt_best) * current_best_ensemble_wording + wgt_best * MODELS[k_best]\n",
        "        # current_best_test_preds = (1-wgt_best) * current_best_test_preds + wgt_best * test_preds[k_best]\n",
        "        MODELS.drop(k_best, axis=1, inplace=True)\n",
        "        if MODELS.shape[1]==0:\n",
        "            STOP = True\n",
        "        print(f'Iteration: {i}, Model added: {k_best}, Best weight: {wgt_best:.2f}, Best RMSE: {potential_new_best_cv_score:.5f}')\n",
        "        history.append(potential_new_best_cv_score)\n",
        "    else:\n",
        "        STOP = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBxFe3swcKOb",
        "outputId": "67ae5ae7-bee8-496b-b791-76a576cd8c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1, Model added: debertav3base1, Best weight: 0.50, Best RMSE: 0.58936\n",
            "Iteration: 2, Model added: debertav3base_ind, Best weight: 0.35, Best RMSE: 0.58517\n",
            "Iteration: 3, Model added: debertav3large1, Best weight: 0.08, Best RMSE: 0.58438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_best_ensemble_wording"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljHV-C9Ecn0J",
        "outputId": "30050613-f346-4c1a-b9b4-4e8f48fd2b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.038146\n",
              "1      -1.083007\n",
              "2      -0.219623\n",
              "3       0.375772\n",
              "4      -0.619894\n",
              "          ...   \n",
              "7160    0.373162\n",
              "7161   -1.013632\n",
              "7162   -0.293504\n",
              "7163   -0.025156\n",
              "7164    0.544369\n",
              "Length: 7165, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_ensemble_preds_train = np.column_stack((current_best_ensemble_content,current_best_ensemble_wording))"
      ],
      "metadata": {
        "id": "1KgnMRBtcsAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Best mcrmse: {compute_mcrmse((best_ensemble_preds_train,train[target_cols].values))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhGcciaTdupA",
        "outputId": "01b24a3e-a24e-4501-e0c1-789ede2fbe37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best mcrmse: {'content_rmse': 0.4621805909691432, 'wording_rmse': 0.5984625324208646, 'mcrmse': 0.5303215616950039}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training debertav3large on individual columns"
      ],
      "metadata": {
        "id": "1a39rfSzi1TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For the different target models\n",
        "for target in target_cols:\n",
        "    if os.path.exists(target):\n",
        "        shutil.rmtree(target)\n",
        "    os.mkdir(target)"
      ],
      "metadata": {
        "id": "MNq7FCpXk7H6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "bEX-Xys8m2U7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for target in target_cols:\n",
        "    print(f\"Target: {target}\")\n",
        "    for fold in range(CFG.n_splits):\n",
        "        print(f\"Fold: {fold}\")\n",
        "        fold_train_data = train[train['fold']!=fold]\n",
        "        fold_val_data = train[train['fold']==fold]\n",
        "        fold_train_dataset = Dataset.from_pandas(fold_train_data[text_cols + target_cols])\n",
        "        fold_val_dataset = Dataset.from_pandas(fold_val_data[text_cols + target_cols])\n",
        "        fold_train_tokenized = fold_train_dataset.map(lambda x: generate_tokens_for_single_target(x,target,text_col=text_col),batched=True)\n",
        "        fold_val_tokenized = fold_val_dataset.map(lambda x: generate_tokens_for_single_target(x,target,text_col=text_col),batched=True)\n",
        "        print(f\"Number of training examples: {fold_train_tokenized.num_rows}\")\n",
        "        print(f\"Number of validation examples: {fold_val_tokenized.num_rows}\")\n",
        "        gc.collect()\n",
        "\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(f'{BASE_DIR}/{CFG.model_name}',config=config)\n",
        "        # freezing embeddings layer\n",
        "        model.base_model.embeddings.requires_grad_(False)\n",
        "\n",
        "        # freezing the initial N layers\n",
        "        for k, param in model.base_model.encoder.layer.named_parameters():\n",
        "            l = int(k.split(\".\")[0])\n",
        "            if l < CFG.n_freeze_layers:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        model_gpu = model.to(device)\n",
        "\n",
        "        model_dir =  f\"{target}/{CFG.model_name}/fold_{fold}\"\n",
        "        model_fold_dir = os.path.join(model_dir, str(fold))\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir = model_fold_dir,\n",
        "            report_to='none',\n",
        "            load_best_model_at_end=True, # select best model\n",
        "            learning_rate=CFG.learning_rate,\n",
        "            per_device_train_batch_size=CFG.batch_size,\n",
        "            per_device_eval_batch_size=CFG.batch_size*2,\n",
        "            num_train_epochs=CFG.num_train_epochs,\n",
        "            weight_decay=CFG.weight_decay,\n",
        "            greater_is_better=False,\n",
        "            metric_for_best_model=\"rmse\", #mcrmse\n",
        "            save_strategy='epoch', #steps\n",
        "            evaluation_strategy='epoch',\n",
        "            save_total_limit=1,\n",
        "            gradient_accumulation_steps=4,\n",
        "            # gradient_checkpointing=True,\n",
        "            optim='adafactor',\n",
        "            fp16=True,\n",
        "            # save_steps = CFG.save_steps,\n",
        "            # eval_steps = CFG.save_steps\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model = model_gpu,\n",
        "            train_dataset = fold_train_tokenized,\n",
        "            eval_dataset = fold_val_tokenized,\n",
        "            args = training_args,\n",
        "            data_collator = train_collator,\n",
        "            tokenizer = tokenizer,\n",
        "            compute_metrics = compute_metrics  #compute_mcrmse\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "        trainer.save_model(model_dir)\n",
        "\n",
        "##         Not needed since trainer saves everything - https://discuss.huggingface.co/t/what-is-the-purpose-of-save-pretrained/9167/2\n",
        "#         model_gpu.save_pretrained(model_dir)\n",
        "#         tokenizer.save_pretrained(model_dir)\n",
        "        model_gpu.cpu()\n",
        "        del model_gpu\n",
        "        del model\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5e8WDTwvi6Yk",
        "outputId": "d14799d0-3bb7-4b94-987b-e25bbf2b69d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: content\n",
            "Fold: 0\n",
            "Number of training examples: 5108\n",
            "Number of validation examples: 2057\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1595' max='1595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1595/1595 35:53, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.190180</td>\n",
              "      <td>0.436096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.269700</td>\n",
              "      <td>0.278995</td>\n",
              "      <td>0.528200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.269700</td>\n",
              "      <td>0.200656</td>\n",
              "      <td>0.447946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.129200</td>\n",
              "      <td>0.180339</td>\n",
              "      <td>0.424663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.047200</td>\n",
              "      <td>0.214475</td>\n",
              "      <td>0.463114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold: 1\n",
            "Number of training examples: 5156\n",
            "Number of validation examples: 2009\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1610' max='1610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1610/1610 35:23, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.617509</td>\n",
              "      <td>0.785817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.258000</td>\n",
              "      <td>0.301197</td>\n",
              "      <td>0.548814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.258000</td>\n",
              "      <td>0.283845</td>\n",
              "      <td>0.532771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.268790</td>\n",
              "      <td>0.518450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.054700</td>\n",
              "      <td>0.279526</td>\n",
              "      <td>0.528702</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold: 2\n",
            "Number of training examples: 5169\n",
            "Number of validation examples: 1996\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1615' max='1615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1615/1615 38:10, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.234826</td>\n",
              "      <td>0.484589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.278000</td>\n",
              "      <td>0.242077</td>\n",
              "      <td>0.492013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.278000</td>\n",
              "      <td>0.185580</td>\n",
              "      <td>0.430790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.129100</td>\n",
              "      <td>0.183014</td>\n",
              "      <td>0.427801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.052600</td>\n",
              "      <td>0.183060</td>\n",
              "      <td>0.427855</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold: 3\n",
            "Number of training examples: 6062\n",
            "Number of validation examples: 1103\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1895' max='1895' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1895/1895 42:29, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.299118</td>\n",
              "      <td>0.546916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.264600</td>\n",
              "      <td>0.374188</td>\n",
              "      <td>0.611709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.129300</td>\n",
              "      <td>0.360397</td>\n",
              "      <td>0.600331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.314002</td>\n",
              "      <td>0.560359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.348049</td>\n",
              "      <td>0.589957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: wording\n",
            "Fold: 0\n",
            "Number of training examples: 5108\n",
            "Number of validation examples: 2057\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1595' max='1595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1595/1595 38:23, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.482726</td>\n",
              "      <td>0.694785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.421200</td>\n",
              "      <td>0.321872</td>\n",
              "      <td>0.567337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.421200</td>\n",
              "      <td>0.304875</td>\n",
              "      <td>0.552154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.208400</td>\n",
              "      <td>0.284974</td>\n",
              "      <td>0.533830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.078600</td>\n",
              "      <td>0.290912</td>\n",
              "      <td>0.539363</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold: 1\n",
            "Number of training examples: 5156\n",
            "Number of validation examples: 2009\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1610' max='1610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1610/1610 36:58, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.799921</td>\n",
              "      <td>0.894383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.389600</td>\n",
              "      <td>0.778880</td>\n",
              "      <td>0.882542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.389600</td>\n",
              "      <td>0.765936</td>\n",
              "      <td>0.875178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.182300</td>\n",
              "      <td>0.856752</td>\n",
              "      <td>0.925609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.055800</td>\n",
              "      <td>0.789664</td>\n",
              "      <td>0.888630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold: 2\n",
            "Number of training examples: 5169\n",
            "Number of validation examples: 1996\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='734' max='1615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 734/1615 16:50 < 20:16, 0.72 it/s, Epoch 2.27/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.273796</td>\n",
              "      <td>0.523256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.430400</td>\n",
              "      <td>0.396022</td>\n",
              "      <td>0.629303</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FLAGS={}\n",
        "# xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "metadata": {
        "id": "NTSHFPnU60bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV"
      ],
      "metadata": {
        "id": "hI2KHs6TmlFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for target in target_cols:\n",
        "    for fold in range(CFG.n_splits):\n",
        "        val_data = train[train['fold']==fold]\n",
        "        val_dataset = Dataset.from_pandas(val_data[text_cols+target_cols])\n",
        "        tokenized_val_dataset = val_dataset.map(lambda x: generate_tokens_for_single_target(x,target,text_col=text_col),batched=True)\n",
        "\n",
        "        model_dir =  f\"{target}/{CFG.model_name}/fold_{fold}\"\n",
        "        model_fold_dir = os.path.join(model_dir, str(fold))\n",
        "\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n",
        "        model_gpu = model.to(device)\n",
        "\n",
        "        test_args = TrainingArguments(\n",
        "            output_dir=  model_fold_dir,\n",
        "            do_train = False,\n",
        "            do_predict = True,\n",
        "            per_device_eval_batch_size = CFG.batch_size,\n",
        "            dataloader_drop_last = False,\n",
        "            fp16=True\n",
        "        )\n",
        "\n",
        "        infer = Trainer(\n",
        "            model = model_gpu,\n",
        "            args = test_args,\n",
        "            tokenizer = tokenizer,\n",
        "            data_collator = train_collator\n",
        "        )\n",
        "\n",
        "        preds = infer.predict(tokenized_val_dataset)[0]\n",
        "        train.loc[val_data.index,f\"{target}_pred\"] = preds\n",
        "\n",
        "        model_gpu.cpu()\n",
        "        del model_gpu\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "JOea9_prjIyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_mcrmse((train[['content_pred','wording_pred']].values,train[target_cols].values)))"
      ],
      "metadata": {
        "id": "mnr-LvbMmm9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof_preds = pd.DataFrame()\n",
        "for target in target_cols:\n",
        "  oof_preds[target] = train[f\"{target}_pred\"]\n",
        "oof_preds.to_csv(f'debertav3large3_oof_preds.csv',index=False)"
      ],
      "metadata": {
        "id": "Eg0a2518nX0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps\n",
        "\n",
        "*   setting dropout probs=0.0\n",
        "*   full_text_2 = question + title + text helps.\n",
        "*   once model with best score, using different random seeds (42,102)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aAEuq0Ux6V3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o3K7S_-17Pgk"
      }
    }
  ]
}