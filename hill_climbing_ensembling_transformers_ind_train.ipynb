{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayu24/Kaggle/blob/master/hill_climbing_ensembling_transformers_ind_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kaggle Data setup"
      ],
      "metadata": {
        "id": "pejqoErSHozC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "syeBLFo1R1Dc",
        "outputId": "2620761a-7f64-450d-a65d-c9e13e035f72"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aef32509-6f9c-4bf5-9831-92b178f741ac\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aef32509-6f9c-4bf5-9831-92b178f741ac\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"aayushpatni\",\"key\":\"ed56c47117dd39939581753865d001bc\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af7myD8qR1VG",
        "outputId": "f43fa5dc-a405-4654-9c0c-7f67d2131ab9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/root/.kaggle': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jonathanchan/deberta-v3-large"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8RT7V2fJws8",
        "outputId": "87419b4c-10c5-4b90-e6f2-112731880e07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading deberta-v3-large.zip to /content\n",
            "100% 768M/770M [00:09<00:00, 50.3MB/s]\n",
            "100% 770M/770M [00:09<00:00, 84.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c commonlit-evaluate-student-summaries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO1soQGrSAAS",
        "outputId": "543d855c-614b-4c38-f351-f78329c9118c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading commonlit-evaluate-student-summaries.zip to /content\n",
            "\r  0% 0.00/1.05M [00:00<?, ?B/s]\n",
            "\r100% 1.05M/1.05M [00:00<00:00, 146MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d aayushpatni/commonlit-oof-preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmfDQtzRSIOp",
        "outputId": "acc07d8d-c82f-47af-88de-e642671e164f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading commonlit-oof-preds.zip to /content\n",
            "\r  0% 0.00/900k [00:00<?, ?B/s]\n",
            "\r100% 900k/900k [00:00<00:00, 142MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d aayushpatni/debertav3-large-freeze-18-steps-eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d3EcP7tHKub",
        "outputId": "6337db0d-4212-47fc-c5a3-33b7f11e74ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading debertav3-large-freeze-18-steps-eval.zip to /content\n",
            "100% 8.58G/8.59G [01:46<00:00, 117MB/s]\n",
            "100% 8.59G/8.59G [01:46<00:00, 86.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets download -d mcpenguin/deberta-v3-weights-ind-seq-len-1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYgG92CFSUcv",
        "outputId": "01ebcd65-f486-4f9f-e8bc-048bd83b15b4"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading deberta-v3-weights-ind-seq-len-1024.zip to /content\n",
            "100% 17.2G/17.2G [11:47<00:00, 28.3MB/s]\n",
            "100% 17.2G/17.2G [11:47<00:00, 26.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets download -d mcpenguin/commonlit-deberta-v3-ind-freeze-18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHT_GIUtSeIn",
        "outputId": "a8d02ded-bd63-4913-dffc-b8b313291dc6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading commonlit-deberta-v3-ind-freeze-18.zip to /content\n",
            "100% 17.2G/17.2G [02:58<00:00, 177MB/s]\n",
            "100% 17.2G/17.2G [02:58<00:00, 103MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir commonlit-evaluate-student-summaries"
      ],
      "metadata": {
        "id": "5jrCzhG1SAwI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p deberta-v3-large-raw"
      ],
      "metadata": {
        "id": "5me8aeRxJy6q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p debertav3-large-freeze-18-steps-eval"
      ],
      "metadata": {
        "id": "8bm8YjZlHRY5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset"
      ],
      "metadata": {
        "id": "zT6SGMW1SFgf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv *.zip dataset/"
      ],
      "metadata": {
        "id": "xpBwxCy_SF9H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset/deberta-v3-large.zip -d deberta-v3-large-raw/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS2ma1DQJ3Wh",
        "outputId": "423749c3-cd45-4f96-dbe5-86ffc2d33264"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset/deberta-v3-large.zip\n",
            "  inflating: deberta-v3-large-raw/deberta-v3-large/README.md  \n",
            "  inflating: deberta-v3-large-raw/deberta-v3-large/config.json  \n",
            "  inflating: deberta-v3-large-raw/deberta-v3-large/pytorch_model.bin  \n",
            "  inflating: deberta-v3-large-raw/deberta-v3-large/spm.model  \n",
            "  inflating: deberta-v3-large-raw/deberta-v3-large/tokenizer_config.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset/commonlit-evaluate-student-summaries.zip -d commonlit-evaluate-student-summaries/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe2Wn2qwTxbz",
        "outputId": "fe5c37cc-8625-4524-8da6-3810ec7b69e4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset/commonlit-evaluate-student-summaries.zip\n",
            "  inflating: commonlit-evaluate-student-summaries/prompts_test.csv  \n",
            "  inflating: commonlit-evaluate-student-summaries/prompts_train.csv  \n",
            "  inflating: commonlit-evaluate-student-summaries/sample_submission.csv  \n",
            "  inflating: commonlit-evaluate-student-summaries/summaries_test.csv  \n",
            "  inflating: commonlit-evaluate-student-summaries/summaries_train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset/debertav3-large-freeze-18-steps-eval.zip -d debertav3-large-freeze-18-steps-eval/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoEBhXsuHVqB",
        "outputId": "476e0fc4-2f23-42ba-dcf3-42e7bac31d08"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset/debertav3-large-freeze-18-steps-eval.zip\n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_0/added_tokens.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_0/config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_0/pytorch_model.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_0/special_tokens_map.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_0/spm.model  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_0/tokenizer.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_0/tokenizer_config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_0/training_args.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_1/added_tokens.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_1/config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_1/pytorch_model.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_1/special_tokens_map.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_1/spm.model  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_1/tokenizer.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_1/tokenizer_config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_1/training_args.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_2/added_tokens.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_2/config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_2/pytorch_model.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_2/special_tokens_map.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_2/spm.model  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_2/tokenizer.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_2/tokenizer_config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_2/training_args.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_3/added_tokens.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_3/config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_3/pytorch_model.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_3/special_tokens_map.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_3/spm.model  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_3/tokenizer.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_3/tokenizer_config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind/fold_3/training_args.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_0/added_tokens.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_0/config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_0/pytorch_model.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_0/special_tokens_map.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_0/spm.model  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_0/tokenizer.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_0/tokenizer_config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_0/training_args.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_1/added_tokens.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_1/config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_1/pytorch_model.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_1/special_tokens_map.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_1/spm.model  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_1/tokenizer.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_1/tokenizer_config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_1/training_args.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_2/added_tokens.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_2/config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_2/pytorch_model.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_2/special_tokens_map.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_2/spm.model  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_2/tokenizer.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_2/tokenizer_config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_2/training_args.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_3/added_tokens.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_3/config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_3/pytorch_model.bin  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_3/special_tokens_map.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_3/spm.model  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_3/tokenizer.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_3/tokenizer_config.json  \n",
            "  inflating: debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind/fold_3/training_args.bin  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir deberta-v3-ind-freeze-18"
      ],
      "metadata": {
        "id": "Wl1hRVnITyV3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf deberta-v3-ind-freeze-18"
      ],
      "metadata": {
        "id": "p-OnWCl7WVjF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip dataset/commonlit-deberta-v3-ind-freeze-18.zip -d deberta-v3-ind-freeze-18/"
      ],
      "metadata": {
        "id": "bw5Qh27qUBkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir deberta-v3-large-1024"
      ],
      "metadata": {
        "id": "tgZexBHDUHFA"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf deberta-v3-large-1024"
      ],
      "metadata": {
        "id": "3WLVAjrwXMAr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf dataset"
      ],
      "metadata": {
        "id": "hAc71W6nUxEg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf deberta-v3-ind-freeze-18"
      ],
      "metadata": {
        "id": "H-8I86h_dVl4"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip /content/deberta-v3-weights-ind-seq-len-1024.zip -d deberta-v3-large-1024/"
      ],
      "metadata": {
        "id": "zCatf6O8eWcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf deberta-v3-weights-ind-seq-len-1024.zip"
      ],
      "metadata": {
        "id": "hgBj-0dbgrxJ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "nWbkclaeRlBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPsJlJKoS0wQ",
        "outputId": "0a80d957-52b5-4416-936d-2487f5c283e9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, xxhash, dill, multiprocess, huggingface-hub, transformers, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 huggingface-hub-0.17.3 multiprocess-0.70.15 safetensors-0.3.3 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.33.3 xxhash-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXKin00pS2yc",
        "outputId": "c1a5a2bd-99b1-41f8-f33f-3d93400f13f0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/258.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m194.6/258.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import Dataset\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "import gc"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:02.180679Z",
          "iopub.execute_input": "2023-09-23T06:55:02.181133Z",
          "iopub.status.idle": "2023-09-23T06:55:15.254765Z",
          "shell.execute_reply.started": "2023-09-23T06:55:02.181103Z",
          "shell.execute_reply": "2023-09-23T06:55:15.253840Z"
        },
        "trusted": true,
        "id": "T8CH0qN0RlBe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import warnings\n",
        "import logging\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "from datasets import disable_progress_bar\n",
        "warnings.simplefilter(\"ignore\")\n",
        "logging.disable(logging.ERROR)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "disable_progress_bar()\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:15.256707Z",
          "iopub.execute_input": "2023-09-23T06:55:15.257030Z",
          "iopub.status.idle": "2023-09-23T06:55:15.265154Z",
          "shell.execute_reply.started": "2023-09-23T06:55:15.257006Z",
          "shell.execute_reply": "2023-09-23T06:55:15.264328Z"
        },
        "trusted": true,
        "id": "JUWyIwQ4RlBf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    # model_name=\"debertav3base\"\n",
        "    model_name=\"deberta-v3-large-raw/deberta-v3-large\"\n",
        "    debug=True\n",
        "    learning_rate=1.5e-5\n",
        "    weight_decay=0.02\n",
        "    hidden_dropout_prob=0.007\n",
        "    attention_probs_dropout_prob=0.007\n",
        "    num_train_epochs=5\n",
        "    n_splits=4\n",
        "    batch_size=8 #4,8\n",
        "    random_seed=42\n",
        "    save_steps=500 #100\n",
        "    max_length=1024 #512\n",
        "    n_freeze_layers=18 #12,6"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:18.255506Z",
          "iopub.execute_input": "2023-09-23T06:55:18.255792Z",
          "iopub.status.idle": "2023-09-23T06:55:18.261662Z",
          "shell.execute_reply.started": "2023-09-23T06:55:18.255744Z",
          "shell.execute_reply": "2023-09-23T06:55:18.260519Z"
        },
        "trusted": true,
        "id": "BU1SuUi4RlBg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SEED 42\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "seed_everything(CFG.random_seed)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:18.441666Z",
          "iopub.execute_input": "2023-09-23T06:55:18.441863Z",
          "iopub.status.idle": "2023-09-23T06:55:18.448853Z",
          "shell.execute_reply.started": "2023-09-23T06:55:18.441840Z",
          "shell.execute_reply": "2023-09-23T06:55:18.447833Z"
        },
        "trusted": true,
        "id": "yl1-k3VCRlBh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "ecmlxNk0RlBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:22.447115Z",
          "iopub.execute_input": "2023-09-23T06:55:22.447361Z",
          "iopub.status.idle": "2023-09-23T06:55:22.452055Z",
          "shell.execute_reply.started": "2023-09-23T06:55:22.447333Z",
          "shell.execute_reply": "2023-09-23T06:55:22.451173Z"
        },
        "trusted": true,
        "id": "I-eX0Gi6RlBh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WORKING_DIR = BASE_DIR"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:22.710662Z",
          "iopub.execute_input": "2023-09-23T06:55:22.711419Z",
          "iopub.status.idle": "2023-09-23T06:55:22.715635Z",
          "shell.execute_reply.started": "2023-09-23T06:55:22.711382Z",
          "shell.execute_reply": "2023-09-23T06:55:22.714601Z"
        },
        "trusted": true,
        "id": "OcVCVZQmRlBi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = f\"{BASE_DIR}/commonlit-evaluate-student-summaries/\"\n",
        "\n",
        "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
        "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
        "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:23.008684Z",
          "iopub.execute_input": "2023-09-23T06:55:23.009434Z",
          "iopub.status.idle": "2023-09-23T06:55:23.137495Z",
          "shell.execute_reply.started": "2023-09-23T06:55:23.009401Z",
          "shell.execute_reply": "2023-09-23T06:55:23.136651Z"
        },
        "trusted": true,
        "id": "7mjTd-_KRlBi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.merge(prompts_train,summaries_train,on='prompt_id')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:23.825218Z",
          "iopub.execute_input": "2023-09-23T06:55:23.825453Z",
          "iopub.status.idle": "2023-09-23T06:55:23.854856Z",
          "shell.execute_reply.started": "2023-09-23T06:55:23.825425Z",
          "shell.execute_reply": "2023-09-23T06:55:23.854015Z"
        },
        "trusted": true,
        "id": "1bLU8iheRlBj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gkf = GroupKFold(n_splits=CFG.n_splits) # Since 4 prompts in training set\n",
        "\n",
        "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
        "    train.loc[val_index, \"fold\"] = i"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:26.303008Z",
          "iopub.execute_input": "2023-09-23T06:55:26.303973Z",
          "iopub.status.idle": "2023-09-23T06:55:26.320912Z",
          "shell.execute_reply.started": "2023-09-23T06:55:26.303941Z",
          "shell.execute_reply": "2023-09-23T06:55:26.320069Z"
        },
        "trusted": true,
        "id": "AKutcGMfRlBj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.groupby(\"fold\").count()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:26.521458Z",
          "iopub.execute_input": "2023-09-23T06:55:26.521684Z",
          "iopub.status.idle": "2023-09-23T06:55:26.548214Z",
          "shell.execute_reply.started": "2023-09-23T06:55:26.521659Z",
          "shell.execute_reply": "2023-09-23T06:55:26.547249Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gwP0dfjWRlBj",
        "outputId": "7c5f3d18-86fe-4c6f-a898-22868cb8b962"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      prompt_id  prompt_question  prompt_title  prompt_text  student_id  text  \\\n",
              "fold                                                                            \n",
              "0.0        2057             2057          2057         2057        2057  2057   \n",
              "1.0        2009             2009          2009         2009        2009  2009   \n",
              "2.0        1996             1996          1996         1996        1996  1996   \n",
              "3.0        1103             1103          1103         1103        1103  1103   \n",
              "\n",
              "      content  wording  \n",
              "fold                    \n",
              "0.0      2057     2057  \n",
              "1.0      2009     2009  \n",
              "2.0      1996     1996  \n",
              "3.0      1103     1103  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cee0c77-6db0-42e6-8233-65921287ee83\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>student_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fold</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cee0c77-6db0-42e6-8233-65921287ee83')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cee0c77-6db0-42e6-8233-65921287ee83 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cee0c77-6db0-42e6-8233-65921287ee83');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-44372a44-4308-4d25-9ac7-cbbfe7b169cc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44372a44-4308-4d25-9ac7-cbbfe7b169cc')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-44372a44-4308-4d25-9ac7-cbbfe7b169cc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if CFG.debug:\n",
        "#     display(train.groupby('fold').size())\n",
        "#     train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
        "#     display(train.groupby('fold').size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "qpwVHKmLM0Hx",
        "outputId": "aa4321fa-7542-4dfb-95bf-85e86cb2a288"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "fold\n",
              "0.0    2057\n",
              "1.0    2009\n",
              "2.0    1996\n",
              "3.0    1103\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "fold\n",
              "0.0    276\n",
              "1.0    276\n",
              "2.0    286\n",
              "3.0    162\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer and Collator"
      ],
      "metadata": {
        "id": "HnYpdLIrRlBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(f'{BASE_DIR}/{CFG.model_name}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:29.794974Z",
          "iopub.execute_input": "2023-09-23T06:55:29.795228Z",
          "iopub.status.idle": "2023-09-23T06:55:30.971165Z",
          "shell.execute_reply.started": "2023-09-23T06:55:29.795200Z",
          "shell.execute_reply": "2023-09-23T06:55:30.970102Z"
        },
        "trusted": true,
        "id": "ga5V4OVTRlBj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_collator = DataCollatorWithPadding(tokenizer)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:30.973901Z",
          "iopub.execute_input": "2023-09-23T06:55:30.974118Z",
          "iopub.status.idle": "2023-09-23T06:55:30.980103Z",
          "shell.execute_reply.started": "2023-09-23T06:55:30.974093Z",
          "shell.execute_reply": "2023-09-23T06:55:30.979234Z"
        },
        "trusted": true,
        "id": "Dr8Genu8RlBk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Figure out generating labels columns for batch of thousand\n",
        "def generate_tokens(examples: pd.DataFrame,mode='train',text_col='text'):\n",
        "    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,return_tensors='np')\n",
        "    if mode == 'test':\n",
        "        return encodings\n",
        "    labels = np.column_stack((examples['content'],examples['wording']))\n",
        "    return {**encodings, \"labels\": labels}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:34.000544Z",
          "iopub.execute_input": "2023-09-23T06:55:34.001638Z",
          "iopub.status.idle": "2023-09-23T06:55:34.009072Z",
          "shell.execute_reply.started": "2023-09-23T06:55:34.001594Z",
          "shell.execute_reply": "2023-09-23T06:55:34.007509Z"
        },
        "trusted": true,
        "id": "AaDrDm01RlBk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tokens_for_single_target(examples: pd.DataFrame,target: str,mode='train',text_col='text'):\n",
        "    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,return_tensors='np')\n",
        "    if mode == 'test':\n",
        "        return encodings\n",
        "    labels = examples[target]\n",
        "    return {**encodings, \"labels\": labels}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:34.586083Z",
          "iopub.execute_input": "2023-09-23T06:55:34.586339Z",
          "iopub.status.idle": "2023-09-23T06:55:34.592397Z",
          "shell.execute_reply.started": "2023-09-23T06:55:34.586312Z",
          "shell.execute_reply": "2023-09-23T06:55:34.591441Z"
        },
        "trusted": true,
        "id": "DY-gd5-rRlBk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Text cols"
      ],
      "metadata": {
        "id": "OAz2AYfrRlBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autocorrect==1.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JInLOoLFN0rV",
        "outputId": "4712e137-95fe-4360-c478-1cbc6d014b10"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autocorrect==1.1.0\n",
            "  Downloading autocorrect-1.1.0.tar.gz (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-1.1.0-py3-none-any.whl size=1810751 sha256=f59b1e448f57777575b51cdc90cc5e5ab55892dcabda431d88b29c9b952f7877\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/be/f2/f4fdf5922c7635a8615179f817e876a19259d36a2b944df585\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autocorrect import Speller\n",
        "speller = Speller(lang='en')"
      ],
      "metadata": {
        "id": "vBw2xbukOOd3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train[\"text_low\"] = train[\"text\"].astype(str).str.lower()\n",
        "# train['corrected_summary_text'] = train[\"text_low\"].progress_apply(speller)\n",
        "train = train.applymap(lambda s: s.lower() if type(s)==str else s)\n",
        "train['corrected_summary_text'] = train[\"text\"].progress_apply(speller)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FzmuIBwOS2F",
        "outputId": "9518122a-786c-4f62-d622-53bdede8638e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7165/7165 [03:56<00:00, 30.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sep = tokenizer.sep_token\n",
        "train['full_text'] = train['prompt_title'] + sep + train['prompt_question'] + sep + train['corrected_summary_text'] #text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:38.592317Z",
          "iopub.execute_input": "2023-09-23T06:55:38.592959Z",
          "iopub.status.idle": "2023-09-23T06:55:38.604968Z",
          "shell.execute_reply.started": "2023-09-23T06:55:38.592909Z",
          "shell.execute_reply": "2023-09-23T06:55:38.604014Z"
        },
        "trusted": true,
        "id": "dYkduqurRlBk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = ['content','wording']\n",
        "text_col = 'full_text' #'text'\n",
        "text_cols = [text_col]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:38.863355Z",
          "iopub.execute_input": "2023-09-23T06:55:38.863578Z",
          "iopub.status.idle": "2023-09-23T06:55:38.868047Z",
          "shell.execute_reply.started": "2023-09-23T06:55:38.863553Z",
          "shell.execute_reply": "2023-09-23T06:55:38.867141Z"
        },
        "trusted": true,
        "id": "cX5Zpx0ERlBk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-trained Models"
      ],
      "metadata": {
        "id": "7EGaxPLBRlBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_MULTI = {\n",
        "    \"debertav3base1\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/weights/weights/debertav3base\",\n",
        "    \"debertav3large1\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/deberta-v3-large/deberta-v3-large/deberta-v3-large\",\n",
        "    \"debertav3large2\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/deberta-v3-large-freeze-6/deberta-v3-large-freeze-6\"\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:42.150519Z",
          "iopub.execute_input": "2023-09-23T06:55:42.151472Z",
          "iopub.status.idle": "2023-09-23T06:55:42.156849Z",
          "shell.execute_reply.started": "2023-09-23T06:55:42.151429Z",
          "shell.execute_reply": "2023-09-23T06:55:42.155902Z"
        },
        "trusted": true,
        "id": "V9ktgvE0RlBk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_models = [\"debertav3base1\",\"debertav3large1\",\"debertav3large2\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:42.420502Z",
          "iopub.execute_input": "2023-09-23T06:55:42.420733Z",
          "iopub.status.idle": "2023-09-23T06:55:42.424889Z",
          "shell.execute_reply.started": "2023-09-23T06:55:42.420709Z",
          "shell.execute_reply": "2023-09-23T06:55:42.423956Z"
        },
        "trusted": true,
        "id": "Pl4NO7T_RlBl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_IND = {\n",
        "    \"debertav3base_ind_content\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/v3_small_individual_targets/v3_small_individual_targets/content/debertav3base\",\n",
        "    \"debertav3base_ind_wording\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/v3_small_individual_targets/v3_small_individual_targets/wording/debertav3base\",\n",
        "    \"debertav3large_ind_content\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/deberta-v3-large-ind-autocorrect/commonlit-deberta-v3-weights/content/deberta-v3-large-ind\",\n",
        "    \"debertav3large_ind_wording\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/deberta-v3-large-ind-autocorrect/commonlit-deberta-v3-weights/wording/deberta-v3-large-ind\",\n",
        "    \"debertav3large_freeze_18_ind_content\" : f\"{BASE_DIR}/deberta-v3-ind-freeze-18/content/deberta-v3-large-ind\" ,\n",
        "    \"debertav3large_freeze_18_ind_wording\": f\"{BASE_DIR}/deberta-v3-ind-freeze-18/wording/deberta-v3-large-ind\",\n",
        "    \"debertav3large_1024_ind_content\": f\"{BASE_DIR}/deberta-v3-large-1024/content/deberta-v3-large-ind\",\n",
        "    \"debertav3large_1024_ind_wording\": f\"{BASE_DIR}/deberta-v3-large-1024/wording/deberta-v3-large-ind\",\n",
        "    \"debertav3large_freeze_18_step_eval_ind_content\": f\"{BASE_DIR}/debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind\",\n",
        "    \"debertav3large_freeze_18_step_eval_ind_wording\": f\"{BASE_DIR}/debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind\"\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:44.448498Z",
          "iopub.execute_input": "2023-09-23T06:55:44.449445Z",
          "iopub.status.idle": "2023-09-23T06:55:44.455321Z",
          "shell.execute_reply.started": "2023-09-23T06:55:44.449401Z",
          "shell.execute_reply": "2023-09-23T06:55:44.454385Z"
        },
        "trusted": true,
        "id": "hxL52K9VRlBl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ind_models = [\"debertav3base_ind\",\"debertav3large_ind\"]\n",
        "# ind_models = [\"debertav3large_freeze_18_ind\"]\n",
        "# ind_models = [\"debertav3base_ind\",\"debertav3large_ind\",\"debertav3large_freeze_18_ind\"]\n",
        "# ind_models = [\"debertav3large_1024_ind\"]\n",
        "# ind_models = [\"debertav3base_ind\",\"debertav3large_ind\",\"debertav3large_freeze_18_ind\",\"debertav3large_1024_ind\"]\n",
        "ind_models = [\"debertav3large_freeze_18_step_eval_ind\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:44.657960Z",
          "iopub.execute_input": "2023-09-23T06:55:44.658160Z",
          "iopub.status.idle": "2023-09-23T06:55:44.662312Z",
          "shell.execute_reply.started": "2023-09-23T06:55:44.658137Z",
          "shell.execute_reply": "2023-09-23T06:55:44.661385Z"
        },
        "trusted": true,
        "id": "5IxH6XBfRlBl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "0S4DPHbLRlBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
        "    return {\"rmse\": rmse}\n",
        "\n",
        "def compute_mcrmse(eval_pred):\n",
        "    \"\"\"\n",
        "    Calculates mean columnwise root mean squared error\n",
        "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
        "    \"\"\"\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
        "    mcrmse = np.mean(col_rmse)\n",
        "\n",
        "    return {\n",
        "        \"content_rmse\": col_rmse[0],\n",
        "        \"wording_rmse\": col_rmse[1],\n",
        "        \"mcrmse\": mcrmse,\n",
        "    }\n",
        "\n",
        "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
        "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
        "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
        "\n",
        "    return (content_score + wording_score)/2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:46.918369Z",
          "iopub.execute_input": "2023-09-23T06:55:46.918636Z",
          "iopub.status.idle": "2023-09-23T06:55:46.926148Z",
          "shell.execute_reply.started": "2023-09-23T06:55:46.918607Z",
          "shell.execute_reply": "2023-09-23T06:55:46.925212Z"
        },
        "trusted": true,
        "id": "pnFPDNu8RlBl"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU setup"
      ],
      "metadata": {
        "id": "YKtlJ8MQRlBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "cuda.empty_cache()\n",
        "print(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:49.281885Z",
          "iopub.execute_input": "2023-09-23T06:55:49.282148Z",
          "iopub.status.idle": "2023-09-23T06:55:49.314877Z",
          "shell.execute_reply.started": "2023-09-23T06:55:49.282121Z",
          "shell.execute_reply": "2023-09-23T06:55:49.313617Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMNcq7sERlBl",
        "outputId": "279c0341-5e01-4561-924f-ee6d15e7e699"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:49.520787Z",
          "iopub.execute_input": "2023-09-23T06:55:49.522461Z",
          "iopub.status.idle": "2023-09-23T06:55:49.762338Z",
          "shell.execute_reply.started": "2023-09-23T06:55:49.522429Z",
          "shell.execute_reply": "2023-09-23T06:55:49.761199Z"
        },
        "trusted": true,
        "id": "fRkEX5sMRlBm"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions on train set"
      ],
      "metadata": {
        "id": "aF6KQ6n6RlBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for multi_model in multi_models:\n",
        "#     print(f'Model: {multi_model}')\n",
        "#     oof_preds = pd.DataFrame()\n",
        "#     for fold in range(CFG.n_splits):\n",
        "#         val_data = train[train['fold']==fold]\n",
        "#         val_dataset = Dataset.from_pandas(val_data[text_cols+target_cols])\n",
        "#         tokenized_val_dataset = val_dataset.map(lambda x: generate_tokens(x,text_col=text_col),batched=True)\n",
        "\n",
        "#         pretrained_model_dir = f\"{CONFIG_MULTI[multi_model]}/fold_{fold}\"\n",
        "#         model_dir = f\"{multi_model}/fold_{fold}\"\n",
        "#         model_fold_dir = os.path.join(model_dir, str(fold))\n",
        "\n",
        "#         model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_dir)\n",
        "#         model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n",
        "#         model_gpu = model.to(device)\n",
        "\n",
        "#         test_args = TrainingArguments(\n",
        "#             output_dir=  model_fold_dir,\n",
        "#             do_train = False,\n",
        "#             do_predict = True,\n",
        "#             per_device_eval_batch_size = CFG.batch_size,\n",
        "#             dataloader_drop_last = False,\n",
        "#             fp16=True\n",
        "#         )\n",
        "\n",
        "#         infer = Trainer(\n",
        "#             model = model_gpu,\n",
        "#             args = test_args,\n",
        "#             tokenizer = tokenizer,\n",
        "#             data_collator = train_collator\n",
        "#         )\n",
        "\n",
        "#         preds = infer.predict(tokenized_val_dataset)[0]\n",
        "#         train.loc[val_data.index,f\"{multi_model}_content_pred\"] = preds[:,0]\n",
        "#         train.loc[val_data.index,f\"{multi_model}_wording_pred\"] = preds[:,1]\n",
        "\n",
        "#         model_gpu.cpu()\n",
        "#         del model_gpu\n",
        "#         del model\n",
        "#         gc.collect()\n",
        "#         torch.cuda.empty_cache()\n",
        "\n",
        "#     print(f\"Saving {multi_model} oof preds in csv file.\")\n",
        "#     for target in target_cols:\n",
        "#         oof_preds[target] = train[f\"{multi_model}_{target}_pred\"]\n",
        "#     oof_preds.to_csv(f\"{multi_model}_oof_preds.csv\",index=False)"
      ],
      "metadata": {
        "id": "ezA1ObXbRlBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf content"
      ],
      "metadata": {
        "id": "Po6kfysAQYrh"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf wording"
      ],
      "metadata": {
        "id": "KksMm_S6d_q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ind_model in ind_models:\n",
        "    print(f'Model: {ind_model}')\n",
        "    oof_preds=pd.DataFrame()\n",
        "    for target in target_cols:\n",
        "        for fold in range(CFG.n_splits):\n",
        "            val_data = train[train['fold']==fold]\n",
        "            val_dataset = Dataset.from_pandas(val_data[text_cols+target_cols])\n",
        "            tokenized_val_dataset = val_dataset.map(lambda x: generate_tokens_for_single_target(x,target,text_col=text_col),batched=True)\n",
        "            pretrained_model_dir = f\"{CONFIG_IND[f'{ind_model}_{target}']}/fold_{fold}\"\n",
        "            model_dir =  f\"{target}/{ind_model}/fold_{fold}\"\n",
        "            model_fold_dir = os.path.join(model_dir, str(fold))\n",
        "\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_dir)\n",
        "            model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n",
        "            model_gpu = model.to(device)\n",
        "\n",
        "            test_args = TrainingArguments(\n",
        "                output_dir=  model_fold_dir,\n",
        "                do_train = False,\n",
        "                do_predict = True,\n",
        "                per_device_eval_batch_size = CFG.batch_size,\n",
        "                dataloader_drop_last = False,\n",
        "                fp16=True\n",
        "            )\n",
        "\n",
        "            infer = Trainer(\n",
        "                model = model_gpu,\n",
        "                args = test_args,\n",
        "                tokenizer = tokenizer,\n",
        "                data_collator = train_collator\n",
        "            )\n",
        "\n",
        "            preds = infer.predict(tokenized_val_dataset)[0]\n",
        "            train.loc[val_data.index,f\"{ind_model}_{target}_pred\"] = preds\n",
        "\n",
        "            model_gpu.cpu()\n",
        "            del model_gpu\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "        oof_preds[target] = train[f\"{ind_model}_{target}_pred\"]\n",
        "    print(f\"Saving {ind_model} oof preds in csv file.\")\n",
        "    oof_preds['student_id'] = train['student_id']\n",
        "    oof_preds.to_csv(f\"{ind_model}_oof_preds.csv\",index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "4qBP74NzRlBm",
        "outputId": "ae2b8284-e854-4489-b885-48f756d0310f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: debertav3large_freeze_18_step_eval_ind\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving debertav3large_freeze_18_step_eval_ind oof preds in csv file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions on test set"
      ],
      "metadata": {
        "id": "hqeTZzxeRlBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
        "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
        "test = pd.merge(prompts_test,summaries_test,on='prompt_id')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:55:58.107980Z",
          "iopub.execute_input": "2023-09-23T06:55:58.108227Z",
          "iopub.status.idle": "2023-09-23T06:55:58.124531Z",
          "shell.execute_reply.started": "2023-09-23T06:55:58.108199Z",
          "shell.execute_reply": "2023-09-23T06:55:58.123495Z"
        },
        "trusted": true,
        "id": "etx92EKfRlBm"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = test.applymap(lambda s: s.lower() if type(s)==str else s)\n",
        "train['corrected_summary_text'] = test[\"text\"].progress_apply(speller)\n",
        "test['full_text'] = test['prompt_title'] + sep + test['prompt_question'] + sep + test['corrected_summary_text']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:58:53.889299Z",
          "iopub.execute_input": "2023-09-23T06:58:53.889587Z",
          "iopub.status.idle": "2023-09-23T06:58:53.897003Z",
          "shell.execute_reply.started": "2023-09-23T06:58:53.889550Z",
          "shell.execute_reply": "2023-09-23T06:58:53.895840Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU2voiD1RlBm",
        "outputId": "f6a9f00c-4540-4b65-a993-531c741d6cfd"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 3105.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Dataset.from_pandas(test[text_cols])\n",
        "tokenized_test_dataset = test_dataset.map(lambda x: generate_tokens(x,'test','full_text'),batched=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:58:54.384809Z",
          "iopub.execute_input": "2023-09-23T06:58:54.385048Z",
          "iopub.status.idle": "2023-09-23T06:58:54.462084Z",
          "shell.execute_reply.started": "2023-09-23T06:58:54.385022Z",
          "shell.execute_reply": "2023-09-23T06:58:54.461226Z"
        },
        "trusted": true,
        "id": "r3OZrMFYRlBm"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for multi_model in multi_models:\n",
        "    print(f'Model: {multi_model}')\n",
        "    test_preds = pd.DataFrame()\n",
        "    for fold in range(CFG.n_splits):\n",
        "        pretrained_model_dir = f\"{CONFIG_MULTI[multi_model]}/fold_{fold}\"\n",
        "        model_dir = f\"{multi_model}/fold_{fold}\"\n",
        "        model_fold_dir = os.path.join(model_dir, str(fold))\n",
        "\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_dir)\n",
        "        model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n",
        "        model_gpu = model.to(device)\n",
        "\n",
        "        test_args = TrainingArguments(\n",
        "            output_dir=  model_fold_dir,\n",
        "            do_train = False,\n",
        "            do_predict = True,\n",
        "            per_device_eval_batch_size = CFG.batch_size,\n",
        "            dataloader_drop_last = False,\n",
        "            fp16=True\n",
        "        )\n",
        "\n",
        "        infer = Trainer(\n",
        "            model = model_gpu,\n",
        "            args = test_args,\n",
        "            tokenizer = tokenizer,\n",
        "            data_collator = train_collator\n",
        "        )\n",
        "\n",
        "        preds = infer.predict(tokenized_test_dataset)[0]\n",
        "        test[f\"{multi_model}_content_pred\"] = preds[:,0]\n",
        "        test[f\"{multi_model}_wording_pred\"] = preds[:,1]\n",
        "\n",
        "        model_gpu.cpu()\n",
        "        del model_gpu\n",
        "        del model\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"Saving {multi_model} test preds in csv file.\")\n",
        "    for target in target_cols:\n",
        "        test_preds[target] = test[f\"{multi_model}_{target}_pred\"]\n",
        "    test_preds['student_id'] = test['student_id']\n",
        "    test_preds.to_csv(f\"{multi_model}_test_preds.csv\",index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T06:59:01.055449Z",
          "iopub.execute_input": "2023-09-23T06:59:01.055942Z",
          "iopub.status.idle": "2023-09-23T07:02:28.873861Z",
          "shell.execute_reply.started": "2023-09-23T06:59:01.055889Z",
          "shell.execute_reply": "2023-09-23T07:02:28.872613Z"
        },
        "trusted": true,
        "id": "XevzDv_NRlBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ind_model in ind_models:\n",
        "    print(f'Model: {ind_model}')\n",
        "    test_preds=pd.DataFrame()\n",
        "    for target in target_cols:\n",
        "        for fold in range(CFG.n_splits):\n",
        "            pretrained_model_dir = f\"{CONFIG_IND[f'{ind_model}_{target}']}/fold_{fold}\"\n",
        "            model_dir =  f\"{target}/{ind_model}/fold_{fold}\"\n",
        "            model_fold_dir = os.path.join(model_dir, str(fold))\n",
        "\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_dir)\n",
        "            model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n",
        "            model_gpu = model.to(device)\n",
        "\n",
        "            test_args = TrainingArguments(\n",
        "                output_dir=  model_fold_dir,\n",
        "                do_train = False,\n",
        "                do_predict = True,\n",
        "                per_device_eval_batch_size = CFG.batch_size,\n",
        "                dataloader_drop_last = False,\n",
        "                fp16=True\n",
        "            )\n",
        "\n",
        "            infer = Trainer(\n",
        "                model = model_gpu,\n",
        "                args = test_args,\n",
        "                tokenizer = tokenizer,\n",
        "                data_collator = train_collator\n",
        "            )\n",
        "\n",
        "            preds = infer.predict(tokenized_test_dataset)[0]\n",
        "            test[f\"{ind_model}_{target}_pred\"] = preds\n",
        "\n",
        "            model_gpu.cpu()\n",
        "            del model_gpu\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "        test_preds[target] = test[f\"{ind_model}_{target}_pred\"]\n",
        "    print(f\"Saving {ind_model} test preds in csv file.\")\n",
        "    test_preds['student_id'] = test['student_id']\n",
        "    test_preds.to_csv(f\"{ind_model}_test_preds.csv\",index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:02:28.876102Z",
          "iopub.execute_input": "2023-09-23T07:02:28.876382Z",
          "iopub.status.idle": "2023-09-23T07:06:13.968820Z",
          "shell.execute_reply.started": "2023-09-23T07:02:28.876343Z",
          "shell.execute_reply": "2023-09-23T07:06:13.967601Z"
        },
        "trusted": true,
        "id": "8bv3R-03RlBn",
        "outputId": "7abc4c53-8fcd-45b3-df0c-6284a63f1a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: debertav3base_ind\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Saving debertav3base_ind test preds in csv file.\nModel: debertav3large_ind\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Saving debertav3large_ind test preds in csv file.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hill Cimbing"
      ],
      "metadata": {
        "id": "GkUJ1nifRlBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d aayushpatni/commonlit-oof-preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pebSsxsPYxlM",
        "outputId": "46d872a3-7ddc-4086-b881-9c1f904f98d0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading commonlit-oof-preds.zip to /content\n",
            "\r  0% 0.00/900k [00:00<?, ?B/s]\n",
            "\r100% 900k/900k [00:00<00:00, 98.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf commonlit-oof-preds"
      ],
      "metadata": {
        "id": "GTUXBOI-sTqI"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir commonlit-oof-preds"
      ],
      "metadata": {
        "id": "rEoAavXlZs9e"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip commonlit-oof-preds.zip -d commonlit-oof-preds/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egDEMZHmY4IK",
        "outputId": "abae9452-df68-498f-844a-0089c507bed5"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  commonlit-oof-preds.zip\n",
            "  inflating: commonlit-oof-preds/debertav3base1_oof_preds.csv  \n",
            "  inflating: commonlit-oof-preds/debertav3base_ind_oof_preds.csv  \n",
            "  inflating: commonlit-oof-preds/debertav3large1_oof_preds.csv  \n",
            "  inflating: commonlit-oof-preds/debertav3large2_ind_oof_preds.csv  \n",
            "  inflating: commonlit-oof-preds/debertav3large2_oof_preds.csv  \n",
            "  inflating: commonlit-oof-preds/debertav3large_1024_ind_oof_preds.csv  \n",
            "  inflating: commonlit-oof-preds/debertav3large_freeze_18_ind_oof_preds.csv  \n",
            "  inflating: commonlit-oof-preds/debertav3large_ind_oof_preds.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {}\n",
        "for multi_model in multi_models:\n",
        "    scores[multi_model] = compute_mcrmse((pd.read_csv(f'{BASE_DIR}/commonlit-oof-preds/{multi_model}_oof_preds.csv')[target_cols].values,train[target_cols].values))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:06:13.970233Z",
          "iopub.execute_input": "2023-09-23T07:06:13.970928Z",
          "iopub.status.idle": "2023-09-23T07:06:14.019290Z",
          "shell.execute_reply.started": "2023-09-23T07:06:13.970886Z",
          "shell.execute_reply": "2023-09-23T07:06:14.018460Z"
        },
        "trusted": true,
        "id": "aaS1OJj8RlBo"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ind_model in ind_models:\n",
        "      scores[ind_model] = compute_mcrmse((pd.read_csv(f'{BASE_DIR}/commonlit-oof-preds/{ind_model}_oof_preds.csv')[target_cols].values,train[target_cols].values))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:06:14.021444Z",
          "iopub.execute_input": "2023-09-23T07:06:14.021690Z",
          "iopub.status.idle": "2023-09-23T07:06:14.051464Z",
          "shell.execute_reply.started": "2023-09-23T07:06:14.021658Z",
          "shell.execute_reply": "2023-09-23T07:06:14.050666Z"
        },
        "trusted": true,
        "id": "y7MYenqSRlBo"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:06:14.052685Z",
          "iopub.execute_input": "2023-09-23T07:06:14.052922Z",
          "iopub.status.idle": "2023-09-23T07:06:14.060987Z",
          "shell.execute_reply.started": "2023-09-23T07:06:14.052891Z",
          "shell.execute_reply": "2023-09-23T07:06:14.060107Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YT7AfksRlBo",
        "outputId": "558ce1a4-609c-4c07-a203-de80d6321f58"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'debertav3base1': {'content_rmse': 0.476628584745796,\n",
              "  'wording_rmse': 0.6357522646155996,\n",
              "  'mcrmse': 0.5561904246806978},\n",
              " 'debertav3large1': {'content_rmse': 0.6286460800064813,\n",
              "  'wording_rmse': 0.6878538019328642,\n",
              "  'mcrmse': 0.6582499409696727},\n",
              " 'debertav3large2': {'content_rmse': 0.46874032364212037,\n",
              "  'wording_rmse': 0.6064148516998585,\n",
              "  'mcrmse': 0.5375775876709894},\n",
              " 'debertav3base_ind': {'content_rmse': 0.5042827060349722,\n",
              "  'wording_rmse': 0.611206661209505,\n",
              "  'mcrmse': 0.5577446836222386},\n",
              " 'debertav3large_ind': {'content_rmse': 0.4743638733040936,\n",
              "  'wording_rmse': 0.6302055670290027,\n",
              "  'mcrmse': 0.5522847201665482},\n",
              " 'debertav3large_freeze_18_ind': {'content_rmse': 0.4577357710838505,\n",
              "  'wording_rmse': 0.6305033929667518,\n",
              "  'mcrmse': 0.5441195820253012},\n",
              " 'debertav3large_1024_ind': {'content_rmse': 0.46482656801171157,\n",
              "  'wording_rmse': 0.6408757193475337,\n",
              "  'mcrmse': 0.5528511436796226}}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Content"
      ],
      "metadata": {
        "id": "w5s2JsPzRlBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_content = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1]['content_rmse'])}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:07:49.431929Z",
          "iopub.execute_input": "2023-09-23T07:07:49.432217Z",
          "iopub.status.idle": "2023-09-23T07:07:49.437755Z",
          "shell.execute_reply.started": "2023-09-23T07:07:49.432187Z",
          "shell.execute_reply": "2023-09-23T07:07:49.436610Z"
        },
        "trusted": true,
        "id": "_1LgWsHyRlBp"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = train['content'].values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:07:49.857022Z",
          "iopub.execute_input": "2023-09-23T07:07:49.857233Z",
          "iopub.status.idle": "2023-09-23T07:07:49.861838Z",
          "shell.execute_reply.started": "2023-09-23T07:07:49.857208Z",
          "shell.execute_reply": "2023-09-23T07:07:49.860877Z"
        },
        "trusted": true,
        "id": "uSwsTPPhRlBp"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof_df_content = pd.DataFrame()\n",
        "# test_df_content = pd.DataFrame()\n",
        "\n",
        "for item in scores_content.items():\n",
        "    oof_df_content[item[0]]=pd.read_csv(f'{BASE_DIR}/commonlit-oof-preds/{item[0]}_oof_preds.csv')['content'].values\n",
        "    # test_df_content[item[0]]=pd.read_csv(f'{WORKING_DIR}/{item[0]}_test_preds.csv')['content'].values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:07:53.073212Z",
          "iopub.execute_input": "2023-09-23T07:07:53.073481Z",
          "iopub.status.idle": "2023-09-23T07:07:53.133836Z",
          "shell.execute_reply.started": "2023-09-23T07:07:53.073453Z",
          "shell.execute_reply": "2023-09-23T07:07:53.132904Z"
        },
        "trusted": true,
        "id": "XMwb2C5nRlBp"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise\n",
        "STOP = False\n",
        "current_best_ensemble_content = oof_df_content.iloc[:,0]\n",
        "# current_best_test_preds_content = test_df_content.iloc[:,0]\n",
        "MODELS = oof_df_content.iloc[:,1:]\n",
        "# weight_range = np.arange(0.01,0.51,0.01)   # or with negative weights: np.arange(-0.5,0.51,0.01)\n",
        "weight_range = np.arange(-0.5,0.51,0.01)   # or with negative weights: np.arange(-0.5,0.51,0.01)\n",
        "history = [compute_metrics((current_best_ensemble_content,y))['rmse']]\n",
        "i=0\n",
        "\n",
        "# Hill climbing\n",
        "while not STOP:\n",
        "    i+=1\n",
        "    potential_new_best_cv_score = compute_metrics((current_best_ensemble_content,y))['rmse']\n",
        "    k_best, wgt_best = None, None\n",
        "    for k in MODELS:\n",
        "        for wgt in weight_range:\n",
        "            potential_ensemble = (1-wgt) * current_best_ensemble_content + wgt * MODELS[k]\n",
        "            cv_score = compute_metrics((potential_ensemble,y))['rmse']\n",
        "            if cv_score < potential_new_best_cv_score:\n",
        "                potential_new_best_cv_score = cv_score\n",
        "                k_best, wgt_best = k, wgt\n",
        "\n",
        "    if k_best is not None:\n",
        "        current_best_ensemble_content = (1-wgt_best) * current_best_ensemble_content + wgt_best * MODELS[k_best]\n",
        "        # current_best_test_preds_content = (1-wgt_best) * current_best_test_preds_content + wgt_best * test_df_content[k_best]\n",
        "        MODELS.drop(k_best, axis=1, inplace=True)\n",
        "        if MODELS.shape[1]==0:\n",
        "            STOP = True\n",
        "        print(f'Iteration: {i}, Model added: {k_best}, Best weight: {wgt_best:.2f}, Best RMSE: {potential_new_best_cv_score:.5f}')\n",
        "        history.append(potential_new_best_cv_score)\n",
        "    else:\n",
        "        STOP = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:07:53.580208Z",
          "iopub.execute_input": "2023-09-23T07:07:53.580444Z",
          "iopub.status.idle": "2023-09-23T07:07:53.988402Z",
          "shell.execute_reply.started": "2023-09-23T07:07:53.580417Z",
          "shell.execute_reply": "2023-09-23T07:07:53.987570Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jLrdLwWRlBp",
        "outputId": "e9e3301e-212b-4576-e50b-44476a04a93c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1, Model added: debertav3large2, Best weight: 0.34, Best RMSE: 0.45371\n",
            "Iteration: 2, Model added: debertav3large1, Best weight: -0.18, Best RMSE: 0.44867\n",
            "Iteration: 3, Model added: debertav3base1, Best weight: 0.19, Best RMSE: 0.44710\n",
            "Iteration: 4, Model added: debertav3large_ind, Best weight: 0.10, Best RMSE: 0.44671\n",
            "Iteration: 5, Model added: debertav3large_1024_ind, Best weight: 0.08, Best RMSE: 0.44657\n",
            "Iteration: 6, Model added: debertav3base_ind, Best weight: -0.07, Best RMSE: 0.44632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_wording = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1]['wording_rmse'],reverse=False)}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:09:21.917769Z",
          "iopub.execute_input": "2023-09-23T07:09:21.918012Z",
          "iopub.status.idle": "2023-09-23T07:09:21.924054Z",
          "shell.execute_reply.started": "2023-09-23T07:09:21.917986Z",
          "shell.execute_reply": "2023-09-23T07:09:21.923194Z"
        },
        "trusted": true,
        "id": "846CvG-GRlBp"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_wording"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:09:37.435419Z",
          "iopub.execute_input": "2023-09-23T07:09:37.436002Z",
          "iopub.status.idle": "2023-09-23T07:09:37.442363Z",
          "shell.execute_reply.started": "2023-09-23T07:09:37.435967Z",
          "shell.execute_reply": "2023-09-23T07:09:37.441488Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35D0DrrCRlBp",
        "outputId": "06325dce-12a3-4b64-859f-dee66149f73c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'debertav3large2': {'content_rmse': 0.46874032364212037,\n",
              "  'wording_rmse': 0.6064148516998585,\n",
              "  'mcrmse': 0.5375775876709894},\n",
              " 'debertav3base_ind': {'content_rmse': 0.5042827060349722,\n",
              "  'wording_rmse': 0.611206661209505,\n",
              "  'mcrmse': 0.5577446836222386},\n",
              " 'debertav3large_ind': {'content_rmse': 0.4743638733040936,\n",
              "  'wording_rmse': 0.6302055670290027,\n",
              "  'mcrmse': 0.5522847201665482},\n",
              " 'debertav3large_freeze_18_ind': {'content_rmse': 0.4577357710838505,\n",
              "  'wording_rmse': 0.6305033929667518,\n",
              "  'mcrmse': 0.5441195820253012},\n",
              " 'debertav3base1': {'content_rmse': 0.476628584745796,\n",
              "  'wording_rmse': 0.6357522646155996,\n",
              "  'mcrmse': 0.5561904246806978},\n",
              " 'debertav3large_1024_ind': {'content_rmse': 0.46482656801171157,\n",
              "  'wording_rmse': 0.6408757193475337,\n",
              "  'mcrmse': 0.5528511436796226},\n",
              " 'debertav3large1': {'content_rmse': 0.6286460800064813,\n",
              "  'wording_rmse': 0.6878538019328642,\n",
              "  'mcrmse': 0.6582499409696727}}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oof_df_wording = pd.DataFrame()\n",
        "# test_df_wording = pd.DataFrame()\n",
        "for item in scores_wording.items():\n",
        "    oof_df_wording[item[0]]=pd.read_csv(f'{BASE_DIR}/commonlit-oof-preds/{item[0]}_oof_preds.csv')['wording'].values\n",
        "    # test_df_wording[item[0]]=pd.read_csv(f'{WORKING_DIR}/{item[0]}_test_preds.csv')['wording'].values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:09:29.926173Z",
          "iopub.execute_input": "2023-09-23T07:09:29.926419Z",
          "iopub.status.idle": "2023-09-23T07:09:29.983846Z",
          "shell.execute_reply.started": "2023-09-23T07:09:29.926392Z",
          "shell.execute_reply": "2023-09-23T07:09:29.982986Z"
        },
        "trusted": true,
        "id": "OtwLIh94RlBq"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise\n",
        "STOP = False\n",
        "current_best_ensemble_wording = oof_df_wording.iloc[:,0]\n",
        "# current_best_test_preds_wording = test_df_wording.iloc[:,0]\n",
        "MODELS = oof_df_wording.iloc[:,1:]\n",
        "# weight_range = np.arange(0.01,0.51,0.01)   # or with negative weights: np.arange(-0.5,0.51,0.01)\n",
        "weight_range = np.arange(-0.5,0.51,0.01)   # or with negative weights: np.arange(-0.5,0.51,0.01)\n",
        "history = [compute_metrics((current_best_ensemble_wording,y))['rmse']]\n",
        "i=0\n",
        "\n",
        "# Hill climbing\n",
        "while not STOP:\n",
        "    i+=1\n",
        "    potential_new_best_cv_score = compute_metrics((current_best_ensemble_wording,y))['rmse']\n",
        "    k_best, wgt_best = None, None\n",
        "    for k in MODELS:\n",
        "        for wgt in weight_range:\n",
        "            potential_ensemble = (1-wgt) * current_best_ensemble_wording + wgt * MODELS[k]\n",
        "            cv_score = compute_metrics((potential_ensemble,y))['rmse']\n",
        "            if cv_score < potential_new_best_cv_score:\n",
        "                potential_new_best_cv_score = cv_score\n",
        "                k_best, wgt_best = k, wgt\n",
        "\n",
        "    if k_best is not None:\n",
        "        current_best_ensemble_wording = (1-wgt_best) * current_best_ensemble_wording + wgt_best * MODELS[k_best]\n",
        "        # current_best_test_preds_wording = (1-wgt_best) * current_best_test_preds_wording + wgt_best * test_df_wording[k_best]\n",
        "        MODELS.drop(k_best, axis=1, inplace=True)\n",
        "        if MODELS.shape[1]==0:\n",
        "            STOP = True\n",
        "        print(f'Iteration: {i}, Model added: {k_best}, Best weight: {wgt_best:.2f}, Best RMSE: {potential_new_best_cv_score:.5f}')\n",
        "        history.append(potential_new_best_cv_score)\n",
        "    else:\n",
        "        STOP = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:10:59.001790Z",
          "iopub.execute_input": "2023-09-23T07:10:59.002052Z",
          "iopub.status.idle": "2023-09-23T07:10:59.481778Z",
          "shell.execute_reply.started": "2023-09-23T07:10:59.002023Z",
          "shell.execute_reply": "2023-09-23T07:10:59.480844Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pW19N8-RlBq",
        "outputId": "0cc47fec-a3ed-46a4-b45f-96e537741f5e"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1, Model added: debertav3base1, Best weight: 0.50, Best RMSE: 0.58936\n",
            "Iteration: 2, Model added: debertav3large_1024_ind, Best weight: 0.33, Best RMSE: 0.58412\n",
            "Iteration: 3, Model added: debertav3base_ind, Best weight: 0.29, Best RMSE: 0.58106\n",
            "Iteration: 4, Model added: debertav3large_ind, Best weight: -0.16, Best RMSE: 0.58011\n",
            "Iteration: 5, Model added: debertav3large1, Best weight: 0.08, Best RMSE: 0.57922\n",
            "Iteration: 6, Model added: debertav3large_freeze_18_ind, Best weight: 0.09, Best RMSE: 0.57885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_ensemble_preds_train = np.column_stack((current_best_ensemble_content,current_best_ensemble_wording))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:11:05.838963Z",
          "iopub.execute_input": "2023-09-23T07:11:05.839218Z",
          "iopub.status.idle": "2023-09-23T07:11:05.844110Z",
          "shell.execute_reply.started": "2023-09-23T07:11:05.839191Z",
          "shell.execute_reply": "2023-09-23T07:11:05.843260Z"
        },
        "trusted": true,
        "id": "c1h4Zu4mRlBq"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Best mcrmse: {compute_mcrmse((best_ensemble_preds_train,train[target_cols].values))}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:11:07.689568Z",
          "iopub.execute_input": "2023-09-23T07:11:07.690088Z",
          "iopub.status.idle": "2023-09-23T07:11:07.697572Z",
          "shell.execute_reply.started": "2023-09-23T07:11:07.690045Z",
          "shell.execute_reply": "2023-09-23T07:11:07.696721Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0V0ISNXRlBq",
        "outputId": "81909848-ac1b-46cd-a4d9-09a81e609b88"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best mcrmse: {'content_rmse': 0.44632080774608374, 'wording_rmse': 0.5995757313489272, 'mcrmse': 0.5229482695475054}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission"
      ],
      "metadata": {
        "id": "BaMTI87vRlBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission = pd.DataFrame()\n",
        "df_submission['student_id'] = test['student_id']\n",
        "df_submission['content'] = current_best_test_preds_content\n",
        "df_submission['wording'] = current_best_test_preds_wording\n",
        "df_submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:11:11.452269Z",
          "iopub.execute_input": "2023-09-23T07:11:11.452563Z",
          "iopub.status.idle": "2023-09-23T07:11:11.463183Z",
          "shell.execute_reply.started": "2023-09-23T07:11:11.452514Z",
          "shell.execute_reply": "2023-09-23T07:11:11.462228Z"
        },
        "trusted": true,
        "id": "Wy9GJXN7RlBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission.head(4)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T07:11:11.763005Z",
          "iopub.execute_input": "2023-09-23T07:11:11.763214Z",
          "iopub.status.idle": "2023-09-23T07:11:11.773269Z",
          "shell.execute_reply.started": "2023-09-23T07:11:11.763190Z",
          "shell.execute_reply": "2023-09-23T07:11:11.772334Z"
        },
        "trusted": true,
        "id": "8Ou-Py8SRlBq",
        "outputId": "4a6fe41e-0b6d-44e8-92a2-803b297f6acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 54,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     student_id   content   wording\n0  000000ffffff -1.433373 -1.273849\n1  222222cccccc -1.422159 -1.292670\n2  111111eeeeee -1.445878 -1.275566\n3  333333dddddd -1.425719 -1.283874",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>-1.433373</td>\n      <td>-1.273849</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>222222cccccc</td>\n      <td>-1.422159</td>\n      <td>-1.292670</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111111eeeeee</td>\n      <td>-1.445878</td>\n      <td>-1.275566</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>-1.425719</td>\n      <td>-1.283874</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SD-Z_EunRlBr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}