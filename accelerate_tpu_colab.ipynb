{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayu24/Kaggle/blob/master/accelerate_tpu_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "metadata": {
        "id": "WPcXLp1um4CK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "1-PKM2jtm96l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()         # expire any previous token(s) and upload recreated token"
      ],
      "metadata": {
        "id": "OQD-cPjDfo96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# !kaggle datasets list"
      ],
      "metadata": {
        "id": "4uWhUucofuxZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c commonlit-evaluate-student-summaries"
      ],
      "metadata": {
        "id": "HkLzyl9rfxF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir commonlit-evaluate-student-summaries"
      ],
      "metadata": {
        "id": "5G7Fxl2ogFwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip commonlit-evaluate-student-summaries.zip -d commonlit-evaluate-student-summaries/"
      ],
      "metadata": {
        "id": "vBpOPgaegKiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-28T09:42:29.174970Z",
          "iopub.execute_input": "2023-09-28T09:42:29.175369Z",
          "iopub.status.idle": "2023-09-28T09:42:44.026386Z",
          "shell.execute_reply.started": "2023-09-28T09:42:29.175336Z",
          "shell.execute_reply": "2023-09-28T09:42:44.025089Z"
        },
        "trusted": true,
        "id": "jN5aNEtwfn2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autocorrect==1.1.0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-28T09:42:44.028651Z",
          "iopub.execute_input": "2023-09-28T09:42:44.030588Z",
          "iopub.status.idle": "2023-09-28T09:42:58.616182Z",
          "shell.execute_reply.started": "2023-09-28T09:42:44.030552Z",
          "shell.execute_reply": "2023-09-28T09:42:58.615089Z"
        },
        "trusted": true,
        "id": "YKUlkpYUfn2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "id": "C-HW-L4GgSHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "jOKWtqEfhENA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "Nmto3T-Bfn2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import accelerate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import Dataset\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "import gc"
      ],
      "metadata": {
        "id": "WTcyI4tPEdtv",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:42:58.618350Z",
          "iopub.execute_input": "2023-09-28T09:42:58.618769Z",
          "iopub.status.idle": "2023-09-28T09:43:21.706054Z",
          "shell.execute_reply.started": "2023-09-28T09:42:58.618715Z",
          "shell.execute_reply": "2023-09-28T09:43:21.705076Z"
        },
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import warnings\n",
        "import logging\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "from datasets import disable_progress_bar\n",
        "warnings.simplefilter(\"ignore\")\n",
        "logging.disable(logging.ERROR)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "disable_progress_bar()\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "mtTY-CBJE8Sf",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:21.708991Z",
          "iopub.execute_input": "2023-09-28T09:43:21.709747Z",
          "iopub.status.idle": "2023-09-28T09:43:21.718857Z",
          "shell.execute_reply.started": "2023-09-28T09:43:21.709712Z",
          "shell.execute_reply": "2023-09-28T09:43:21.717969Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content\""
      ],
      "metadata": {
        "id": "1IWvFSmnG7hH",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:21.720230Z",
          "iopub.execute_input": "2023-09-28T09:43:21.721068Z",
          "iopub.status.idle": "2023-09-28T09:43:21.731763Z",
          "shell.execute_reply.started": "2023-09-28T09:43:21.721033Z",
          "shell.execute_reply": "2023-09-28T09:43:21.730783Z"
        },
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WORKING_DIR = BASE_DIR"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:21.733327Z",
          "iopub.execute_input": "2023-09-28T09:43:21.733587Z",
          "iopub.status.idle": "2023-09-28T09:43:21.747166Z",
          "shell.execute_reply.started": "2023-09-28T09:43:21.733556Z",
          "shell.execute_reply": "2023-09-28T09:43:21.746085Z"
        },
        "trusted": true,
        "id": "tNzQtz1Dfn2N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    # model_name=\"debertav3base\"\n",
        "    model_name=\"deberta-v3-large\"\n",
        "    name = \"deberta-v3-large-ind\"\n",
        "    learning_rate=1.5e-5 #1e-5\n",
        "    weight_decay=0.03\n",
        "    hidden_dropout_prob=0.0 #0.0\n",
        "    attention_probs_dropout_prob=0.0 #0.0\n",
        "    num_train_epochs=5\n",
        "    n_splits=4\n",
        "    batch_size=4 #1,4,8\n",
        "    random_seed=42 #42,102\n",
        "    save_steps=100 #500\n",
        "    max_length=512 #1024\n",
        "    n_freeze_layers=6 #6,10,12"
      ],
      "metadata": {
        "id": "v215Kr_AFIjZ",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:21.748826Z",
          "iopub.execute_input": "2023-09-28T09:43:21.749435Z",
          "iopub.status.idle": "2023-09-28T09:43:21.759876Z",
          "shell.execute_reply.started": "2023-09-28T09:43:21.749398Z",
          "shell.execute_reply": "2023-09-28T09:43:21.758964Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SEED 42\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "seed_everything(CFG.random_seed)"
      ],
      "metadata": {
        "id": "irb1_QWBFLm4",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:21.761284Z",
          "iopub.execute_input": "2023-09-28T09:43:21.761693Z",
          "iopub.status.idle": "2023-09-28T09:43:21.779331Z",
          "shell.execute_reply.started": "2023-09-28T09:43:21.761656Z",
          "shell.execute_reply": "2023-09-28T09:43:21.778408Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "RKL61NjZfn2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = f\"{BASE_DIR}/commonlit-evaluate-student-summaries/\"\n",
        "\n",
        "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
        "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
        "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
      ],
      "metadata": {
        "id": "1L0lw5e9FNkU",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:21.780848Z",
          "iopub.execute_input": "2023-09-28T09:43:21.781246Z",
          "iopub.status.idle": "2023-09-28T09:43:21.911917Z",
          "shell.execute_reply.started": "2023-09-28T09:43:21.781213Z",
          "shell.execute_reply": "2023-09-28T09:43:21.911065Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.merge(prompts_train,summaries_train,on='prompt_id')"
      ],
      "metadata": {
        "id": "0vEUlsmOGF-_",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:21.917083Z",
          "iopub.execute_input": "2023-09-28T09:43:21.917280Z",
          "iopub.status.idle": "2023-09-28T09:43:21.954412Z",
          "shell.execute_reply.started": "2023-09-28T09:43:21.917257Z",
          "shell.execute_reply": "2023-09-28T09:43:21.953564Z"
        },
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gkf = GroupKFold(n_splits=CFG.n_splits) # Since 4 prompts in training set\n",
        "\n",
        "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
        "    train.loc[val_index, \"fold\"] = i"
      ],
      "metadata": {
        "id": "udm6XYNVGbzF",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:21.957380Z",
          "iopub.execute_input": "2023-09-28T09:43:21.957577Z",
          "iopub.status.idle": "2023-09-28T09:43:21.974934Z",
          "shell.execute_reply.started": "2023-09-28T09:43:21.957553Z",
          "shell.execute_reply": "2023-09-28T09:43:21.974021Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.groupby(\"fold\").count()"
      ],
      "metadata": {
        "id": "OsdbweqWGd_A",
        "outputId": "f741d042-1fab-47aa-ee60-289b8beec4f5",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:21.976442Z",
          "iopub.execute_input": "2023-09-28T09:43:21.976702Z",
          "iopub.status.idle": "2023-09-28T09:43:22.002953Z",
          "shell.execute_reply.started": "2023-09-28T09:43:21.976669Z",
          "shell.execute_reply": "2023-09-28T09:43:22.001967Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      prompt_id  prompt_question  prompt_title  prompt_text  student_id  text  \\\n",
              "fold                                                                            \n",
              "0.0        2057             2057          2057         2057        2057  2057   \n",
              "1.0        2009             2009          2009         2009        2009  2009   \n",
              "2.0        1996             1996          1996         1996        1996  1996   \n",
              "3.0        1103             1103          1103         1103        1103  1103   \n",
              "\n",
              "      content  wording  \n",
              "fold                    \n",
              "0.0      2057     2057  \n",
              "1.0      2009     2009  \n",
              "2.0      1996     1996  \n",
              "3.0      1103     1103  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41373233-e0ce-4715-abb5-be0643b287bf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>student_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fold</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "      <td>2057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "      <td>1103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41373233-e0ce-4715-abb5-be0643b287bf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-41373233-e0ce-4715-abb5-be0643b287bf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-41373233-e0ce-4715-abb5-be0643b287bf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-850493f0-ae59-439b-9934-01260df98f5a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-850493f0-ae59-439b-9934-01260df98f5a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-850493f0-ae59-439b-9934-01260df98f5a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline components"
      ],
      "metadata": {
        "id": "_WeyZCKvQLwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(f'microsoft/{CFG.model_name}')"
      ],
      "metadata": {
        "id": "98-qQOxyGgUL",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:22.004562Z",
          "iopub.execute_input": "2023-09-28T09:43:22.004834Z",
          "iopub.status.idle": "2023-09-28T09:43:23.318875Z",
          "shell.execute_reply.started": "2023-09-28T09:43:22.004800Z",
          "shell.execute_reply": "2023-09-28T09:43:23.317903Z"
        },
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_collator = DataCollatorWithPadding(tokenizer)"
      ],
      "metadata": {
        "id": "czLB_iMzQKds",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:23.320489Z",
          "iopub.execute_input": "2023-09-28T09:43:23.320751Z",
          "iopub.status.idle": "2023-09-28T09:43:23.325899Z",
          "shell.execute_reply.started": "2023-09-28T09:43:23.320719Z",
          "shell.execute_reply": "2023-09-28T09:43:23.324692Z"
        },
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(f'microsoft/{CFG.model_name}')\n",
        "config.update({\n",
        "    \"num_labels\": 1, #2\n",
        "    \"problem_type\": 'regression',\n",
        "    \"hidden_dropout_prob\": CFG.hidden_dropout_prob,\n",
        "    \"attention_probs_dropout_prob\": CFG.attention_probs_dropout_prob\n",
        "})"
      ],
      "metadata": {
        "id": "_lgPO55CjU-T",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:23.327366Z",
          "iopub.execute_input": "2023-09-28T09:43:23.327615Z",
          "iopub.status.idle": "2023-09-28T09:43:23.352613Z",
          "shell.execute_reply.started": "2023-09-28T09:43:23.327585Z",
          "shell.execute_reply": "2023-09-28T09:43:23.351717Z"
        },
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "id": "Yo_hdtfHkh2P",
        "outputId": "cfb74569-095b-43d0-899b-65618c378ed4",
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:23.354261Z",
          "iopub.execute_input": "2023-09-28T09:43:23.354510Z",
          "iopub.status.idle": "2023-09-28T09:43:23.367074Z",
          "shell.execute_reply.started": "2023-09-28T09:43:23.354479Z",
          "shell.execute_reply": "2023-09-28T09:43:23.366046Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DebertaV2Config {\n",
              "  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n",
              "  \"attention_probs_dropout_prob\": 0.0,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.0,\n",
              "  \"hidden_size\": 1024,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"LABEL_0\"\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 4096,\n",
              "  \"label2id\": {\n",
              "    \"LABEL_0\": 0\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-07,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"max_relative_positions\": -1,\n",
              "  \"model_type\": \"deberta-v2\",\n",
              "  \"norm_rel_ebd\": \"layer_norm\",\n",
              "  \"num_attention_heads\": 16,\n",
              "  \"num_hidden_layers\": 24,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pooler_dropout\": 0,\n",
              "  \"pooler_hidden_act\": \"gelu\",\n",
              "  \"pooler_hidden_size\": 1024,\n",
              "  \"pos_att_type\": [\n",
              "    \"p2c\",\n",
              "    \"c2p\"\n",
              "  ],\n",
              "  \"position_biased_input\": false,\n",
              "  \"position_buckets\": 256,\n",
              "  \"problem_type\": \"regression\",\n",
              "  \"relative_attention\": true,\n",
              "  \"share_att_key\": true,\n",
              "  \"transformers_version\": \"4.33.3\",\n",
              "  \"type_vocab_size\": 0,\n",
              "  \"vocab_size\": 128100\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Util functions"
      ],
      "metadata": {
        "id": "ukAlGxaPQWQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "w1BFvDjhklBb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Figure out generating labels columns for batch of thousand\n",
        "def generate_tokens(examples: pd.DataFrame,mode='train',text_col='text'):\n",
        "    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,return_tensors='pt',padding='max_length')\n",
        "    if mode == 'test':\n",
        "        return encodings\n",
        "    labels = torch.from_numpy(np.column_stack((examples['content'],examples['wording'])))\n",
        "    return {**encodings, \"labels\": labels}"
      ],
      "metadata": {
        "id": "3Nv3VsZTQZE4",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:23.368850Z",
          "iopub.execute_input": "2023-09-28T09:43:23.369120Z",
          "iopub.status.idle": "2023-09-28T09:43:23.378604Z",
          "shell.execute_reply.started": "2023-09-28T09:43:23.369096Z",
          "shell.execute_reply": "2023-09-28T09:43:23.377768Z"
        },
        "trusted": true
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tokens_for_single_target(examples: pd.DataFrame,target: str,mode='train',text_col='text'):\n",
        "    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,return_tensors='pt',padding='max_length')\n",
        "    if mode == 'test':\n",
        "        return encodings\n",
        "    labels = torch.Tensor(examples[target])\n",
        "    return {**encodings, \"labels\": labels}"
      ],
      "metadata": {
        "id": "A0Kp0rVXQY60",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:23.379856Z",
          "iopub.execute_input": "2023-09-28T09:43:23.380646Z",
          "iopub.status.idle": "2023-09-28T09:43:23.392620Z",
          "shell.execute_reply.started": "2023-09-28T09:43:23.380607Z",
          "shell.execute_reply": "2023-09-28T09:43:23.391727Z"
        },
        "trusted": true
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokenizer(train.loc[0]['text'],return_tensors='np'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0jWAUDUihs8",
        "outputId": "2822c115-1a45-4e1a-c187-dd1dc66046c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokenizer(train.loc[0]['text'],return_tensors='pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ1eOJamiyRK",
        "outputId": "40395b89-31f5-44c2-a6fe-59329d76f262"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train['text'].to_numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X7hTJZ5sESy",
        "outputId": "64f12fa4-9796-4ff2-a8e0-0b413145182a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing text cols"
      ],
      "metadata": {
        "id": "Ad__5dq6Qe6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autocorrect import Speller\n",
        "speller = Speller(lang='en')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:23.394202Z",
          "iopub.execute_input": "2023-09-28T09:43:23.394476Z",
          "iopub.status.idle": "2023-09-28T09:43:23.806510Z",
          "shell.execute_reply.started": "2023-09-28T09:43:23.394445Z",
          "shell.execute_reply": "2023-09-28T09:43:23.805577Z"
        },
        "trusted": true,
        "id": "XuP5UW3Efn2R"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sep = tokenizer.sep_token\n",
        "train = train.applymap(lambda s: s.lower() if type(s)==str else s)\n",
        "train['corrected_summary_text'] = train[\"text\"].progress_apply(speller)\n",
        "train['full_text'] = train['prompt_title'] + sep + train['prompt_question'] + sep + train['corrected_summary_text']"
      ],
      "metadata": {
        "id": "H-YjXkSeQjCv",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:43:23.807797Z",
          "iopub.execute_input": "2023-09-28T09:43:23.808483Z",
          "iopub.status.idle": "2023-09-28T09:48:07.825175Z",
          "shell.execute_reply.started": "2023-09-28T09:43:23.808446Z",
          "shell.execute_reply": "2023-09-28T09:48:07.824095Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e3a3e4-12b3-4bd3-82e6-602b6f3c7824"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7165/7165 [05:51<00:00, 20.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = ['content','wording']\n",
        "text_col = 'full_text' #'text'\n",
        "text_cols = [text_col]"
      ],
      "metadata": {
        "id": "ZjR2CF-cQi8l",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:48:07.828700Z",
          "iopub.execute_input": "2023-09-28T09:48:07.829199Z",
          "iopub.status.idle": "2023-09-28T09:48:07.834566Z",
          "shell.execute_reply.started": "2023-09-28T09:48:07.829164Z",
          "shell.execute_reply": "2023-09-28T09:48:07.833619Z"
        },
        "trusted": true
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "e4VksKpFP7ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    rmse = mean_squared_error(labels.numpy(), predictions.numpy(), squared=False)\n",
        "    return {\"rmse\": rmse}\n",
        "\n",
        "def compute_mcrmse(eval_pred):\n",
        "    \"\"\"\n",
        "    Calculates mean columnwise root mean squared error\n",
        "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
        "    \"\"\"\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    col_rmse = torch.sqrt(torch.mean((preds - labels) ** 2, axis=0))\n",
        "    mcrmse = np.mean(col_rmse)\n",
        "\n",
        "    return {\n",
        "        \"content_rmse\": col_rmse[0],\n",
        "        \"wording_rmse\": col_rmse[1],\n",
        "        \"mcrmse\": mcrmse,\n",
        "    }\n",
        "\n",
        "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
        "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
        "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
        "\n",
        "    return (content_score + wording_score)/2"
      ],
      "metadata": {
        "id": "6S8_4NcqP0_V",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:48:07.836132Z",
          "iopub.execute_input": "2023-09-28T09:48:07.836617Z",
          "iopub.status.idle": "2023-09-28T09:48:07.846865Z",
          "shell.execute_reply.started": "2023-09-28T09:48:07.836582Z",
          "shell.execute_reply": "2023-09-28T09:48:07.846073Z"
        },
        "trusted": true
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU setup"
      ],
      "metadata": {
        "id": "C90HQOomSRcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch import cuda\n",
        "# device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "# cuda.empty_cache()\n",
        "# print(device)"
      ],
      "metadata": {
        "id": "9UFLK3kwSQZT",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:48:07.848526Z",
          "iopub.execute_input": "2023-09-28T09:48:07.848834Z",
          "iopub.status.idle": "2023-09-28T09:48:07.867464Z",
          "shell.execute_reply.started": "2023-09-28T09:48:07.848803Z",
          "shell.execute_reply": "2023-09-28T09:48:07.866609Z"
        },
        "trusted": true
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "_0Nu1Y3mSIQr",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:48:07.868650Z",
          "iopub.execute_input": "2023-09-28T09:48:07.868944Z",
          "iopub.status.idle": "2023-09-28T09:48:08.132134Z",
          "shell.execute_reply.started": "2023-09-28T09:48:07.868914Z",
          "shell.execute_reply": "2023-09-28T09:48:08.131007Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bb66f7-abb4-4297-979c-50983fab9ca9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training debertav3large on individual columns"
      ],
      "metadata": {
        "id": "1a39rfSzi1TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For the different target models\n",
        "for target in target_cols:\n",
        "    if os.path.exists(target):\n",
        "        shutil.rmtree(target)\n",
        "    os.mkdir(target)"
      ],
      "metadata": {
        "id": "MNq7FCpXk7H6",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:48:08.136298Z",
          "iopub.execute_input": "2023-09-28T09:48:08.137177Z",
          "iopub.status.idle": "2023-09-28T09:48:08.142958Z",
          "shell.execute_reply.started": "2023-09-28T09:48:08.137103Z",
          "shell.execute_reply": "2023-09-28T09:48:08.142079Z"
        },
        "trusted": true
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "bEX-Xys8m2U7",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:48:08.144517Z",
          "iopub.execute_input": "2023-09-28T09:48:08.144887Z",
          "iopub.status.idle": "2023-09-28T09:48:08.155775Z",
          "shell.execute_reply.started": "2023-09-28T09:48:08.144853Z",
          "shell.execute_reply": "2023-09-28T09:48:08.154943Z"
        },
        "trusted": true
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate.utils import find_executable_batch_size"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-28T09:48:08.157412Z",
          "iopub.execute_input": "2023-09-28T09:48:08.157663Z",
          "iopub.status.idle": "2023-09-28T09:48:08.168598Z",
          "shell.execute_reply.started": "2023-09-28T09:48:08.157632Z",
          "shell.execute_reply": "2023-09-28T09:48:08.167762Z"
        },
        "trusted": true,
        "id": "RYkZ4pJFfn2S"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(train,CFG,target_cols,text_cols,text_col,generate_tokens_for_single_target,BASE_DIR,config):\n",
        "    accelerator = Accelerator(mixed_precision=\"bf16\")\n",
        "    @find_executable_batch_size(starting_batch_size=CFG.batch_size)\n",
        "    def inner_loop(batch_size):\n",
        "        nonlocal accelerator\n",
        "        for target in target_cols:\n",
        "            accelerator.print(f\"Target: {target}\")\n",
        "            for fold in range(CFG.n_splits):\n",
        "                accelerator.print(f\"Fold: {fold}\")\n",
        "                fold_train_data = train[train['fold']!=fold]\n",
        "                fold_val_data = train[train['fold']==fold]\n",
        "                fold_train_dataset = Dataset.from_pandas(fold_train_data[text_cols + target_cols])\n",
        "                fold_val_dataset = Dataset.from_pandas(fold_val_data[text_cols + target_cols])\n",
        "                fold_train_tokenized = fold_train_dataset.map(lambda x: generate_tokens_for_single_target(x,target,text_col=text_col),batched=True)\n",
        "                fold_val_tokenized = fold_val_dataset.map(lambda x: generate_tokens_for_single_target(x,target,text_col=text_col),batched=True)\n",
        "                accelerator.print(f\"Number of training examples: {fold_train_tokenized.num_rows}\")\n",
        "                accelerator.print(f\"Number of validation examples: {fold_val_tokenized.num_rows}\")\n",
        "                gc.collect()\n",
        "    #             nonlocal accelerator # Ensure they can be used in our context\n",
        "                accelerator.free_memory() # Free all lingering references\n",
        "\n",
        "    #             accelerator = Accelerator(mixed_precision='fp16')\n",
        "\n",
        "                model = AutoModelForSequenceClassification.from_pretrained(f'microsoft/{CFG.model_name}',config=config)\n",
        "                # freezing embeddings layer\n",
        "                model.base_model.embeddings.requires_grad_(False)\n",
        "\n",
        "                # freezing the initial N layers\n",
        "                for k, param in model.base_model.encoder.layer.named_parameters():\n",
        "                    l = int(k.split(\".\")[0])\n",
        "                    if l < CFG.n_freeze_layers:\n",
        "                        param.requires_grad = False\n",
        "\n",
        "                model_gpu = model.to(accelerator.device)\n",
        "\n",
        "                model_dir =  f\"{target}/{CFG.name}/fold_{fold}\"\n",
        "                model_fold_dir = os.path.join(model_dir, str(fold))\n",
        "\n",
        "                training_args = TrainingArguments(\n",
        "                    output_dir = model_fold_dir,\n",
        "                    report_to='none',\n",
        "                    load_best_model_at_end=True, # select best model\n",
        "                    learning_rate=CFG.learning_rate,\n",
        "                    per_device_train_batch_size=batch_size,\n",
        "                    per_device_eval_batch_size=batch_size*2,\n",
        "                    num_train_epochs=CFG.num_train_epochs,\n",
        "                    weight_decay=CFG.weight_decay,\n",
        "                    greater_is_better=False,\n",
        "                    metric_for_best_model=\"rmse\", #mcrmse\n",
        "                    save_strategy='epoch', #steps\n",
        "                    evaluation_strategy='epoch',\n",
        "                    save_total_limit=1,\n",
        "                    gradient_accumulation_steps=4,\n",
        "                    # gradient_checkpointing=True,\n",
        "                    optim='adafactor',\n",
        "    #                 fp16=True,\n",
        "                    # save_steps = CFG.save_steps,\n",
        "                    # eval_steps = CFG.save_steps\n",
        "                )\n",
        "\n",
        "                trainer = Trainer(\n",
        "                    model = model_gpu,\n",
        "                    train_dataset = fold_train_tokenized,\n",
        "                    eval_dataset = fold_val_tokenized,\n",
        "                    args = training_args,\n",
        "                    data_collator = train_collator,\n",
        "                    tokenizer = tokenizer,\n",
        "                    compute_metrics = compute_metrics  #compute_mcrmse\n",
        "                )\n",
        "\n",
        "                trainer.train()\n",
        "                trainer.save_model(model_dir)\n",
        "\n",
        "        ##         Not needed since trainer saves everything - https://discuss.huggingface.co/t/what-is-the-purpose-of-save-pretrained/9167/2\n",
        "        #         model_gpu.save_pretrained(model_dir)\n",
        "        #         tokenizer.save_pretrained(model_dir)\n",
        "    #             model_gpu.cpu()\n",
        "                del model_gpu\n",
        "                del model\n",
        "                gc.collect()\n",
        "                accelerator.free_memory()\n",
        "        #         torch.cuda.empty_cache()\n",
        "    inner_loop()\n",
        "    accelerator.free_memory()"
      ],
      "metadata": {
        "id": "5e8WDTwvi6Yk",
        "execution": {
          "iopub.status.busy": "2023-09-28T09:48:08.175068Z",
          "iopub.execute_input": "2023-09-28T09:48:08.177161Z",
          "iopub.status.idle": "2023-09-28T09:48:08.193191Z",
          "shell.execute_reply.started": "2023-09-28T09:48:08.177125Z",
          "shell.execute_reply": "2023-09-28T09:48:08.192190Z"
        },
        "trusted": true
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator, notebook_launcher\n",
        "notebook_launcher(run,args=(train,CFG,target_cols,text_cols,text_col,generate_tokens_for_single_target,BASE_DIR,config))"
      ],
      "metadata": {
        "trusted": true,
        "id": "9Ovvn6DEfn2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CV"
      ],
      "metadata": {
        "id": "hI2KHs6TmlFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for target in target_cols:\n",
        "    for fold in range(CFG.n_splits):\n",
        "        val_data = train[train['fold']==fold]\n",
        "        val_dataset = Dataset.from_pandas(val_data[text_cols+target_cols])\n",
        "        tokenized_val_dataset = val_dataset.map(lambda x: generate_tokens_for_single_target(x,target,text_col=text_col),batched=True)\n",
        "\n",
        "        model_dir =  f\"{target}/{CFG.name}/fold_{fold}\"\n",
        "        model_fold_dir = os.path.join(model_dir, str(fold))\n",
        "\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n",
        "        model_gpu = model.to(device)\n",
        "\n",
        "        test_args = TrainingArguments(\n",
        "            output_dir=  model_fold_dir,\n",
        "            do_train = False,\n",
        "            do_predict = True,\n",
        "            per_device_eval_batch_size = CFG.batch_size,\n",
        "            dataloader_drop_last = False,\n",
        "            fp16=True\n",
        "        )\n",
        "\n",
        "        infer = Trainer(\n",
        "            model = model_gpu,\n",
        "            args = test_args,\n",
        "            tokenizer = tokenizer,\n",
        "            data_collator = train_collator\n",
        "        )\n",
        "\n",
        "        preds = infer.predict(tokenized_val_dataset)[0]\n",
        "        train.loc[val_data.index,f\"{target}_pred\"] = preds\n",
        "\n",
        "        model_gpu.cpu()\n",
        "        del model_gpu\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "JOea9_prjIyP",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_mcrmse((train[['content_pred','wording_pred']].values,train[target_cols].values)))"
      ],
      "metadata": {
        "id": "mnr-LvbMmm9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save train cols output"
      ],
      "metadata": {
        "id": "h6kn9zuZfn2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oof_preds = pd.DataFrame()\n",
        "for target in target_cols:\n",
        "    oof_preds[target] = train[f\"{target}_pred\"]\n",
        "oof_preds['student_id'] = train['student_id']\n",
        "oof_preds.to_csv(f'debertav3large_ind_oof_preds.csv',index=False)"
      ],
      "metadata": {
        "id": "Eg0a2518nX0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "gbFll_6gfn2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
        "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")"
      ],
      "metadata": {
        "id": "sHXAFNZTfn2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=pd.merge(prompts_test,summaries_test,on='prompt_id')"
      ],
      "metadata": {
        "id": "sPWhLCRMfn2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['full_text'] = test['prompt_title'] + sep + test['prompt_question'] + sep + test['text']"
      ],
      "metadata": {
        "id": "sMK_tXGmfn2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Dataset.from_pandas(test[text_cols])"
      ],
      "metadata": {
        "id": "FP0dNzvkfn2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_test_dataset = test_dataset.map(lambda x: generate_tokens(x,'test','full_text'),batched=True)"
      ],
      "metadata": {
        "id": "n4QFfNzKfn2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for target in target_cols:\n",
        "    for fold in range(CFG.n_splits):\n",
        "        model_dir =  f\"{target}/{CFG.name}/fold_{fold}\"\n",
        "        model_fold_dir = os.path.join(model_dir, str(fold))\n",
        "\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n",
        "        model_gpu = model.to(device)\n",
        "\n",
        "        test_args = TrainingArguments(\n",
        "            output_dir=  model_fold_dir,\n",
        "            do_train = False,\n",
        "            do_predict = True,\n",
        "            per_device_eval_batch_size = CFG.batch_size,\n",
        "            dataloader_drop_last = False,\n",
        "            fp16=True\n",
        "        )\n",
        "\n",
        "        infer = Trainer(\n",
        "            model = model_gpu,\n",
        "            args = test_args,\n",
        "            tokenizer = tokenizer,\n",
        "            data_collator = train_collator\n",
        "        )\n",
        "\n",
        "        preds = infer.predict(tokenized_test_dataset)[0]\n",
        "        test[f\"{target}_{fold}\"] = preds\n",
        "\n",
        "        model_gpu.cpu()\n",
        "        del model_gpu\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "IGOtqQQVfn2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Take mean of predictions across all folds\n",
        "for target in target_cols:\n",
        "    test[target] =test[[f\"{target}_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)"
      ],
      "metadata": {
        "id": "GfDOPdDYfn2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission"
      ],
      "metadata": {
        "id": "24ewheq-fn2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission = pd.DataFrame()\n",
        "df_submission['student_id'] = test['student_id']\n",
        "df_submission['content'] = 0\n",
        "df_submission['wording'] = 0\n",
        "df_submission[target_cols[0]] = test[target_cols[0]]\n",
        "df_submission[target_cols[1]] = test[target_cols[1]]\n",
        "df_submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "KG-_jzCAfn2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission.head(4)"
      ],
      "metadata": {
        "id": "1K6B2Yiqfn2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps\n",
        "\n",
        "*  changing save strategy to steps instead of epoch\n",
        "*  setting dropout probs=0.0\n",
        "*  full_text_2 = question + title + text helps.\n",
        "*  once model with best score, using different random seeds (42,102)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aAEuq0Ux6V3b"
      }
    }
  ]
}