{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install accelerate","metadata":{"execution":{"iopub.status.busy":"2023-09-28T09:42:29.174970Z","iopub.execute_input":"2023-09-28T09:42:29.175369Z","iopub.status.idle":"2023-09-28T09:42:44.026386Z","shell.execute_reply.started":"2023-09-28T09:42:29.175336Z","shell.execute_reply":"2023-09-28T09:42:44.025089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install autocorrect==1.1.0","metadata":{"execution":{"iopub.status.busy":"2023-09-28T09:42:44.028651Z","iopub.execute_input":"2023-09-28T09:42:44.030588Z","iopub.status.idle":"2023-09-28T09:42:58.616182Z","shell.execute_reply.started":"2023-09-28T09:42:44.030552Z","shell.execute_reply":"2023-09-28T09:42:58.615089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import accelerate\nimport numpy as np\nimport pandas as pd\nimport transformers\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset\nfrom transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import mean_squared_error\nimport torch\nfrom sklearn.model_selection import KFold, GroupKFold\nimport gc","metadata":{"id":"WTcyI4tPEdtv","execution":{"iopub.status.busy":"2023-09-28T09:42:58.618350Z","iopub.execute_input":"2023-09-28T09:42:58.618769Z","iopub.status.idle":"2023-09-28T09:43:21.706054Z","shell.execute_reply.started":"2023-09-28T09:42:58.618715Z","shell.execute_reply":"2023-09-28T09:43:21.705076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nimport warnings\nimport logging\nimport shutil\nfrom tqdm import tqdm\nfrom datasets import disable_progress_bar\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\ndisable_progress_bar()\ntqdm.pandas()","metadata":{"id":"mtTY-CBJE8Sf","execution":{"iopub.status.busy":"2023-09-28T09:43:21.708991Z","iopub.execute_input":"2023-09-28T09:43:21.709747Z","iopub.status.idle":"2023-09-28T09:43:21.718857Z","shell.execute_reply.started":"2023-09-28T09:43:21.709712Z","shell.execute_reply":"2023-09-28T09:43:21.717969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_DIR = \"/kaggle/input\"","metadata":{"id":"1IWvFSmnG7hH","execution":{"iopub.status.busy":"2023-09-28T09:43:21.720230Z","iopub.execute_input":"2023-09-28T09:43:21.721068Z","iopub.status.idle":"2023-09-28T09:43:21.731763Z","shell.execute_reply.started":"2023-09-28T09:43:21.721033Z","shell.execute_reply":"2023-09-28T09:43:21.730783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WORKING_DIR = \"/kaggle/working\"","metadata":{"execution":{"iopub.status.busy":"2023-09-28T09:43:21.733327Z","iopub.execute_input":"2023-09-28T09:43:21.733587Z","iopub.status.idle":"2023-09-28T09:43:21.747166Z","shell.execute_reply.started":"2023-09-28T09:43:21.733556Z","shell.execute_reply":"2023-09-28T09:43:21.746085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    # model_name=\"debertav3base\"\n    model_name=\"deberta-v3-large/deberta-v3-large\"\n    name = \"deberta-v3-large-ind\"\n    learning_rate=1.5e-5 #1e-5\n    weight_decay=0.02\n    hidden_dropout_prob=0.007 #0.0\n    attention_probs_dropout_prob=0.007 #0.0\n    num_train_epochs=5\n    n_splits=4\n    batch_size=2 #1,4,8\n    random_seed=42 #42,102\n    save_steps=100 #500\n    max_length=512 #1024\n    n_freeze_layers=6 #6,10,12","metadata":{"id":"v215Kr_AFIjZ","execution":{"iopub.status.busy":"2023-09-28T09:43:21.748826Z","iopub.execute_input":"2023-09-28T09:43:21.749435Z","iopub.status.idle":"2023-09-28T09:43:21.759876Z","shell.execute_reply.started":"2023-09-28T09:43:21.749398Z","shell.execute_reply":"2023-09-28T09:43:21.758964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SEED 42\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything(CFG.random_seed)","metadata":{"id":"irb1_QWBFLm4","execution":{"iopub.status.busy":"2023-09-28T09:43:21.761284Z","iopub.execute_input":"2023-09-28T09:43:21.761693Z","iopub.status.idle":"2023-09-28T09:43:21.779331Z","shell.execute_reply.started":"2023-09-28T09:43:21.761656Z","shell.execute_reply":"2023-09-28T09:43:21.778408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"DATA_DIR = f\"{BASE_DIR}/commonlit-evaluate-student-summaries/\"\n\nprompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\nsummaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\nsample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")","metadata":{"id":"1L0lw5e9FNkU","execution":{"iopub.status.busy":"2023-09-28T09:43:21.780848Z","iopub.execute_input":"2023-09-28T09:43:21.781246Z","iopub.status.idle":"2023-09-28T09:43:21.911917Z","shell.execute_reply.started":"2023-09-28T09:43:21.781213Z","shell.execute_reply":"2023-09-28T09:43:21.911065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.merge(prompts_train,summaries_train,on='prompt_id')","metadata":{"id":"0vEUlsmOGF-_","execution":{"iopub.status.busy":"2023-09-28T09:43:21.917083Z","iopub.execute_input":"2023-09-28T09:43:21.917280Z","iopub.status.idle":"2023-09-28T09:43:21.954412Z","shell.execute_reply.started":"2023-09-28T09:43:21.917257Z","shell.execute_reply":"2023-09-28T09:43:21.953564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gkf = GroupKFold(n_splits=CFG.n_splits) # Since 4 prompts in training set\n\nfor i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n    train.loc[val_index, \"fold\"] = i","metadata":{"id":"udm6XYNVGbzF","execution":{"iopub.status.busy":"2023-09-28T09:43:21.957380Z","iopub.execute_input":"2023-09-28T09:43:21.957577Z","iopub.status.idle":"2023-09-28T09:43:21.974934Z","shell.execute_reply.started":"2023-09-28T09:43:21.957553Z","shell.execute_reply":"2023-09-28T09:43:21.974021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"fold\").count()","metadata":{"id":"OsdbweqWGd_A","outputId":"323ef24e-1f87-4605-be4c-733e0b6056c2","execution":{"iopub.status.busy":"2023-09-28T09:43:21.976442Z","iopub.execute_input":"2023-09-28T09:43:21.976702Z","iopub.status.idle":"2023-09-28T09:43:22.002953Z","shell.execute_reply.started":"2023-09-28T09:43:21.976669Z","shell.execute_reply":"2023-09-28T09:43:22.001967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pipeline components","metadata":{"id":"_WeyZCKvQLwu"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(f'{BASE_DIR}/{CFG.model_name}')","metadata":{"id":"98-qQOxyGgUL","execution":{"iopub.status.busy":"2023-09-28T09:43:22.004562Z","iopub.execute_input":"2023-09-28T09:43:22.004834Z","iopub.status.idle":"2023-09-28T09:43:23.318875Z","shell.execute_reply.started":"2023-09-28T09:43:22.004800Z","shell.execute_reply":"2023-09-28T09:43:23.317903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_collator = DataCollatorWithPadding(tokenizer)","metadata":{"id":"czLB_iMzQKds","execution":{"iopub.status.busy":"2023-09-28T09:43:23.320489Z","iopub.execute_input":"2023-09-28T09:43:23.320751Z","iopub.status.idle":"2023-09-28T09:43:23.325899Z","shell.execute_reply.started":"2023-09-28T09:43:23.320719Z","shell.execute_reply":"2023-09-28T09:43:23.324692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(f'{BASE_DIR}/{CFG.model_name}')\nconfig.update({\n    \"num_labels\": 1, #2\n    \"problem_type\": 'regression',\n    \"hidden_dropout_prob\": CFG.hidden_dropout_prob,\n    \"attention_probs_dropout_prob\": CFG.attention_probs_dropout_prob\n})","metadata":{"id":"_lgPO55CjU-T","execution":{"iopub.status.busy":"2023-09-28T09:43:23.327366Z","iopub.execute_input":"2023-09-28T09:43:23.327615Z","iopub.status.idle":"2023-09-28T09:43:23.352613Z","shell.execute_reply.started":"2023-09-28T09:43:23.327585Z","shell.execute_reply":"2023-09-28T09:43:23.351717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"id":"Yo_hdtfHkh2P","outputId":"18ac4f11-042c-47f7-b52b-06646ccb26fb","_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-28T09:43:23.354261Z","iopub.execute_input":"2023-09-28T09:43:23.354510Z","iopub.status.idle":"2023-09-28T09:43:23.367074Z","shell.execute_reply.started":"2023-09-28T09:43:23.354479Z","shell.execute_reply":"2023-09-28T09:43:23.366046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Util functions","metadata":{"id":"ukAlGxaPQWQG"}},{"cell_type":"code","source":"## Figure out generating labels columns for batch of thousand\ndef generate_tokens(examples: pd.DataFrame,mode='train',text_col='text'):\n    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,return_tensors='np')\n    if mode == 'test':\n        return encodings\n    labels = np.column_stack((examples['content'],examples['wording']))\n    return {**encodings, \"labels\": labels}","metadata":{"id":"3Nv3VsZTQZE4","execution":{"iopub.status.busy":"2023-09-28T09:43:23.368850Z","iopub.execute_input":"2023-09-28T09:43:23.369120Z","iopub.status.idle":"2023-09-28T09:43:23.378604Z","shell.execute_reply.started":"2023-09-28T09:43:23.369096Z","shell.execute_reply":"2023-09-28T09:43:23.377768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_tokens_for_single_target(examples: pd.DataFrame,target: str,mode='train',text_col='text'):\n    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,return_tensors='np')\n    if mode == 'test':\n        return encodings\n    labels = examples[target]\n    return {**encodings, \"labels\": labels}","metadata":{"id":"A0Kp0rVXQY60","execution":{"iopub.status.busy":"2023-09-28T09:43:23.379856Z","iopub.execute_input":"2023-09-28T09:43:23.380646Z","iopub.status.idle":"2023-09-28T09:43:23.392620Z","shell.execute_reply.started":"2023-09-28T09:43:23.380607Z","shell.execute_reply":"2023-09-28T09:43:23.391727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing text cols","metadata":{"id":"Ad__5dq6Qe6i"}},{"cell_type":"code","source":"from autocorrect import Speller\nspeller = Speller(lang='en')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T09:43:23.394202Z","iopub.execute_input":"2023-09-28T09:43:23.394476Z","iopub.status.idle":"2023-09-28T09:43:23.806510Z","shell.execute_reply.started":"2023-09-28T09:43:23.394445Z","shell.execute_reply":"2023-09-28T09:43:23.805577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sep = tokenizer.sep_token\ntrain = train.applymap(lambda s: s.lower() if type(s)==str else s)\ntrain['corrected_summary_text'] = train[\"text\"].progress_apply(speller)\ntrain['full_text'] = train['prompt_title'] + sep + train['prompt_question'] + sep + train['corrected_summary_text']","metadata":{"id":"H-YjXkSeQjCv","execution":{"iopub.status.busy":"2023-09-28T09:43:23.807797Z","iopub.execute_input":"2023-09-28T09:43:23.808483Z","iopub.status.idle":"2023-09-28T09:48:07.825175Z","shell.execute_reply.started":"2023-09-28T09:43:23.808446Z","shell.execute_reply":"2023-09-28T09:48:07.824095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cols = ['content','wording']\ntext_col = 'full_text' #'text'\ntext_cols = [text_col]","metadata":{"id":"ZjR2CF-cQi8l","execution":{"iopub.status.busy":"2023-09-28T09:48:07.828700Z","iopub.execute_input":"2023-09-28T09:48:07.829199Z","iopub.status.idle":"2023-09-28T09:48:07.834566Z","shell.execute_reply.started":"2023-09-28T09:48:07.829164Z","shell.execute_reply":"2023-09-28T09:48:07.833619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics","metadata":{"id":"e4VksKpFP7ch"}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    rmse = mean_squared_error(labels, predictions, squared=False)\n    return {\"rmse\": rmse}\n\ndef compute_mcrmse(eval_pred):\n    \"\"\"\n    Calculates mean columnwise root mean squared error\n    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n    \"\"\"\n    preds, labels = eval_pred\n\n    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n    mcrmse = np.mean(col_rmse)\n\n    return {\n        \"content_rmse\": col_rmse[0],\n        \"wording_rmse\": col_rmse[1],\n        \"mcrmse\": mcrmse,\n    }\n\ndef compt_score(content_true, content_pred, wording_true, wording_pred):\n    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n\n    return (content_score + wording_score)/2","metadata":{"id":"6S8_4NcqP0_V","execution":{"iopub.status.busy":"2023-09-28T09:48:07.836132Z","iopub.execute_input":"2023-09-28T09:48:07.836617Z","iopub.status.idle":"2023-09-28T09:48:07.846865Z","shell.execute_reply.started":"2023-09-28T09:48:07.836582Z","shell.execute_reply":"2023-09-28T09:48:07.846073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GPU setup","metadata":{"id":"C90HQOomSRcu"}},{"cell_type":"code","source":"# from torch import cuda\n# device = 'cuda' if cuda.is_available() else 'cpu'\n# cuda.empty_cache()\n# print(device)","metadata":{"id":"9UFLK3kwSQZT","outputId":"3e3dd424-2310-4817-a325-87c03e7b5450","execution":{"iopub.status.busy":"2023-09-28T09:48:07.848526Z","iopub.execute_input":"2023-09-28T09:48:07.848834Z","iopub.status.idle":"2023-09-28T09:48:07.867464Z","shell.execute_reply.started":"2023-09-28T09:48:07.848803Z","shell.execute_reply":"2023-09-28T09:48:07.866609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\n# torch.cuda.empty_cache()","metadata":{"id":"_0Nu1Y3mSIQr","execution":{"iopub.status.busy":"2023-09-28T09:48:07.868650Z","iopub.execute_input":"2023-09-28T09:48:07.868944Z","iopub.status.idle":"2023-09-28T09:48:08.132134Z","shell.execute_reply.started":"2023-09-28T09:48:07.868914Z","shell.execute_reply":"2023-09-28T09:48:08.131007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training debertav3large on individual columns","metadata":{"id":"1a39rfSzi1TQ"}},{"cell_type":"code","source":"# For the different target models\nfor target in target_cols:\n    if os.path.exists(target):\n        shutil.rmtree(target)\n    os.mkdir(target)","metadata":{"id":"MNq7FCpXk7H6","execution":{"iopub.status.busy":"2023-09-28T09:48:08.136298Z","iopub.execute_input":"2023-09-28T09:48:08.137177Z","iopub.status.idle":"2023-09-28T09:48:08.142958Z","shell.execute_reply.started":"2023-09-28T09:48:08.137103Z","shell.execute_reply":"2023-09-28T09:48:08.142079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gc.collect()\n# torch.cuda.empty_cache()","metadata":{"id":"bEX-Xys8m2U7","execution":{"iopub.status.busy":"2023-09-28T09:48:08.144517Z","iopub.execute_input":"2023-09-28T09:48:08.144887Z","iopub.status.idle":"2023-09-28T09:48:08.155775Z","shell.execute_reply.started":"2023-09-28T09:48:08.144853Z","shell.execute_reply":"2023-09-28T09:48:08.154943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from accelerate.utils import find_executable_batch_size","metadata":{"execution":{"iopub.status.busy":"2023-09-28T09:48:08.157412Z","iopub.execute_input":"2023-09-28T09:48:08.157663Z","iopub.status.idle":"2023-09-28T09:48:08.168598Z","shell.execute_reply.started":"2023-09-28T09:48:08.157632Z","shell.execute_reply":"2023-09-28T09:48:08.167762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(train,CFG,target_cols,text_cols,text_col,generate_tokens_for_single_target,BASE_DIR,config):\n    accelerator = Accelerator()\n    @find_executable_batch_size(starting_batch_size=CFG.batch_size)\n    def inner_loop(batch_size):\n        nonlocal accelerator\n        for target in target_cols:\n            accelerator.print(f\"Target: {target}\")\n            for fold in range(CFG.n_splits):\n                accelerator.print(f\"Fold: {fold}\")\n                fold_train_data = train[train['fold']!=fold]\n                fold_val_data = train[train['fold']==fold]\n                fold_train_dataset = Dataset.from_pandas(fold_train_data[text_cols + target_cols])\n                fold_val_dataset = Dataset.from_pandas(fold_val_data[text_cols + target_cols])\n                fold_train_tokenized = fold_train_dataset.map(lambda x: generate_tokens_for_single_target(x,target,text_col=text_col),batched=True)\n                fold_val_tokenized = fold_val_dataset.map(lambda x: generate_tokens_for_single_target(x,target,text_col=text_col),batched=True)\n                accelerator.print(f\"Number of training examples: {fold_train_tokenized.num_rows}\")\n                accelerator.print(f\"Number of validation examples: {fold_val_tokenized.num_rows}\")\n                gc.collect()\n    #             nonlocal accelerator # Ensure they can be used in our context\n                accelerator.free_memory() # Free all lingering references\n\n    #             accelerator = Accelerator(mixed_precision='fp16')\n\n                model = AutoModelForSequenceClassification.from_pretrained(f'{BASE_DIR}/{CFG.model_name}',config=config)\n                # freezing embeddings layer\n                model.base_model.embeddings.requires_grad_(False)\n\n                # freezing the initial N layers\n                for k, param in model.base_model.encoder.layer.named_parameters():\n                    l = int(k.split(\".\")[0])\n                    if l < CFG.n_freeze_layers:\n                        param.requires_grad = False\n\n                model_gpu = model.to(accelerator.device)\n\n                model_dir =  f\"{target}/{CFG.name}/fold_{fold}\"\n                model_fold_dir = os.path.join(model_dir, str(fold))\n\n                training_args = TrainingArguments(\n                    output_dir = model_fold_dir,\n                    report_to='none',\n                    load_best_model_at_end=True, # select best model\n                    learning_rate=CFG.learning_rate,\n                    per_device_train_batch_size=batch_size,\n                    per_device_eval_batch_size=batch_size*2,\n                    num_train_epochs=CFG.num_train_epochs,\n                    weight_decay=CFG.weight_decay,\n                    greater_is_better=False,\n                    metric_for_best_model=\"rmse\", #mcrmse\n                    save_strategy='epoch', #steps\n                    evaluation_strategy='epoch',\n                    save_total_limit=1,\n                    gradient_accumulation_steps=4,\n                    # gradient_checkpointing=True,\n                    optim='adafactor',\n    #                 fp16=True,\n                    # save_steps = CFG.save_steps,\n                    # eval_steps = CFG.save_steps\n                )\n\n                trainer = Trainer(\n                    model = model_gpu,\n                    train_dataset = fold_train_tokenized,\n                    eval_dataset = fold_val_tokenized,\n                    args = training_args,\n                    data_collator = train_collator,\n                    tokenizer = tokenizer,\n                    compute_metrics = compute_metrics  #compute_mcrmse\n                )\n\n                trainer.train()\n                trainer.save_model(model_dir)\n\n        ##         Not needed since trainer saves everything - https://discuss.huggingface.co/t/what-is-the-purpose-of-save-pretrained/9167/2\n        #         model_gpu.save_pretrained(model_dir)\n        #         tokenizer.save_pretrained(model_dir)\n    #             model_gpu.cpu()\n                del model_gpu\n                del model\n                gc.collect()\n                accelerator.free_memory()\n        #         torch.cuda.empty_cache()\n    inner_loop()\n    accelerator.free_memory()","metadata":{"id":"5e8WDTwvi6Yk","outputId":"d14799d0-3bb7-4b94-987b-e25bbf2b69d2","execution":{"iopub.status.busy":"2023-09-28T09:48:08.175068Z","iopub.execute_input":"2023-09-28T09:48:08.177161Z","iopub.status.idle":"2023-09-28T09:48:08.193191Z","shell.execute_reply.started":"2023-09-28T09:48:08.177125Z","shell.execute_reply":"2023-09-28T09:48:08.192190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from accelerate import Accelerator, notebook_launcher\nnotebook_launcher(run,args=(train,CFG,target_cols,text_cols,text_col,generate_tokens_for_single_target,BASE_DIR,config),num_processes=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CV","metadata":{"id":"hI2KHs6TmlFH"}},{"cell_type":"code","source":"for target in target_cols:\n    for fold in range(CFG.n_splits):\n        val_data = train[train['fold']==fold]\n        val_dataset = Dataset.from_pandas(val_data[text_cols+target_cols])\n        tokenized_val_dataset = val_dataset.map(lambda x: generate_tokens_for_single_target(x,target,text_col=text_col),batched=True)\n\n        model_dir =  f\"{target}/{CFG.name}/fold_{fold}\"\n        model_fold_dir = os.path.join(model_dir, str(fold))\n\n        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n        model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n        model_gpu = model.to(device)\n\n        test_args = TrainingArguments(\n            output_dir=  model_fold_dir,\n            do_train = False,\n            do_predict = True,\n            per_device_eval_batch_size = CFG.batch_size,\n            dataloader_drop_last = False,\n            fp16=True\n        )\n\n        infer = Trainer(\n            model = model_gpu,\n            args = test_args,\n            tokenizer = tokenizer,\n            data_collator = train_collator\n        )\n\n        preds = infer.predict(tokenized_val_dataset)[0]\n        train.loc[val_data.index,f\"{target}_pred\"] = preds\n\n        model_gpu.cpu()\n        del model_gpu\n        gc.collect()\n        torch.cuda.empty_cache()","metadata":{"id":"JOea9_prjIyP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(compute_mcrmse((train[['content_pred','wording_pred']].values,train[target_cols].values)))","metadata":{"id":"mnr-LvbMmm9a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Save train cols output","metadata":{}},{"cell_type":"code","source":"oof_preds = pd.DataFrame()\nfor target in target_cols:\n    oof_preds[target] = train[f\"{target}_pred\"]\noof_preds['student_id'] = train['student_id']\noof_preds.to_csv(f'debertav3large_ind_oof_preds.csv',index=False)","metadata":{"id":"Eg0a2518nX0O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\nsummaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=pd.merge(prompts_test,summaries_test,on='prompt_id')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['full_text'] = test['prompt_title'] + sep + test['prompt_question'] + sep + test['text']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = Dataset.from_pandas(test[text_cols])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_dataset = test_dataset.map(lambda x: generate_tokens(x,'test','full_text'),batched=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for target in target_cols:    \n    for fold in range(CFG.n_splits):\n        model_dir =  f\"{target}/{CFG.name}/fold_{fold}\"\n        model_fold_dir = os.path.join(model_dir, str(fold))\n\n        model = AutoModelForSequenceClassification.from_pretrained(model_dir)    \n        model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n        model_gpu = model.to(device)\n\n        test_args = TrainingArguments(\n            output_dir=  model_fold_dir,\n            do_train = False,\n            do_predict = True,\n            per_device_eval_batch_size = CFG.batch_size,   \n            dataloader_drop_last = False,\n            fp16=True\n        )\n\n        infer = Trainer(\n            model = model_gpu,\n            args = test_args,\n            tokenizer = tokenizer,\n            data_collator = train_collator\n        )\n\n        preds = infer.predict(tokenized_test_dataset)[0]\n        test[f\"{target}_{fold}\"] = preds\n\n        model_gpu.cpu()\n        del model_gpu\n        gc.collect()\n        torch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Take mean of predictions across all folds\nfor target in target_cols:\n    test[target] =test[[f\"{target}_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"df_submission = pd.DataFrame()\ndf_submission['student_id'] = test['student_id']\ndf_submission['content'] = 0\ndf_submission['wording'] = 0\ndf_submission[target_cols[0]] = test[target_cols[0]]\ndf_submission[target_cols[1]] = test[target_cols[1]]\ndf_submission.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission.head(4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Next steps\n\n*  changing save strategy to steps instead of epoch \n*  setting dropout probs=0.0\n*  full_text_2 = question + title + text helps.\n*  once model with best score, using different random seeds (42,102)\n\n\n\n\n\n\n","metadata":{"id":"aAEuq0Ux6V3b"}}]}