{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-27T11:53:20.163734Z","iopub.execute_input":"2023-09-27T11:53:20.164151Z","iopub.status.idle":"2023-09-27T11:53:20.195190Z","shell.execute_reply.started":"2023-09-27T11:53:20.164116Z","shell.execute_reply":"2023-09-27T11:53:20.194368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Installing offline libraries","metadata":{}},{"cell_type":"code","source":"!python -m pip install --no-index --find-links=../input/autocorrect-offline-install -r ../input/autocorrect-offline-install/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:01.208111Z","iopub.execute_input":"2023-09-28T06:43:01.208495Z","iopub.status.idle":"2023-09-28T06:43:17.522067Z","shell.execute_reply.started":"2023-09-28T06:43:01.208439Z","shell.execute_reply":"2023-09-28T06:43:17.520644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport transformers\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset\nfrom transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import mean_squared_error\nimport torch\nfrom sklearn.model_selection import KFold, GroupKFold\nimport gc","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:17.524736Z","iopub.execute_input":"2023-09-28T06:43:17.525117Z","iopub.status.idle":"2023-09-28T06:43:32.375761Z","shell.execute_reply.started":"2023-09-28T06:43:17.525079Z","shell.execute_reply":"2023-09-28T06:43:32.374669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nimport warnings\nimport logging\nimport shutil\nfrom tqdm import tqdm\nfrom datasets import disable_progress_bar\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \ndisable_progress_bar()\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:32.378644Z","iopub.execute_input":"2023-09-28T06:43:32.379763Z","iopub.status.idle":"2023-09-28T06:43:32.388364Z","shell.execute_reply.started":"2023-09-28T06:43:32.379724Z","shell.execute_reply":"2023-09-28T06:43:32.386960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n#     model_name=\"debertav3base\"\n    model_name=\"deberta-v3-large/deberta-v3-large\"\n    debug=False\n    learning_rate=1.5e-5\n    weight_decay=0.02\n    hidden_dropout_prob=0.007\n    attention_probs_dropout_prob=0.007\n    num_train_epochs=5\n    n_splits=4\n    batch_size=8 #4,8\n    random_seed=42\n    save_steps=500 #100\n    max_length=512 #1024\n    n_freeze_layers=6 #12","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:32.393288Z","iopub.execute_input":"2023-09-28T06:43:32.393509Z","iopub.status.idle":"2023-09-28T06:43:32.402171Z","shell.execute_reply.started":"2023-09-28T06:43:32.393483Z","shell.execute_reply":"2023-09-28T06:43:32.401099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SEED 42\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything(CFG.random_seed)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:32.403557Z","iopub.execute_input":"2023-09-28T06:43:32.404187Z","iopub.status.idle":"2023-09-28T06:43:32.417508Z","shell.execute_reply.started":"2023-09-28T06:43:32.404150Z","shell.execute_reply":"2023-09-28T06:43:32.416386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading Data","metadata":{}},{"cell_type":"code","source":"BASE_DIR = \"/kaggle/input\"","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:32.419280Z","iopub.execute_input":"2023-09-28T06:43:32.419584Z","iopub.status.idle":"2023-09-28T06:43:32.424895Z","shell.execute_reply.started":"2023-09-28T06:43:32.419547Z","shell.execute_reply":"2023-09-28T06:43:32.423694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WORKING_DIR = \"/kaggle/working\"","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:32.426608Z","iopub.execute_input":"2023-09-28T06:43:32.426878Z","iopub.status.idle":"2023-09-28T06:43:32.436262Z","shell.execute_reply.started":"2023-09-28T06:43:32.426843Z","shell.execute_reply":"2023-09-28T06:43:32.435121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir {WORKING_DIR}/commonlit-oof-preds","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:32.438040Z","iopub.execute_input":"2023-09-28T06:43:32.438546Z","iopub.status.idle":"2023-09-28T06:43:33.482770Z","shell.execute_reply.started":"2023-09-28T06:43:32.438428Z","shell.execute_reply":"2023-09-28T06:43:33.481516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = f\"{BASE_DIR}/commonlit-evaluate-student-summaries/\"\n\nprompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\nsummaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\nsample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:33.484939Z","iopub.execute_input":"2023-09-28T06:43:33.485223Z","iopub.status.idle":"2023-09-28T06:43:33.598046Z","shell.execute_reply.started":"2023-09-28T06:43:33.485187Z","shell.execute_reply":"2023-09-28T06:43:33.597056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.merge(prompts_train,summaries_train,on='prompt_id')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:33.602980Z","iopub.execute_input":"2023-09-28T06:43:33.603431Z","iopub.status.idle":"2023-09-28T06:43:33.635197Z","shell.execute_reply.started":"2023-09-28T06:43:33.603402Z","shell.execute_reply":"2023-09-28T06:43:33.634175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gkf = GroupKFold(n_splits=CFG.n_splits) # Since 4 prompts in training set\n\nfor i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n    train.loc[val_index, \"fold\"] = i","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:33.637159Z","iopub.execute_input":"2023-09-28T06:43:33.637509Z","iopub.status.idle":"2023-09-28T06:43:33.657543Z","shell.execute_reply.started":"2023-09-28T06:43:33.637472Z","shell.execute_reply":"2023-09-28T06:43:33.656516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"fold\").count()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:33.659251Z","iopub.execute_input":"2023-09-28T06:43:33.659551Z","iopub.status.idle":"2023-09-28T06:43:33.692696Z","shell.execute_reply.started":"2023-09-28T06:43:33.659514Z","shell.execute_reply":"2023-09-28T06:43:33.691591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.debug:\n    display(train.groupby('fold').size())\n    train = train.sample(n=10, random_state=42).reset_index(drop=True)\n    display(train.groupby('fold').size())","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:33.694743Z","iopub.execute_input":"2023-09-28T06:43:33.695042Z","iopub.status.idle":"2023-09-28T06:43:33.701481Z","shell.execute_reply.started":"2023-09-28T06:43:33.695002Z","shell.execute_reply":"2023-09-28T06:43:33.700495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenizer and Collator","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(f'{BASE_DIR}/{CFG.model_name}')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:33.702964Z","iopub.execute_input":"2023-09-28T06:43:33.703998Z","iopub.status.idle":"2023-09-28T06:43:34.994778Z","shell.execute_reply.started":"2023-09-28T06:43:33.703955Z","shell.execute_reply":"2023-09-28T06:43:34.993731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_collator = DataCollatorWithPadding(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:34.996309Z","iopub.execute_input":"2023-09-28T06:43:34.996665Z","iopub.status.idle":"2023-09-28T06:43:35.001832Z","shell.execute_reply.started":"2023-09-28T06:43:34.996629Z","shell.execute_reply":"2023-09-28T06:43:35.000750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Figure out generating labels columns for batch of thousand\ndef generate_tokens(examples: pd.DataFrame,mode='train',text_col='text'):\n    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,return_tensors='np')\n    if mode == 'test':\n        return encodings\n    labels = np.column_stack((examples['content'],examples['wording']))\n    return {**encodings, \"labels\": labels}","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:35.003538Z","iopub.execute_input":"2023-09-28T06:43:35.003851Z","iopub.status.idle":"2023-09-28T06:43:35.013088Z","shell.execute_reply.started":"2023-09-28T06:43:35.003817Z","shell.execute_reply":"2023-09-28T06:43:35.011843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_tokens_for_single_target(examples: pd.DataFrame,target: str,mode='train',text_col='text'):\n    encodings = tokenizer(examples[text_col],truncation=True,max_length=CFG.max_length,return_tensors='np')\n    if mode == 'test':\n        return encodings\n    labels = examples[target]\n    return {**encodings, \"labels\": labels}","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:35.014873Z","iopub.execute_input":"2023-09-28T06:43:35.015199Z","iopub.status.idle":"2023-09-28T06:43:35.024472Z","shell.execute_reply.started":"2023-09-28T06:43:35.015164Z","shell.execute_reply":"2023-09-28T06:43:35.023562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Text cols","metadata":{}},{"cell_type":"code","source":"from autocorrect import Speller\nspeller = Speller(lang='en')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:43:37.374468Z","iopub.execute_input":"2023-09-28T06:43:37.374768Z","iopub.status.idle":"2023-09-28T06:43:37.824639Z","shell.execute_reply.started":"2023-09-28T06:43:37.374738Z","shell.execute_reply":"2023-09-28T06:43:37.823740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sep = tokenizer.sep_token\ntrain = train.applymap(lambda s: s.lower() if type(s)==str else s)\ntrain['corrected_summary_text'] = train[\"text\"].progress_apply(speller)\ntrain['full_text'] = train['prompt_title'] + sep + train['prompt_question'] + sep + train['corrected_summary_text']","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:44:12.844187Z","iopub.execute_input":"2023-09-28T06:44:12.844496Z","iopub.status.idle":"2023-09-28T06:49:27.409889Z","shell.execute_reply.started":"2023-09-28T06:44:12.844440Z","shell.execute_reply":"2023-09-28T06:49:27.408992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cols = ['content','wording']\ntext_col = 'full_text' #'text'\ntext_cols = [text_col]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:49:27.411961Z","iopub.execute_input":"2023-09-28T06:49:27.412483Z","iopub.status.idle":"2023-09-28T06:49:27.417502Z","shell.execute_reply.started":"2023-09-28T06:49:27.412420Z","shell.execute_reply":"2023-09-28T06:49:27.416510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre-trained Models","metadata":{}},{"cell_type":"code","source":"CONFIG_MULTI = {\n    \"debertav3base1\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/weights/weights/debertav3base\",\n    \"debertav3large1\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/deberta-v3-large/deberta-v3-large/deberta-v3-large\",\n    \"debertav3large2\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/deberta-v3-large-freeze-6/deberta-v3-large-freeze-6\"\n}","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:49:27.418996Z","iopub.execute_input":"2023-09-28T06:49:27.419482Z","iopub.status.idle":"2023-09-28T06:49:27.431561Z","shell.execute_reply.started":"2023-09-28T06:49:27.419429Z","shell.execute_reply":"2023-09-28T06:49:27.430502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_models = [\"debertav3base1\",\"debertav3large1\",\"debertav3large2\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:49:27.434715Z","iopub.execute_input":"2023-09-28T06:49:27.435198Z","iopub.status.idle":"2023-09-28T06:49:27.448708Z","shell.execute_reply.started":"2023-09-28T06:49:27.435081Z","shell.execute_reply":"2023-09-28T06:49:27.447372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG_IND = {\n    \"debertav3base_ind_content\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/v3_small_individual_targets/v3_small_individual_targets/content/debertav3base\",\n    \"debertav3base_ind_wording\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/v3_small_individual_targets/v3_small_individual_targets/wording/debertav3base\",\n    \"debertav3large_ind_content\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/deberta-v3-large-ind-autocorrect/commonlit-deberta-v3-weights/content/deberta-v3-large-ind\",\n    \"debertav3large_ind_wording\" : f\"{BASE_DIR}/debertav3large-weights-for-commonlit/deberta-v3-large-ind-autocorrect/commonlit-deberta-v3-weights/wording/deberta-v3-large-ind\",\n    \"debertav3large_freeze_18_ind_content\" : f\"{BASE_DIR}/commonlit-deberta-v3-ind-freeze-18/content/deberta-v3-large-ind\" ,\n    \"debertav3large_freeze_18_ind_wording\": f\"{BASE_DIR}/commonlit-deberta-v3-ind-freeze-18/wording/deberta-v3-large-ind\",\n    \"debertav3large_1024_ind_content\": f\"{BASE_DIR}/deberta-v3-weights-ind-seq-len-1024/content/deberta-v3-large-ind\",\n    \"debertav3large_1024_ind_wording\": f\"{BASE_DIR}/deberta-v3-weights-ind-seq-len-1024/wording/deberta-v3-large-ind\",\n    \"debertav3large_freeze_18_step_eval_ind_content\": f\"{BASE_DIR}/debertav3-large-freeze-18-steps-eval/content/deberta-v3-large-ind\",\n    \"debertav3large_freeze_18_step_eval_ind_wording\": f\"{BASE_DIR}/debertav3-large-freeze-18-steps-eval/wording/deberta-v3-large-ind\"\n}","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:49:27.450536Z","iopub.execute_input":"2023-09-28T06:49:27.450813Z","iopub.status.idle":"2023-09-28T06:49:27.460968Z","shell.execute_reply.started":"2023-09-28T06:49:27.450777Z","shell.execute_reply":"2023-09-28T06:49:27.459958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind_models = [\"debertav3base_ind\",\"debertav3large_ind\",\"debertav3large_freeze_18_ind\",\"debertav3large_1024_ind\",\"debertav3large_freeze_18_step_eval_ind\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:49:27.462683Z","iopub.execute_input":"2023-09-28T06:49:27.463652Z","iopub.status.idle":"2023-09-28T06:49:27.474029Z","shell.execute_reply.started":"2023-09-28T06:49:27.463572Z","shell.execute_reply":"2023-09-28T06:49:27.473036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    rmse = mean_squared_error(labels, predictions, squared=False)\n    return {\"rmse\": rmse}\n\ndef compute_mcrmse(eval_pred):\n    \"\"\"\n    Calculates mean columnwise root mean squared error\n    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n    \"\"\"\n    preds, labels = eval_pred\n\n    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n    mcrmse = np.mean(col_rmse)\n\n    return {\n        \"content_rmse\": col_rmse[0],\n        \"wording_rmse\": col_rmse[1],\n        \"mcrmse\": mcrmse,\n    }\n\ndef compt_score(content_true, content_pred, wording_true, wording_pred):\n    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n    \n    return (content_score + wording_score)/2","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:49:27.475423Z","iopub.execute_input":"2023-09-28T06:49:27.476226Z","iopub.status.idle":"2023-09-28T06:49:27.489009Z","shell.execute_reply.started":"2023-09-28T06:49:27.476191Z","shell.execute_reply":"2023-09-28T06:49:27.487900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GPU setup","metadata":{}},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\ncuda.empty_cache()\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:49:27.490435Z","iopub.execute_input":"2023-09-28T06:49:27.490780Z","iopub.status.idle":"2023-09-28T06:49:27.528124Z","shell.execute_reply.started":"2023-09-28T06:49:27.490738Z","shell.execute_reply":"2023-09-28T06:49:27.527391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:49:27.529595Z","iopub.execute_input":"2023-09-28T06:49:27.530395Z","iopub.status.idle":"2023-09-28T06:49:27.864691Z","shell.execute_reply.started":"2023-09-28T06:49:27.530358Z","shell.execute_reply":"2023-09-28T06:49:27.863287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions on train set ","metadata":{}},{"cell_type":"code","source":"# for multi_model in multi_models:\n#     print(f'Model: {multi_model}')\n#     oof_preds = pd.DataFrame()\n#     for fold in range(CFG.n_splits):\n#         val_data = train[train['fold']==fold]\n#         val_dataset = Dataset.from_pandas(val_data[text_cols+target_cols])\n#         tokenized_val_dataset = val_dataset.map(lambda x: generate_tokens(x,text_col=text_col),batched=True)\n\n#         pretrained_model_dir = f\"{CONFIG_MULTI[multi_model]}/fold_{fold}\"\n#         model_dir = f\"{multi_model}/fold_{fold}\"\n#         model_fold_dir = os.path.join(model_dir, str(fold))\n\n#         model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_dir)\n#         model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n#         model_gpu = model.to(device)\n\n#         test_args = TrainingArguments(\n#             output_dir=  model_fold_dir,\n#             do_train = False,\n#             do_predict = True,\n#             per_device_eval_batch_size = CFG.batch_size,\n#             dataloader_drop_last = False,\n# #             fp16=True\n#         )\n\n#         infer = Trainer(\n#             model = model_gpu,\n#             args = test_args,\n#             tokenizer = tokenizer,\n#             data_collator = train_collator\n#         )\n\n#         preds = infer.predict(tokenized_val_dataset)[0]\n#         train.loc[val_data.index,f\"{multi_model}_content_pred\"] = preds[:,0]\n#         train.loc[val_data.index,f\"{multi_model}_wording_pred\"] = preds[:,1]\n\n#         model_gpu.cpu()\n#         del model_gpu\n#         del model\n#         gc.collect()\n#         torch.cuda.empty_cache()\n\n#     print(f\"Saving {multi_model} oof preds in csv file.\")\n#     for target in target_cols:\n#         oof_preds[target] = train[f\"{multi_model}_{target}_pred\"]\n#     oof_preds.to_csv(f\"{WORKING_DIR}/commonlit-oof-preds/{multi_model}_oof_preds.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T11:53:58.079850Z","iopub.execute_input":"2023-09-27T11:53:58.080171Z","iopub.status.idle":"2023-09-27T11:58:52.824843Z","shell.execute_reply.started":"2023-09-27T11:53:58.080131Z","shell.execute_reply":"2023-09-27T11:58:52.824065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for ind_model in ind_models:\n#     print(f'Model: {ind_model}')\n#     oof_preds=pd.DataFrame()\n#     for target in target_cols:\n#         for fold in range(CFG.n_splits):\n#             val_data = train[train['fold']==fold]\n#             val_dataset = Dataset.from_pandas(val_data[text_cols+target_cols])\n#             tokenized_val_dataset = val_dataset.map(lambda x: generate_tokens_for_single_target(x,target,text_col=text_col),batched=True)\n#             pretrained_model_dir = f\"{CONFIG_IND[f'{ind_model}_{target}']}/fold_{fold}\"\n#             model_dir =  f\"{target}/{ind_model}/fold_{fold}\"\n#             model_fold_dir = os.path.join(model_dir, str(fold))\n\n#             model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_dir)\n#             model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n#             model_gpu = model.to(device)\n\n#             test_args = TrainingArguments(\n#                 output_dir=  model_fold_dir,\n#                 do_train = False,\n#                 do_predict = True,\n#                 per_device_eval_batch_size = CFG.batch_size,\n#                 dataloader_drop_last = False,\n# #                 fp16=True\n#             )\n\n#             infer = Trainer(\n#                 model = model_gpu,\n#                 args = test_args,\n#                 tokenizer = tokenizer,\n#                 data_collator = train_collator\n#             )\n\n#             preds = infer.predict(tokenized_val_dataset)[0]\n#             train.loc[val_data.index,f\"{ind_model}_{target}_pred\"] = preds\n\n#             model_gpu.cpu()\n#             del model_gpu\n#             gc.collect()\n#             torch.cuda.empty_cache()\n#         oof_preds[target] = train[f\"{ind_model}_{target}_pred\"]\n#     print(f\"Saving {ind_model} oof preds in csv file.\")\n#     oof_preds['student_id'] = train['student_id']\n#     oof_preds.to_csv(f\"{WORKING_DIR}/commonlit-oof-preds/{ind_model}_oof_preds.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T11:58:52.826333Z","iopub.execute_input":"2023-09-27T11:58:52.827282Z","iopub.status.idle":"2023-09-27T12:13:34.796485Z","shell.execute_reply.started":"2023-09-27T11:58:52.827240Z","shell.execute_reply":"2023-09-27T12:13:34.795620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions on test set","metadata":{}},{"cell_type":"code","source":"prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\nsummaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\ntest = pd.merge(prompts_test,summaries_test,on='prompt_id')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:49:27.868566Z","iopub.execute_input":"2023-09-28T06:49:27.868904Z","iopub.status.idle":"2023-09-28T06:49:27.893166Z","shell.execute_reply.started":"2023-09-28T06:49:27.868863Z","shell.execute_reply":"2023-09-28T06:49:27.892209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.applymap(lambda s: s.lower() if type(s)==str else s)\ntest['corrected_summary_text'] = test[\"text\"].progress_apply(speller)\ntest['full_text'] = test['prompt_title'] + sep + test['prompt_question'] + sep + test['text']","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:49:27.894799Z","iopub.execute_input":"2023-09-28T06:49:27.895143Z","iopub.status.idle":"2023-09-28T06:49:27.913391Z","shell.execute_reply.started":"2023-09-28T06:49:27.895108Z","shell.execute_reply":"2023-09-28T06:49:27.911847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = Dataset.from_pandas(test[text_cols])\ntokenized_test_dataset = test_dataset.map(lambda x: generate_tokens(x,'test','full_text'),batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:49:27.915239Z","iopub.execute_input":"2023-09-28T06:49:27.915614Z","iopub.status.idle":"2023-09-28T06:49:27.994056Z","shell.execute_reply.started":"2023-09-28T06:49:27.915576Z","shell.execute_reply":"2023-09-28T06:49:27.992735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for multi_model in multi_models:\n    print(f'Model: {multi_model}')\n    test_preds = pd.DataFrame()\n    for fold in range(CFG.n_splits):\n        pretrained_model_dir = f\"{CONFIG_MULTI[multi_model]}/fold_{fold}\"\n        model_dir = f\"{multi_model}/fold_{fold}\"\n        model_fold_dir = os.path.join(model_dir, str(fold))\n\n        model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_dir)\n        model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n        model_gpu = model.to(device)\n\n        test_args = TrainingArguments(\n            output_dir=  model_fold_dir,\n            do_train = False,\n            do_predict = True,\n            per_device_eval_batch_size = CFG.batch_size,\n            dataloader_drop_last = False,\n            fp16=True\n        )\n\n        infer = Trainer(\n            model = model_gpu,\n            args = test_args,\n            tokenizer = tokenizer,\n            data_collator = train_collator\n        )\n\n        preds = infer.predict(tokenized_test_dataset)[0]\n        test[f\"{multi_model}_content_pred\"] = preds[:,0]\n        test[f\"{multi_model}_wording_pred\"] = preds[:,1]\n\n        model_gpu.cpu()\n        del model_gpu\n        del model\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    print(f\"Saving {multi_model} test preds in csv file.\")\n    for target in target_cols:\n        test_preds[target] = test[f\"{multi_model}_{target}_pred\"]\n    test_preds['student_id'] = test['student_id']\n    test_preds.to_csv(f\"{multi_model}_test_preds.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T06:49:27.995773Z","iopub.execute_input":"2023-09-28T06:49:27.996061Z","iopub.status.idle":"2023-09-28T06:53:47.840183Z","shell.execute_reply.started":"2023-09-28T06:49:27.996013Z","shell.execute_reply":"2023-09-28T06:53:47.839138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ind_model in ind_models:\n    print(f'Model: {ind_model}')\n    test_preds=pd.DataFrame()\n    for target in target_cols:\n        for fold in range(CFG.n_splits):\n            pretrained_model_dir = f\"{CONFIG_IND[f'{ind_model}_{target}']}/fold_{fold}\"\n            model_dir =  f\"{target}/{ind_model}/fold_{fold}\"\n            model_fold_dir = os.path.join(model_dir, str(fold))\n\n            model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_dir)\n            model.eval() # Set default model mode to evaluation - https://huggingface.co/docs/transformers/main_classes/model\n            model_gpu = model.to(device)\n\n            test_args = TrainingArguments(\n                output_dir=  model_fold_dir,\n                do_train = False,\n                do_predict = True,\n                per_device_eval_batch_size = CFG.batch_size,\n                dataloader_drop_last = False,\n                fp16=True\n            )\n\n            infer = Trainer(\n                model = model_gpu,\n                args = test_args,\n                tokenizer = tokenizer,\n                data_collator = train_collator\n            )\n\n            preds = infer.predict(tokenized_test_dataset)[0]\n            test[f\"{ind_model}_{target}_pred\"] = preds\n\n            model_gpu.cpu()\n            del model_gpu\n            gc.collect()\n            torch.cuda.empty_cache()\n        test_preds[target] = test[f\"{ind_model}_{target}_pred\"]\n    print(f\"Saving {ind_model} test preds in csv file.\")\n    test_preds['student_id'] = test['student_id']\n    test_preds.to_csv(f\"{ind_model}_test_preds.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hill Cimbing","metadata":{}},{"cell_type":"code","source":"# Change BASE_DIR to WORKING_DIR when running debug samples\nscores = {}\nfor multi_model in multi_models:\n    scores[multi_model] = compute_mcrmse((pd.read_csv(f'{BASE_DIR}/commonlit-oof-preds/{multi_model}_oof_preds.csv')[target_cols].values,train[target_cols].values))","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:27:26.802687Z","iopub.execute_input":"2023-09-27T12:27:26.802926Z","iopub.status.idle":"2023-09-27T12:27:26.820818Z","shell.execute_reply.started":"2023-09-27T12:27:26.802897Z","shell.execute_reply":"2023-09-27T12:27:26.819654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ind_model in ind_models:\n      scores[ind_model] = compute_mcrmse((pd.read_csv(f'{BASE_DIR}/commonlit-oof-preds/{ind_model}_oof_preds.csv')[target_cols].values,train[target_cols].values))","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:27:26.822379Z","iopub.execute_input":"2023-09-27T12:27:26.822607Z","iopub.status.idle":"2023-09-27T12:27:26.842027Z","shell.execute_reply.started":"2023-09-27T12:27:26.822582Z","shell.execute_reply":"2023-09-27T12:27:26.840939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:27:26.843574Z","iopub.execute_input":"2023-09-27T12:27:26.843804Z","iopub.status.idle":"2023-09-27T12:27:26.850421Z","shell.execute_reply.started":"2023-09-27T12:27:26.843777Z","shell.execute_reply":"2023-09-27T12:27:26.849661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Content","metadata":{}},{"cell_type":"code","source":"scores_content = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1]['content_rmse'])}","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:27:26.851684Z","iopub.execute_input":"2023-09-27T12:27:26.852094Z","iopub.status.idle":"2023-09-27T12:27:26.868841Z","shell.execute_reply.started":"2023-09-27T12:27:26.852067Z","shell.execute_reply":"2023-09-27T12:27:26.868066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_content","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_df_content = pd.DataFrame()\ntest_df_content = pd.DataFrame()\n\nfor item in scores_content.items():\n    oof_df_content[item[0]]=pd.read_csv(f'{BASE_DIR}/commonlit-oof-preds/{item[0]}_oof_preds.csv')['content'].values\n    test_df_content[item[0]]=pd.read_csv(f'{WORKING_DIR}/{item[0]}_test_preds.csv')['content'].values","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:29:00.616323Z","iopub.execute_input":"2023-09-27T12:29:00.616628Z","iopub.status.idle":"2023-09-27T12:29:00.653434Z","shell.execute_reply.started":"2023-09-27T12:29:00.616598Z","shell.execute_reply":"2023-09-27T12:29:00.652383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialise\ny_content = train['content'].values\nSTOP = False\ncurrent_best_ensemble_content = oof_df_content.iloc[:,0]\ncurrent_best_test_preds_content = test_df_content.iloc[:,0]\nMODELS = oof_df_content.iloc[:,1:]\n# weight_range = np.arange(0.01,0.51,0.01)   # or with negative weights: np.arange(-0.5,0.51,0.01)\nweight_range = np.arange(-0.5,0.51,0.01)   # or with negative weights: np.arange(-0.5,0.51,0.01)\nhistory = [compute_metrics((current_best_ensemble_content,y_content))['rmse']]\ni=0\n\n# Hill climbing\nwhile not STOP:\n    i+=1\n    potential_new_best_cv_score = compute_metrics((current_best_ensemble_content,y_content))['rmse']\n    k_best, wgt_best = None, None\n    for k in MODELS:\n        for wgt in weight_range:\n            potential_ensemble = (1-wgt) * current_best_ensemble_content + wgt * MODELS[k]\n            cv_score = compute_metrics((potential_ensemble,y_content))['rmse']\n            if cv_score < potential_new_best_cv_score:\n                potential_new_best_cv_score = cv_score\n                k_best, wgt_best = k, wgt\n\n    if k_best is not None:\n        current_best_ensemble_content = (1-wgt_best) * current_best_ensemble_content + wgt_best * MODELS[k_best]\n        current_best_test_preds_content = (1-wgt_best) * current_best_test_preds_content + wgt_best * test_df_content[k_best]\n        MODELS.drop(k_best, axis=1, inplace=True)\n        if MODELS.shape[1]==0:\n            STOP = True\n        print(f'Iteration: {i}, Model added: {k_best}, Best weight: {wgt_best:.2f}, Best RMSE: {potential_new_best_cv_score:.5f}')\n        history.append(potential_new_best_cv_score)\n    else:\n        STOP = True","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:29:03.424810Z","iopub.execute_input":"2023-09-27T12:29:03.425123Z","iopub.status.idle":"2023-09-27T12:29:05.125649Z","shell.execute_reply.started":"2023-09-27T12:29:03.425092Z","shell.execute_reply":"2023-09-27T12:29:05.124615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_wording = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1]['wording_rmse'],reverse=False)}","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:29:10.127322Z","iopub.execute_input":"2023-09-27T12:29:10.127617Z","iopub.status.idle":"2023-09-27T12:29:10.133935Z","shell.execute_reply.started":"2023-09-27T12:29:10.127571Z","shell.execute_reply":"2023-09-27T12:29:10.132728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_wording","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:29:11.923567Z","iopub.execute_input":"2023-09-27T12:29:11.923837Z","iopub.status.idle":"2023-09-27T12:29:11.932174Z","shell.execute_reply.started":"2023-09-27T12:29:11.923809Z","shell.execute_reply":"2023-09-27T12:29:11.930997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_df_wording = pd.DataFrame()\ntest_df_wording = pd.DataFrame()\nfor item in scores_wording.items():\n    oof_df_wording[item[0]]=pd.read_csv(f'{BASE_DIR}/commonlit-oof-preds/{item[0]}_oof_preds.csv')['wording'].values\n    test_df_wording[item[0]]=pd.read_csv(f'{WORKING_DIR}/{item[0]}_test_preds.csv')['wording'].values","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:29:19.747290Z","iopub.execute_input":"2023-09-27T12:29:19.747574Z","iopub.status.idle":"2023-09-27T12:29:19.785076Z","shell.execute_reply.started":"2023-09-27T12:29:19.747546Z","shell.execute_reply":"2023-09-27T12:29:19.783741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialise\ny_wording = train['wording'].values\nSTOP = False\ncurrent_best_ensemble_wording = oof_df_wording.iloc[:,0]\ncurrent_best_test_preds_wording = test_df_wording.iloc[:,0]\nMODELS = oof_df_wording.iloc[:,1:]\n# weight_range = np.arange(0.01,0.51,0.01)   # or with negative weights: np.arange(-0.5,0.51,0.01)\nweight_range = np.arange(-0.5,0.51,0.01)   # or with negative weights: np.arange(-0.5,0.51,0.01)\nhistory = [compute_metrics((current_best_ensemble_wording,y_wording))['rmse']]\ni=0\n\n# Hill climbing\nwhile not STOP:\n    i+=1\n    potential_new_best_cv_score = compute_metrics((current_best_ensemble_wording,y_wording))['rmse']\n    k_best, wgt_best = None, None\n    for k in MODELS:\n        for wgt in weight_range:\n            potential_ensemble = (1-wgt) * current_best_ensemble_wording + wgt * MODELS[k]\n            cv_score = compute_metrics((potential_ensemble,y_wording))['rmse']\n            if cv_score < potential_new_best_cv_score:\n                potential_new_best_cv_score = cv_score\n                k_best, wgt_best = k, wgt\n\n    if k_best is not None:\n        current_best_ensemble_wording = (1-wgt_best) * current_best_ensemble_wording + wgt_best * MODELS[k_best]\n        current_best_test_preds_wording = (1-wgt_best) * current_best_test_preds_wording + wgt_best * test_df_wording[k_best]\n        MODELS.drop(k_best, axis=1, inplace=True)\n        if MODELS.shape[1]==0:\n            STOP = True\n        print(f'Iteration: {i}, Model added: {k_best}, Best weight: {wgt_best:.2f}, Best RMSE: {potential_new_best_cv_score:.5f}')\n        history.append(potential_new_best_cv_score)\n    else:\n        STOP = True","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:29:23.802455Z","iopub.execute_input":"2023-09-27T12:29:23.802764Z","iopub.status.idle":"2023-09-27T12:29:25.492596Z","shell.execute_reply.started":"2023-09-27T12:29:23.802734Z","shell.execute_reply":"2023-09-27T12:29:25.491465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_ensemble_preds_train = np.column_stack((current_best_ensemble_content,current_best_ensemble_wording))","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:29:28.388156Z","iopub.execute_input":"2023-09-27T12:29:28.388437Z","iopub.status.idle":"2023-09-27T12:29:28.393509Z","shell.execute_reply.started":"2023-09-27T12:29:28.388408Z","shell.execute_reply":"2023-09-27T12:29:28.392538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_preds=pd.DataFrame()\nensemble_preds['content'] = current_best_ensemble_content\nensemble_preds['wording'] = current_best_ensemble_wording\nensemble_preds['student_id'] = train['student_id']\nensemble_preds.to_csv('ensemble_oof_preds.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Best mcrmse: {compute_mcrmse((best_ensemble_preds_train,train[target_cols].values))}')","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:29:30.973055Z","iopub.execute_input":"2023-09-27T12:29:30.973326Z","iopub.status.idle":"2023-09-27T12:29:30.980334Z","shell.execute_reply.started":"2023-09-27T12:29:30.973298Z","shell.execute_reply":"2023-09-27T12:29:30.979115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"df_submission = pd.DataFrame()\ndf_submission['student_id'] = test['student_id']\ndf_submission['content'] = current_best_test_preds_content\ndf_submission['wording'] = current_best_test_preds_wording\ndf_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:29:35.315209Z","iopub.execute_input":"2023-09-27T12:29:35.315506Z","iopub.status.idle":"2023-09-27T12:29:35.327848Z","shell.execute_reply.started":"2023-09-27T12:29:35.315477Z","shell.execute_reply":"2023-09-27T12:29:35.326385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission.head(4)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T12:29:37.339263Z","iopub.execute_input":"2023-09-27T12:29:37.339547Z","iopub.status.idle":"2023-09-27T12:29:37.353469Z","shell.execute_reply.started":"2023-09-27T12:29:37.339519Z","shell.execute_reply":"2023-09-27T12:29:37.352375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}